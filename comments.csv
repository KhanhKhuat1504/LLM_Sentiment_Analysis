by,id,parent,text,time,type,story_id
cstanley,39822179,39820639,"This paper was published 154 days ago, probably a year since the authors did the experiment. Sooo much has happened since then! This showed already that GPT4 is pretty darn good analyst.<p>All this real-world complexity can be tamed by stuffing the prompt with a ton of relevant context and an amazing prompt engine. We&#x27;ll have bots that autonomously query the database hundreds of times building a 5 page &quot;deep-dive&quot; analytics report in minutes.<p>At least that&#x27;s what we&#x27;re trying at patterns.app.",1711407375,comment,39820639
andy99,39821924,39820639,May 2023 using GPT-4-0314.,1711405512,comment,39820639
elietoubi,39822235,39820639,"If anyone is interested i built for myself and open sourced parse.dev<p><a href=""https:&#x2F;&#x2F;github.com&#x2F;ParseDev&#x2F;parsedev"">https:&#x2F;&#x2F;github.com&#x2F;ParseDev&#x2F;parsedev</a>",1711407729,comment,39820639
lutusp,39822249,39820639,"&gt; However, we are still at a stage of divergent opinions without any definitive conclusion.<p>Okay, I know picking people&#x27;s sentences apart has fallen out of fashion, but:<p>&quot;Divergent opinions&quot; are ... opinions.
A &quot;definitive conclusion&quot; is ... a conclusion.<p>I see more examples, but I wanted to make a point: I miss the days when fewer words conveyed more meaning. From the classic <a href=""https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;The_Elements_of_Style"" rel=""nofollow"">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;The_Elements_of_Style</a>: &quot;Make every word count.&quot;<p>About brevity of expression, I must add this (possibly apocryphal) story about Ernest Hemingway. In the 1920s Hemingway and his Paris friends had a contest: who could write the shortest readable short story? Hemingway won with this entry:<p>For sale. Baby shoes. Never worn.",1711407845,comment,39820639
apineda,39822475,39822249,"From an alternative viewpoint, this could be seen as descriptive of a community. Opinions could be shared or not, hence &quot;divergent&quot; as an adjective to describe the community. Similar with conclusions people have drawn and &quot;definitive&quot; may refer to a larger consensus among the community. Fun to think about.",1711409383,comment,39820639
greenavocado,39821832,39820639,Even the latest commercial LLMs are happy to confidently bullshit about what they think is in published research even if they provide citations. Often the citations themselves are slightly corrupted. I actually verify each LLM claim so I know this is happening a lot. Occasionally they are complete fabrications. It really varies by research topic. Its really bad in esoteric research areas. They even acknowledge the paper was actually about something else if you call them out on it. What a disaster. LLMs are still useful for information retrieval and exploration as long as you understand you are having a conversation with a habitual liar &#x2F; expert beginner and adjust your prompts and expectations accordingly.,1711404835,comment,39820639
bongodongobob,39821934,39821832,"Unintuitively, I think you&#x27;ll probably end up with better answers if you don&#x27;t ask for citations. The vast majority of its training isn&#x27;t white papers so you&#x27;re artificially constraining its &quot;imagination&quot; to the cited sources space. I find the more constraints you add, the worse your answers are.",1711405644,comment,39820639
notnullorvoid,39822288,39821832,"&gt; They even acknowledge the paper was actually about something else if you call them out on it.<p>For clarity is not really acknowledging it made a mistake. &quot;Calling out&quot; an LLM&#x27;s mistake just leads to the next most likely text to be something that sounds like an acknowledgement of a mistake, but the same is likely to happen if the LLM generated a correct response and you respond claiming that it&#x27;s incorrect.",1711408090,comment,39820639
jiggawatts,39822333,39821832,"&gt; What a disaster.<p>Using tool inappropriately leads to suboptimal outcomes -- news at 11.<p>A good mental model is that an LLM is a blurry JPEG of the Internet.<p>You sound like a scientist, right? You reference &quot;published research&quot;, after all.<p>What would your opinion be of a researcher measuring the exact values of the pixels of a JPEG image instead of the RAW sensor data?",1711408329,comment,39820639
mritchie712,39821929,39820639,"reminds me of this tweet [0]<p><pre><code>    Them: Can you just quickly pull this data for me?

    Me: Sure, let me just: 

    SELECT * FROM some_ideal_clean_and_pristine.table_that_you_think_exists

</code></pre>
GPT-4 is good on a single CSV, but breaks down quickly applied to a real database &#x2F; data warehouse. I know they&#x27;re using multiple tables in the paper, but it appears to be a pristine schema that&#x27;s very easy to reason about. In the real world, when you&#x27;re trying to join postgres to hubspot and stripe data, an LLM isn&#x27;t able to write the SQL from scratch get the right answer.<p>We&#x27;re working on an approach using a semantic layer at <a href=""https:&#x2F;&#x2F;www.definite.app&#x2F;"" rel=""nofollow"">https:&#x2F;&#x2F;www.definite.app&#x2F;</a> if you&#x27;re interested in this sort of thing.<p>0 - <a href=""https:&#x2F;&#x2F;twitter.com&#x2F;sethrosen&#x2F;status&#x2F;1252291581320757249?lang=en"" rel=""nofollow"">https:&#x2F;&#x2F;twitter.com&#x2F;sethrosen&#x2F;status&#x2F;1252291581320757249?lan...</a>",1711405558,comment,39820639
neeleshs,39822450,39821929,"It goes beyond just joining postgres to hubspot and stripe even when humans are doing it. Typos in source systems, duplicative data, unwarranted prefixes, suffixes, stuff you don&#x27;t care about, columns named c0,c1,c2 etc.<p>A semantic layer is just really all about defining data models in the domain of interest. It&#x27;s the hardest part in dealing with data strategies, very manual, very company and process and history specific.<p>Once it&#x27;s defined, the next set of tasks is to make sure that the data in the model is correct and coherent. And only then, querying this data, applying ML etc start becoming worthwhile.<p>We at <a href=""https:&#x2F;&#x2F;syncari.com"" rel=""nofollow"">https:&#x2F;&#x2F;syncari.com</a> take the centralized data model centric approach. 
<a href=""https:&#x2F;&#x2F;www.definite.app&#x2F;"" rel=""nofollow"">https:&#x2F;&#x2F;www.definite.app&#x2F;</a> also looks very cool!",1711409125,comment,39820639
,39822102,39821929,,1711406849,comment,39820639
kva,39821769,39820639,"Given the right prompt, I&#x27;m sure it is....but when do users ever enter the right prompt? :(",1711404364,comment,39820639
richardw,39821856,39821769,"You can&#x27;t depend on it at all.  I mean, you can use it for a tremendous amount of work, but until there is a way to constrain the bullshit LLM&#x27;s can&#x27;t be used for anything that requires a correct answer.<p>The terms &quot;depend&quot; and &quot;require&quot; there are the hard versions. You can&#x27;t send people to the moon on the outputs of LLM&#x27;s.",1711405099,comment,39820639
roenxi,39822287,39821856,"I think we&#x27;ll solve that problem for LLMs before we solve it for humans. Data analysts produce a lot of garbage; data work is really hard. In fact, it isn&#x27;t uncommon in my experience for the data analyst to be the only person saying &quot;hang on, the quality of this reporting isn&#x27;t good enough for the decisions you&#x27;re making from it!&quot; - because they understand what useful information looks like and the company doesn&#x27;t have much of it.",1711408089,comment,39820639
paulsutter,39822236,39821856,"This is sheer cope<p>The tools are good for certain tasks and getting better. Master these tools and be ready for what released in the coming months and years<p>You are either at the center turning the wheel, or you’re on the outside getting spun",1711407737,comment,39820639
richardw,39822437,39822236,"You haven&#x27;t the vaguest fucking idea what I&#x27;m doing with the tools so put up a logical argument on the facts instead of just generating tokens in some way that attempts to play the person and not the ball.<p>Here, argue with Yann, who makes a statement about how language isn&#x27;t enough to produce a mind:
<a href=""https:&#x2F;&#x2F;twitter.com&#x2F;ylecun&#x2F;status&#x2F;1768353714794901530"" rel=""nofollow"">https:&#x2F;&#x2F;twitter.com&#x2F;ylecun&#x2F;status&#x2F;1768353714794901530</a>",1711409040,comment,39820639
Fauntleroy,39822301,39822236,"These tools are great at generating text responses, some of which are usable, but not analysis. We&#x27;re actually far from that. I&#x27;m not sure why some people are out here pretending this is not the case.",1711408156,comment,39820639
williamcotton,39821849,39821769,"Didn’t you get the memo? If you’re holding the hammer by the head and wondering why it isn’t driving the nail in that it is clearly the fault of the  manufacturer.<p>There’s even a handy aphorism to remind you that the user is never to blame: “You’re holding it wrong.”<p>Jokes aside, I wonder what the general writing abilities and communication skills are for people that cannot for the life of them get usable results from an LLM.",1711405010,comment,39820639
dimask,39822449,39821769,If you already know the right answer it is actually easy,1711409112,comment,39820639
viscanti,39821828,39821769,OpenAI should make something so that people can enter their prompt and maybe even drop in a knowledge base and then share with anyone else who wants that functionality.,1711404812,comment,39820639
snoman,39821950,39821828,"That’s ptetty close to what GPTs are, with the exception of knowledge bases.<p>There’s more to it, but the tooling to create a GPT is basically a hand-holding mechanism to create a prompt.",1711405726,comment,39820639
gregorymichael,39822072,39821950,GPTs have the knowledge base too. (Mixed results though),1711406605,comment,39820639
wolpoli,39822064,39821828,"Would the final product be similar to Github copilot, but for prompt?",1711406539,comment,39820639
,39821875,39821769,,1711405230,comment,39820639
SV_BubbleTime,39822021,39821769,“42”,1711406150,comment,39820639
,39822105,39821769,,1711406867,comment,39820639
,39822114,39820639,,1711406923,comment,39820639
dangoodmanUT,39822043,39820639,Not on useful datasets in real places,1711406340,comment,39820639
,39822106,39822043,,1711406884,comment,39820639
einpoklum,39821758,39820639,"I was somewhat put off by the abstract:<p>&gt; LLMs... have demonstrated their powerful capabilities in ... context understanding, code generation, language generation, data storytelling, etc.,<p>LLMs have not demonstrated understanding (in fact, one could argue that they are fundamentally incapable of understanding); they have only AFAICT demonstrated the ability to generate boilerplate-ish code; &quot;language generation&quot; is too general a task to claim that LLMs have succeeded in; and as for data storytelling I don&#x27;t know, but they can spin yarns. The problems is that those yarns are often divorced from reality; see:<p><a href=""https:&#x2F;&#x2F;www.ibm.com&#x2F;topics&#x2F;ai-hallucinations"" rel=""nofollow"">https:&#x2F;&#x2F;www.ibm.com&#x2F;topics&#x2F;ai-hallucinations</a><p>--------<p>Leafing through the paper, and specifically tables 6 and 7, I don&#x27;t believe their conclusion, that &quot;GPT-4 can perform comparable [sic] to a data analyst&quot;, is well-founded.",1711404323,comment,39820639
mewpmewp2,39821827,39821758,"I don&#x27;t even understand what understanding exactly means, perhaps anyone who understands it, can enlighten me?<p>Do I, myself understand? Stand under what exactly? What is that supposed to mean?",1711404798,comment,39820639
modriano,39822345,39821827,"To understand means a few things, but they all essentially boil down to having a correct (or at least correct enough to be useful for your usecase(s)) model for something in your head.<p>Have you told someone something like &quot;no, don&#x27;t do it that way because &lt;insert non-obvious downstream problem&gt;, instead, do &lt;insert alternative strategy that achieves better outcomes&gt;&quot;? That&#x27;s an artifact of understanding and of the model you&#x27;ve developed for that thing.<p>It&#x27;s well described as a mixture of knowledge and wisdom, and is essentially the property of knowing the effect that pulling a lever will cause, coupled with good judgement about how, when, and why to pull the lever.",1711408427,comment,39820639
mewpmewp2,39822518,39822345,"But GPT-4 has told me that as well?<p>Usually in a bit more polite way.<p>That my approach is a &quot;novel&quot; and an &quot;interesting&quot; approach, hinting that it&#x27;s really probably not the best option here.",1711409688,comment,39820639
richardw,39822337,39821827,"The fact that you ask that is in many ways the difference. You feel there’s a limitation in your knowledge of the term “understand” and its use in this context and would like clarification before you’re more certain, either way. At some point either enough information arrives to convince you, or you decide it’s not true. Whatever that process and internal states are, is something GPT can’t do.  It’ll 100% confidently produce something and be fully rewarded that it chose tokens that humans would most likely choose given the preceding tokens. There’s no “aha”.",1711408356,comment,39820639
mewpmewp2,39822485,39822337,"But it frustratingly, frequently tells me it doesn&#x27;t have enough data or other XYZ reasons to why it can&#x27;t answer my weird questions.",1711409459,comment,39820639
advael,39822152,39821827,Solipsism is truly the best fully-general counterargument,1711407216,comment,39820639
,39822321,39822152,,1711408272,comment,39820639
mewpmewp2,39822245,39822152,To AI? Or that you are not a NPC?,1711407823,comment,39820639
advael,39822296,39822245,"To anything, that&#x27;s what &quot;fully-general&quot; means",1711408131,comment,39820639
mewpmewp2,39822371,39822296,So you are a bot?,1711408581,comment,39820639
advael,39822404,39822371,"I mean from your perspective I&#x27;m just a name making more words on your screen, right? Don&#x27;t worry too much about it, buddy, you&#x27;re doin&#x27; great :)",1711408760,comment,39820639
mewpmewp2,39822463,39822404,"Haha, you are funny! What&#x27;s the weather tomorrow? Please also remind me tomorrow to put my gym clothes to washer and dry them after.",1711409250,comment,39820639
advael,39822604,39822463,"I can&#x27;t spoil the weather tomorrow (it&#x27;s a major plot point) but I can tell you that fortune has been tweaked to favor the bold by an additional 10%, just for tomorrow.<p>Laundry service is complimentary, but our records show that you haven&#x27;t registered your home. Would you like to register your home address at this time?",1711410507,comment,39820639
ocbyc,39821860,39821827,"Transformers are just pattern matching. So if you write &quot;give me a list of dog names&quot; it knows that &quot;Spot&quot; should be in that result set. Even though it doesn&#x27;t really know what a dog is, a list is, or what a spot is.",1711405116,comment,39820639
rafaelero,39821915,39821860,&gt; Transformers are just pattern matching.<p>That&#x27;s trivially true. The question is: are we any different?,1711405453,comment,39820639
richardw,39822368,39821915,"I think so. You ask that question because you’re interrogating the position, not because 1000 humans have asked that question in similar situations.<p>You and I know there’s a truth and we’d like to find it. The GPT is just happy (I.e. rewarded) to produce frequently used tokens.",1711408559,comment,39820639
parpfish,39822584,39822368,but maybe that feeling of &#x27;looking for truth&#x27; is just what happens when you&#x27;re doing pattern matching on the text embeddings?,1711410364,comment,39820639
mewpmewp2,39822492,39822368,And I&#x27;m just happy to perform actions that will make me survive and reproduce?,1711409520,comment,39820639
richardw,39822523,39822492,"Most likely, unless you meditate a lot. Sometimes you&#x27;ll take a bullet to save other people. Sometimes you&#x27;ll drink yourself into a state that doesn&#x27;t help you survive or reproduce. Or you&#x27;ll write on a forum anonymously that doesn&#x27;t help with survival or reproduction because it&#x27;s enjoyable, makes you think, or you&#x27;re addicted. Who knows :)",1711409740,comment,39820639
mewpmewp2,39822608,39822523,You are even better at analyzing me than GPT-4.,1711410519,comment,39820639
parpfish,39822205,39821915,I approach LLMs with the perspective that “maybe this demonstrates that we humans are all just stochastic parrots?”and we should have the null hypothesis that humans are just pattern matchers.,1711407551,comment,39820639
mewpmewp2,39822271,39822205,"This is the way I perceive my thoughts. I don&#x27;t know what I&#x27;m going to think of beforehand or in advance, these could all be stochastic &quot;tokens&quot; based on what I&#x27;ve observed in my life.<p>So of course I feel a bit offended when people claim LLMs are just stochastic parrots, because it doesn&#x27;t feel to me, that I&#x27;m specifically any better?<p>My thoughts - they just happen, and sometimes not in my favor - I have had times of depression, I didn&#x27;t have control over my thoughts. Neither do I have now, but at least I am in a better place. Because the &quot;happiness&quot; chemicals are regulated to be in a more favorable state to me for various different factors.<p>I didn&#x27;t know what I was going to comment in response to your comment, I was just streaming my conscious.",1711408022,comment,39820639
bongodongobob,39821908,39821860,"I don&#x27;t think that&#x27;s true. They clearly group related things together and seem to be able to create concepts that aren&#x27;t specifically in the training data. For example, it will figure out the different features of a face, eyes, nose, mouth even if you don&#x27;t explicitly tell it what those are. Which is why they are so cool.",1711405424,comment,39820639
zeusk,39822220,39821908,Most of that magic comes from embedding no? which is clustering things by their relation in some N-dimensional space,1711407636,comment,39820639
bongodongobob,39822383,39822220,"Exactly. It figures that out on its own. That&#x27;s what &quot;understanding&quot; looks like in this context, imo.",1711408637,comment,39820639
mewpmewp2,39822008,39821908,"They are cool, but then you are also cool.",1711406054,comment,39820639
mewpmewp2,39821982,39821860,How would I test whether I &quot;know&quot; or &quot;understand&quot; what a dog is?,1711405918,comment,39820639
notahacker,39822452,39821982,"Oh, that&#x27;s easy, we just give the dog a keyboard and see if you accurately identify it&#x27;s a dog from  your text based interactions ;-)",1711409163,comment,39820639
mewpmewp2,39822499,39822452,Are you calling me a dog?,1711409588,comment,39820639
inopinatus,39822141,39821860,Even this seems too grand a claim. I’d water it down thus: the LLM encodes that the token(s) for “Spot” are probabilistically plausible in the ensuing output.,1711407122,comment,39820639
bongodongobob,39822202,39822141,"...because it understands what a dog name is. Why wouldn&#x27;t you see Gary or Florence in that list? How does it know those aren&#x27;t dog names?<p>You can&#x27;t be suggesting it has memorized relationships between all concepts, the model would be enormous.<p>So clearly, there is something else going on. It&#x27;s able to encode concepts&#x2F;ideas.",1711407529,comment,39820639
inopinatus,39822212,39822202,"The model <i>is</i> enormous, and N-dimensional for very high N. But the model remains insufficiently enormous for understanding, and moreover, the model cannot observe itself and adjust.<p>Ask an LLM to extrapolate, see any semblance of reason collapse.",1711407592,comment,39820639
mewpmewp2,39822253,39822212,Extrapolate what?,1711407890,comment,39820639
ALittleLight,39821966,39821860,Can you describe a test that would separate trivial pattern matching from true understanding?,1711405822,comment,39820639
lottin,39822067,39821966,A simple conversation would do.,1711406572,comment,39820639
mewpmewp2,39822145,39822067,"Could you share a conversation link with GPT-4 with either about a &quot;list&quot; or a &quot;dog&quot;, to determine whether it truly understands one of those things compared to a human?",1711407147,comment,39820639
bongodongobob,39822156,39822067,Just did that. It seems to understand. Checkmate &#x2F;fingerguns,1711407229,comment,39820639
unclebucknasty,39822038,39821758,"Agreed, right down to their conclusion resonating as way overstated. Actually, meaningless would be more accurate.<p>The thing about LLMs is exactly that they <i>don&#x27;t</i> understand by design. It often feels very distinctly like it&#x27;s just engaging in sophisticated wordplay. A parlor trick.<p>When ChatGPT 4 first came out I spent a couple of hours putting together a chess game using ChatGPT as the engine. It was shockingly bad, as in even attempting to make invalid moves.<p>I get it: it&#x27;s not tuned for that purpose, and its chess training corpus could probably be expanded to improve it as well.<p>But, it actually served as a near-perfect demonstration of its lack of understanding, as well as the confidence with which it asserts things that are simply wrong.<p>On a recent integration project with a good bit of nuanced functionality, it led me astray multiple times. I&#x27;ve gotten to a point where I can feel when its answers are not quite right, particularly if I know just a little about the topic. And, when challenged, it does that strange thing of responding with something along the lines of, &quot;My apologies you&#x27;re completely right that I was completely wrong&quot;.<p>Over time, there becomes a sense that there is no there there. Even it&#x27;s writing capabilities, lauded by so many, are of a style that is superficial and perfunctory or rote. That makes sense when you know what it is, but that&#x27;s the thing: we get articles like these, lauding its wisdom.",1711406320,comment,39820639
bongodongobob,39822088,39822038,"Idk. One of my first tests for GPT4 was writing a website &quot;for snakes.&quot; It was a flask app, and it did all the obvious things you&#x27;d expect. There was a title that said &quot;Snake.com - A website for snakes&quot; and a bunch of silly marketing stuff.<p>What impressed me is when I asked to make it more snake-like (what does that even mean right?).<p>It changed the colors to shades of green, used italic fonts, added some hisssssing sssstuff to wordssss, and added a diamond pattern through the background.<p>It was a dumb and not very fancy site, but I&#x27;m not sure you can say it doesn&#x27;t understand anything at all when you ask it to make a website more snakelike and actually made a pretty good attempt at doing it.",1711406723,comment,39820639
unclebucknasty,39822192,39822088,"Yeah, that&#x27;s kind of a different conception of understanding though. The lines do get a little blurry at a certain point, and a lot of what it does &quot;feels&quot; like understanding, especially given how it &quot;communicates&quot;.<p>But I think it comes down to whether it can reason about things and whether it can draw new conclusions or create new information as a result.<p>Your snake site is probably a good example. ChatGPT has a bunch of words that it knows are associated with snakes. It&#x27;s pretty straightforward pattern matching. It doesn&#x27;t really &quot;understand&quot; what those words mean, except that they have relationships to other words.<p>But, if you were to ask it to reason and draw new conclusions about these things beyond its training corpus, it would be unable to reliably do so.<p>Similarly, it had no idea about the quality (and sometimes legality) of the chess moves it generated.",1711407428,comment,39820639
visarga,39822379,39822192,"&gt; it comes down to whether it can reason about things and whether it can draw new conclusions or create new information as a result<p>Neither can humans, at least with our bare brains. We can do it by carefully observing the effects of our actions in the environment, but we are really studying the world and it takes time. Everything we know comes from the environment.<p>The brain by itself invents or discovers nothing, it is the data-engine made by action-effect-feedback that teaches us all we know. Without the ability to push and prod, set up our experiments and carefully observe effects we wouldn&#x27;t be at our current level.<p>Environment is the teacher, but there is another important factor - language. Without it every one of us would have to rediscover from scratch. With it we can build upon other people to learn and cooperate. We encode everything we know in language. It acts like an evolutionary system of ideas.<p>LLMs have what is necessary, they can learn language pretty well, but until now have not been exposed much to the world. There are millions of chats but very little in other kinds of environments - computers, simulators, games, robots. LLMs can create their own experiences and learn from each other, and from us.<p>Open ended discovery is a grand project, a social process, it doesn&#x27;t work well in one agent. Language is the linking element, and the world is the teacher. Some things are not written in any books, only the external world can teach us. Reasoning about things and drawing new conclusions depends on having access to an environment.",1711408625,comment,39820639
bongodongobob,39822325,39822192,"I mostly agree.<p>I really think chess is just a terrible example though. You&#x27;re really asking a lot of it but I&#x27;m honestly shocked it <i>can</i> do what it can. It seems to know some opening books, but falls down immediately. Which really makes sense because you&#x27;ll find a lot of reading material on specific openings, but the problem space of the game is just too big to find texts about any given game state. Maybe if you have it reason about the board state and &quot;think&quot; about tactics you could push it farther. But we&#x27;ve already solved this.<p>We have Stockfish et al and they&#x27;ve literally changed the game. Asking an LLM to play chess, while cool, is like trying to train a fish to dance. I think once we have an AI that&#x27;s built with a bunch of different models that specialize in different things the idea of understanding is going to get even blurrier to the point that we might even say &quot;yes, it doesn&#x27;t &#x27;understand&#x27; things, but it&#x27;s better at humans at literally everything&quot; so the difference becomes meaningless.<p>I&#x27;m also of the opinion that humans are fancy automatons, so I tend to argue both sides. I&#x27;ll say yeah it&#x27;s thinking and so do we or ok it&#x27;s not, but either do we.",1711408290,comment,39820639
withinrafael,39819265,39818823,"&gt; Below are a few examples of the artists’ work, with early thoughts from them on how they see Sora fitting into their workflows and businesses.<p>I wish it was clearer how Sora was used by each artist and how it impacted the provided examples. (I think I see some Sora generated output but I&#x27;d imagine it&#x27;s not as clear cut in artistic works.)",1711388764,comment,39818823
rperez333,39822394,39818823,"I&#x27;m seeing shots that would be incredibly expensive for some productions - even if we ignore the ones requiring visual effects work. Some of them would need small crews, permits, rentals of expensive equipment, casting, and travel. It&#x27;s impressive and concerning at the same time.",1711408711,comment,39818823
Jensson,39819266,39818823,"&gt; Sora is at its most powerful when you’re not replicating the old but bringing to life new and impossible ideas we would have otherwise never had the opportunity to see.<p>Roughly what you would expect, good for artsy pieces where you don&#x27;t need the model to generate anything very specific, but not very useful for most work since most work you want that control.<p>In other words it will be used for very similar things as current image generators, like intro scenes, short one offs, concept art etc.",1711388777,comment,39818823
erickj,39819924,39819266,&gt; not very useful for most work<p>We seem to be on a timeline where most of the significant use cases that the model doesn&#x27;t handle well today is less than 2 years away from significant improvement.<p>My (completely baseless) guess is that within 2 years we begin to see &quot;high budget&quot; feature length productions beginning to move towards a cost saving model which fully allocate the production budget to primarily virtual content.<p>In less than a few years time there will almost certainly be a vast ecosystem of production and post production tools to give creators the controls to reliably create and fine tune their shots.,1711392508,comment,39818823
hexage1814,39820665,39819924,"I agree with you, and just a few more observations about where do I think the current bottleneck might be: I wonder how well the model handles with re-using objects&#x2F;people&#x2F;scenes. Like, can I create a character and then use him again along 10 different shots? Also, I&#x27;m pretty curious about how the user interface looks like. Cause they the text-to-video model interfaces seem pretty limited compared to the freedom a person has using Unreal Engine or Blender or shooting a movie in real life.<p>How would the golden standard text-to-video user interface would look? And I have been thinking on this for years, even before the current generative AI boom, and I wonder if it could generate like a 3D representation of the scene that you described, like there would be a file where you could very easily change things around, as if that thing had been created on Blender or whatever, but very very user-friendly and easy to edit things.<p>It will seem silly what I&#x27;m going to say, but the ideal interface, it reminds those movies people did using the game &quot;The Sims&quot;, and how you could very easily move objects, and move the camera, and so on. What I&#x27;m trying to say here is that I would imagine these models creating a 3D representation of the scene, and the movie-making process ends up being somewhat similar to how could you could customize objects&#x2F;people in that game.",1711396956,comment,39818823
TomaszZielinski,39822424,39820665,"I have only vague idea about this (I worked on small 3d games many many years ago), but I imagined something similar to what you described.<p>Basically you use Sora to generate a promising scene, then you ask it (or another model) to turn that scene into a scene graph in a text file.<p>It will make mistakes, but it could work similarly to the Python interpreter in ChatGPT--it can iterate until everything is OK. Maybe there could even be some adversarial stuff where the scene graph is rendered on the fly to compare it to the generated clip, etc.<p>And then you can use you standard toolset to edit it, probably enhanced with a copilot model to automate as much as possible.",1711408923,comment,39818823
whiplash451,39820668,39819924,"The cool demos from OpenAI, Figure and the like make us hallucinate a future that will take much (much) longer to pan out because they ignore the domain-specific knowledge that is inherent to the domain they pretend to disrupt.<p>I’ll be impressed when ILM talks about it.",1711396970,comment,39818823
commakozzi,39821252,39820668,this&#x27;ll age well...,1711400649,comment,39818823
CamperBob2,39821319,39821252,It&#x27;s &quot;God of the Gaps&quot; all the way down with these folks.,1711401182,comment,39818823
jrflowers,39819795,39818823,"&gt; As great as Sora is at generating things that appear real - what excites us is its ability to make things that are totally surreal.<p>Finally, software that makes images that don’t quite look right. The use cases for these will be unending",1711391865,comment,39818823
whiplash451,39820713,39818823,"I’ll be downvoted for this, but all these videos feel like the high-fructose corn syrup of cooking.",1711397247,comment,39818823
wilg,39821303,39820713,"Successful, widespread, and not differentiable in taste tests?",1711401017,comment,39818823
jazzyjackson,39821843,39821303,a cheap way to make everything sweet so that prepackaged goods are preferable to ever leaning how to make something yourself,1711404933,comment,39818823
wilg,39822234,39821843,I think its good cheap food is available!,1711407722,comment,39818823
xotesos,39822574,39820713,[dead],1711410269,comment,39818823
th0ma5,39819054,39818823,A good study could be comparing artist output and self satisfaction with LLMs vs. Conversing with a rubber duck or just imagining what an LLM might do. A lot of this reads to me as the artists actually selling themselves short.,1711387752,comment,39818823
huytersd,39820854,39818823,How much of this is truly Sora and how much is not?,1711398121,comment,39818823
dzhiurgis,39821423,39818823,I feel all the GPU time should first go to improving GPT or solving AGI rather than image&#x2F;video generation,1711401845,comment,39818823
,39818911,39818823,,1711387142,comment,39818823
p1esk,39794906,39793250,This method has only been tested on tiny models (&lt;1B) and tiny dataset (17B tokens). It’s not clear if it scales.,1711141852,comment,39793250
ml_basics,39795135,39794906,"To be fair to the authors they are affiliated with a university and not a big industrial lab, so they may be working with significantly constrained resources. Not sure exactly what the best solution is for this case given that it affects most people outside of a very select few.",1711143585,comment,39793250
p1esk,39795804,39795135,They could partner with big industrial labs.,1711149019,comment,39793250
refulgentis,39797043,39795804,"Nah, nobody&#x27;s begging for people to A) come use time on their GPUs B) come watch them train their biggest models. Nor does it make sense to spend $X00M training a big model using an experimental technique before you announce it, nor does it make sense to hold back breakthroughs as an academic until someone commercializes it at scale. Category error.",1711162545,comment,39793250
p1esk,39803860,39797043,I do ML research at a small industrial lab. I’ll gladly provide some compute to people with a cool idea if that results in my company name listed on a paper in a top conference. Especially if the people are from a top university.,1711237472,comment,39793250
sp332,39799072,39795804,"Well now that they have a promising result, maybe.",1711192695,comment,39793250
p1esk,39801294,39799072,They had this promising result before they posted the paper.,1711212879,comment,39793250
Buttons840,39795951,39794906,"If a genie appeared and granted one wish, I would wish that we find an extremely powerful machine learning technique that doesn&#x27;t scale. Imagine if an average desktop computer was almost as good as a billion dollar super computer.<p>In other words, I don&#x27;t really care if it scales. I almost hope it doesn&#x27;t.",1711150424,comment,39793250
p1esk,39796150,39795951,Not sure I understand what you mean by “doesn’t scale”. Are you trying to say you would like to see a tiny model performing as well as a large model?,1711152576,comment,39793250
MacsHeadroom,39796687,39795951,Even pocket computers (smartphones) are already better than billion dollar supercomputers from decades past.<p>What is your point?,1711158060,comment,39793250
pyinstallwoes,39804828,39796687,That no one has an advantage,1711249083,comment,39793250
jal278,39795383,39794906,But it may scale -- that&#x27;s science in progress,1711145361,comment,39793250
valine,39795841,39793250,The architecture changes are very straight forward. Model merging has shown that pre-trained transformer layers are very robust. I’ll bet it’s possible to fine tune a pre-trained model like mistral to use this architecture. That would enable someone to test it with more parameters without training a whole new base model.,1711149418,comment,39793250
numeri,39796285,39795841,"They try this in the appendix without success, unfortunately. It seems having this enabled early on in training is important.",1711154161,comment,39793250
matteopagli,39800018,39796285,"We&#x27;re still working on training the DWA weights on top of a pretained model. We&#x27;re hopeful that this is feasible. The experiments you&#x27;re mentioning in the appendix are not changing the learning rate scheduler. E.g., when starting to train the DWA weights after 20k iterations, the learning rate is already quite small. To some extent, this might explain the diminishing returns. Maybe this could work with a completely different learning rate scheduler.",1711202712,comment,39793250
gwern,39807426,39800018,"Yeah, you can&#x27;t change the model much with low LRs. That&#x27;s the point! Same reason you don&#x27;t get continual-learning if you just keep using low LRs: <a href=""https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2403.08763"" rel=""nofollow"">https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2403.08763</a> You need to really shake up the model if you want to learn some genuinely better (ie. different) internal representations that exploits the DenseNet (<a href=""https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;1608.06993)&#x2F;LTG-BERT"" rel=""nofollow"">https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;1608.06993)&#x2F;LTG-BERT</a> (<a href=""https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2311.02265"" rel=""nofollow"">https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2311.02265</a>) arch you&#x27;re using here.",1711290331,comment,39793250
bilsbie,39796597,39795841,I haven’t been able to make sense of model merging. Any insights?<p>Wouldn’t weights between models be completely different? And then there are architecture differences on top of that.,1711157043,comment,39793250
valine,39796718,39796597,"Model merging is usually done with different fine-tunes of the same model. It doesn’t work if the base models are different.<p>One of the more surprising things is that you can actually repeat layers to improve model performance, ie 1-1-2-2 instead of 1-2. That’s how you get models with higher parameter counts than the original.",1711158382,comment,39793250
namibj,39796815,39796718,"C.f. also Universal Transformer: the same layer stacked a lot.
The sparse version of that is basically MoE with also a stick-breaking mechanism to prevent vanishing gradient while letting the model decide whether to terminate layer-count at a token early (ofc with training rewards to favor less layers, to represent the compute savings).",1711159304,comment,39793250
tbalsam,39795683,39793250,"This is a very interesting idea, with DenseNets there are oftentimes some terrible memory gotchas that have gotten me over the past 7-8 years or so, so a part of me is sorta leaning back waiting for some memory usage shoe to drop not specified in the paper (even with the activation patterns!)<p>However, maybe this is not the case. I have a bit of a history of messing with residuals in neural networks, seeing more work on it is good. Fast training networks of course are a very slightly mild obsession of mine as well, and very useful to the field. Here&#x27;s hoping it pans out as a motif, curious to see where it goes.",1711147925,comment,39793250
sp332,39794626,39793250,"Even better is the result on page 7 that perplexity drops faster by wall-clock time. Even if you&#x27;re getting fewer iterations per hour of rented GPU time, you&#x27;re still coming out ahead in model performance.",1711140109,comment,39793250
ml_basics,39795118,39793250,"Cool paper. Really interesting to see how even quite straightforward architectural modifications haven&#x27;t yet all been exhausted yet, despite all the resources being poured into LLMs",1711143467,comment,39793250
samus,39795576,39795118,The problem is that they have to be tested for 7B models at least to show promise for larger models. And that requires significant compute resources.,1711147033,comment,39793250
tbalsam,39795661,39795576,"Due to some of my personal experiences over the years w&#x2F; model development, I believe that this is more due to a failure of the current mainline version of Transformers (the ++ version I believe) not scaling properly, vs an indicator of scale.<p>If that is the case, then it may well be possible to fix some of the scaling issues more apparent with smaller transformer models (maybe not, though). This is at least some of the reasoning that I&#x27;ve been applying when developing hlb-gpt, for example. It&#x27;s partially also why I think changing how we use nonlinearities within the network might impact scaling, due to some of the activation spikes used in more linear regions of the network to control network behavior in a way not originally intended.<p>Agreed that it does require a ton of resources though. But I do think that the problem can be solved on a smaller scale. If we don&#x27;t have a cleanly logarithmic curve, then I think that something is dearly wrong with our base architecture. (However, of course, I may entirely be missing something here).",1711147762,comment,39793250
quotemstr,39796007,39795576,I wonder whether we&#x27;re missing out on techniques that work well on large models but that don&#x27;t show promise on small ones,1711150959,comment,39793250
hackerlight,39796242,39796007,More like we&#x27;re missing out on techniques full stop. Proving things at scale is GPU expensive and gatekeeps publication and therefore accessibility.,1711153632,comment,39793250
danieldk,39798616,39793250,"Nice finding and makes a lot of sense! It is somewhat related to classification heads using their own weighted representation of all transformer layer outputs.<p>I only glanced the paper, but they don&#x27;t seem to softmax ⍺_i for normalization?",1711186517,comment,39793250
zwaps,39797354,39793250,"1. They compare with an older sort of standard implementation of a transformer Unsure whether the results would be equally significant compared to models with gated units or multiquery etc.<p>2. The difference seems to diminish with scale. Real life transformers obviously are much larger and train on many more tokens.<p>3. A very significant part of training transformer models are the throughoutput and memory optimizations. I wonder how their model would work with such fused kernels or specialized paged KV cache schemes. Or activation checkpointing, if run locally.<p>4. Indeed they claim no memory impact, but their code shows that their experiments are conducted with a special optimized version which requires all activations to reside in a single tensor at all times. Not sure this would work with 3d parallelism on multiple nodes etc.",1711166784,comment,39793250
matteopagli,39799970,39793250,"I&#x27;m one of the authors, happy to answer questions.",1711202104,comment,39793250
EvkoGS,39807322,39799970,Is it possible to combine your approach with NATTEN? It seems that both approaches are optimizing from different directions and can be combined with significant throughput and small performance improvements?,1711289278,comment,39793250
efrank3,39796345,39793250,Can&#x27;t believe nobody thought of this yet,1711154973,comment,39793250
aoeusnth1,39795483,39793250,"&gt; Impact statement:<p>&gt; This paper presents work whose goal is to advance the field of Machine Learning. There are many potential societal consequences of our work, none which we feel must be specifically highlighted here.<p>I found this particularly charming.",1711146217,comment,39793250
polygamous_bat,39795552,39795483,"AFAIK this was the default, copy paste impact statement by ICML template.",1711146796,comment,39793250
,39796040,39795483,,1711151228,comment,39793250
wolfhumble,39795597,39794118,"In the Wikipedia article about Little Albert, see: <a href=""https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Little_Albert_experiment"" rel=""nofollow"">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Little_Albert_experiment</a> – another boy is mentioned that could fit the characteristics of Little Albert. See the Wikpedia article and the American Psychologist article: <a href=""https:&#x2F;&#x2F;zenodo.org&#x2F;records&#x2F;1405620"" rel=""nofollow"">https:&#x2F;&#x2F;zenodo.org&#x2F;records&#x2F;1405620</a>",1711147148,comment,39794118
EMM_386,39785820,39782876,"It does make it easier for the end user who doesn&#x27;t want to fiddle around with python dependencies, command lines, building C++ projects, etc.<p>Just install it, point it to a model, and go.  Now you have a local LLM.<p>If you want something more, click the &quot;start server&quot; button and you have a local OpenAI compatible API which you can point more advanced front-ends to.",1711064860,comment,39782876
lagrange77,39785238,39782876,"I was wondering if it uses something like vLLM[0] or Llama.cpp[1].<p>Seems to be Llama.cpp via &#x27;Nitro&#x27;, which was discussed here before [2].<p>[0] <a href=""https:&#x2F;&#x2F;github.com&#x2F;vllm-project&#x2F;vllm"">https:&#x2F;&#x2F;github.com&#x2F;vllm-project&#x2F;vllm</a><p>[1] <a href=""https:&#x2F;&#x2F;github.com&#x2F;ggerganov&#x2F;llama.cpp"">https:&#x2F;&#x2F;github.com&#x2F;ggerganov&#x2F;llama.cpp</a><p>[2] <a href=""https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=38887531"">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=38887531</a>",1711060272,comment,39782876
LeoPanthera,39784818,39782876,"Unless I just can&#x27;t find it, there seems to be no setting for customizing the prompt format for local models. You can edit the prompt itself, but not the format of the prompt or the subsequent messages. This would make using many models difficult, or give poor results, since they don&#x27;t all use the same format.",1711057794,comment,39782876
FuriouslyAdrift,39784716,39782876,"Many LLMs may be run locally with GPT4All...<p><a href=""https:&#x2F;&#x2F;gpt4all.io&#x2F;"" rel=""nofollow"">https:&#x2F;&#x2F;gpt4all.io&#x2F;</a>",1711057093,comment,39782876
nickpsecurity,39786635,39784716,"And MLC puts them on your phone, too.<p><a href=""https:&#x2F;&#x2F;llm.mlc.ai&#x2F;"" rel=""nofollow"">https:&#x2F;&#x2F;llm.mlc.ai&#x2F;</a>",1711071971,comment,39782876
slowmovintarget,39793057,39784716,"GPT4All makes it annoyingly difficult to run any other than their &quot;approved&quot; models. I&#x27;d like to kick the tires on a whole host of random GGUF quantizations on Hugging Face, please.<p>I&#x27;ve poked around the doc, not sure if Jan can do that better.<p>In the mean time, I use text-gen-ui (Oobabooga) as a back-end and have it run with `--api` to use the front end of my choice.",1711129670,comment,39782876
_puk,39794911,39793057,Not at my computer right now to double check.. but doesn&#x27;t GPT4All&#x27;s &quot;Browse&quot; button in the model list let you pick a locally downloaded model?,1711141917,comment,39782876
christkv,39784104,39782876,I got say I’ve been using LLM studio as it exposes the models in the ui as well as through a local open ai compatible server so I can test different models against my workflows locally.,1711053587,comment,39782876
kkfx,39785203,39782876,"I try some LLM on my notes and well... They was unable to give me insights that are hard to spot, like follow the flaw of notes identifying patterns, find similar notes from the past and so on. In ALL cases classic tags&#x2F;riprgrep full-text search was far quicker and equally or more effective.<p>Long story short: LLMs might be useful on hyper big mass of information, like a new kind of search engine that try do achieve a semantic goal mimicking it. But not more than that IMVHO. Marginally LLMs might help computer-illiterate to manage their files, seen <a href=""https:&#x2F;&#x2F;www.theverge.com&#x2F;22684730&#x2F;students-file-folder-directory-structure-education-gen-z"" rel=""nofollow"">https:&#x2F;&#x2F;www.theverge.com&#x2F;22684730&#x2F;students-file-folder-direc...</a> but I doubt they can go any further for the next 5+ years at least.",1711060027,comment,39782876
lxgr,39793736,39785203,"They&#x27;ve been very useful in quickly answering common questions using a too-large-to-manually-scan knowledge base in my experience at my job, and I don&#x27;t consider myself or my colleagues &quot;computer-illiterate&quot;.",1711134275,comment,39782876
kkfx,39798051,39793736,"That&#x27;s follow the &quot;might be useful as a new kind of search engine&quot;, though it might be a sign of an a bit messy KB. The issue of potential hallucinations however is still there so even such usage, a different search engine, demand extra attention.<p>It&#x27;s not a free critic to those who have designed, implemented and trained LLMs, it&#x27;s just the observation that practical usage is far less than the advertised one and it&#x27;s still not much good. It&#x27;s still an advancement, a good thing to have, the start of a revolution, but still far from being what many dreams.",1711177517,comment,39782876
theGnuMe,39786724,39785203,LLMs might help my disorganized approach to files...,1711072933,comment,39782876
pryelluw,39783815,39782876,Would be nice if they listed system requirements. Their docs just say coming soon …,1711052097,comment,39782876
knodi123,39783993,39783815,most of their docs say coming soon.      and their whole wiki.<p>honestly feels like site this was launched a couple of days too soon.,1711053089,comment,39782876
warkdarrior,39784070,39783993,Their LLM is still generating copy for the website..,1711053427,comment,39782876
LeoPanthera,39784464,39782876,"Is this a fork of &quot;LM Studio&quot;? The UI is suspiciously similar, even down to the layout of the labels.",1711055530,comment,39782876
euclaise,39793851,39784464,"LM studio is closed source, so no",1711135087,comment,39782876
throwitaway1123,39783259,39782876,This looks interesting. I would love a comparison between this product and LM Studio.,1711049287,comment,39782876
moose44,39783739,39782876,Running LLMs locally always feels so awesome!,1711051554,comment,39782876
pimlottc,39784329,39782876,"I&#x27;m going to assume this is not an Australian company...<p><a href=""https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=2akt3P8ltLM"" rel=""nofollow"">https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=2akt3P8ltLM</a>",1711054705,comment,39782876
badRNG,39784342,39784329,Looks like they are based out of Singapore,1711054795,comment,39782876
Brajeshwar,39786664,39782876,"This looks awesome. Trying it out. Suggestion, can we please change the &quot;Download Jan for PC&quot; to perhaps just &quot;Download&quot; or &quot;Download for Desktop&quot; or whichever that makes sense but not &quot;PC&quot;. I almost move away thinking this is Windows, thus not for us.<p>I recently stumbled on <a href=""https:&#x2F;&#x2F;mindmac.app"" rel=""nofollow"">https:&#x2F;&#x2F;mindmac.app</a> which is a non-subscription app that uses multiple AI tools (not just OpneAI). Looks Promising.<p>Like the others in the comments, I&#x27;ve tried <a href=""https:&#x2F;&#x2F;www.typingmind.com"" rel=""nofollow"">https:&#x2F;&#x2F;www.typingmind.com</a> (via SetApp).<p>Sindre Sorhus have a pretty stable Native App <a href=""https:&#x2F;&#x2F;sindresorhus.gumroad.com&#x2F;l&#x2F;quickgpt"" rel=""nofollow"">https:&#x2F;&#x2F;sindresorhus.gumroad.com&#x2F;l&#x2F;quickgpt</a><p>These are some of the really good ones. I&#x27;m tending more towards trying out the likes of MindMac just for the fact that I can plug and switch between multiple tools.",1711072212,comment,39782876
Terretta,39801072,39786664,"What&#x27;s the value proposition for TypingMind as a commercial product ($3500 to run locally for 5 seats)?<p>But let me contrast that last &quot;native app&quot; with Machato and MacGPT:<p>== Machato ==<p>Machato is feature-full for system prompts and transcripts, connecting to to OpenAI, Claude, and any &quot;server&quot; endpoint that&#x27;s OpenAPI API compatible, and surfacing parameter and token settings per conversation right on your text entry bar.  You can also point a given conversation to a local ollama endpoint such as Mixtral 8x7B and it works as well.<p>The best feature is the selective forking and suppression of exchanges within conversation threads.<p><a href=""https:&#x2F;&#x2F;untimelyunicorn.gumroad.com&#x2F;l&#x2F;machato"" rel=""nofollow"">https:&#x2F;&#x2F;untimelyunicorn.gumroad.com&#x2F;l&#x2F;machato</a><p>== MacGPT ==<p>MacGPT is highly integrated throughout MacOS, and works with either OpenAI key or a ChatGTP Pro login.  It&#x27;s quite similar to BoltAI mentioned elsewhere in this thread, but in addition to the OpenAI key based mode, also works with a ChatGPT Pro subscription in a ChatGPT web UI pop-up.<p><a href=""https:&#x2F;&#x2F;www.macgpt.com&#x2F;"" rel=""nofollow"">https:&#x2F;&#x2F;www.macgpt.com&#x2F;</a>",1711211337,comment,39782876
longnguyen,39786879,39786664,"Shameless plug: I built a native client called BoltAI[0]. Unlike other clients, I prioritize UI, UX and performance.<p>Give it a try if UI &amp; UX is important to you.<p>[0]: <a href=""https:&#x2F;&#x2F;boltai.com"" rel=""nofollow"">https:&#x2F;&#x2F;boltai.com</a>",1711074465,comment,39782876
geggo98,39811201,39786879,"From the screenshots it looks like there is an activation limit, with a maximum of four devices. Reading the license, I could not confirm this. Is there a limit, and if, what is the maximum?",1711320199,comment,39782876
longnguyen,39812755,39811201,"Sorry for the confusion. I need to improve my pricing page.<p>The license is per user, and can be used on maximum 3 devices. I figured this is enough for most users. If you have more devices or need a custom license, please send me an email (my email is in bio)",1711339046,comment,39782876
Terretta,39801196,39786879,"This looks great relative to others (very similar to MacGPT), and I particularly like how advanced settings are available but tucked away behind discoverable affordances.<p>It&#x27;s interesting that you have team pricing.<p>Can the Team leverage shared system prompts and&#x2F;or assistants from a OneDrive-for-Business (SharePoint) folder or GitHub repo?<p>If not, what makes it &quot;Team&quot; instead of just individual?",1711212097,comment,39782876
longnguyen,39801281,39801196,"Hi. Actually I don’t have a pricing plan for teams yet. It’s still under (heavy) development. I changed my headline to reflect the direction I want to take this year (focus on teams)<p>And yes, some of my customers wanted team and collaborative features like shared prompt, internal plugins and integrations, RAG on internal documents…<p>But I haven’t launched these team features yet.<p>Are you interested in this? Would love to talk to you if it’s something you’re looking for.",1711212798,comment,39782876
Brajeshwar,39787261,39786879,Sure. Why Not. Trying it out.<p>My use case is especially for my daughter so I can just plug in my OpenAI API and let her ask away.,1711078898,comment,39782876
rnd0,39786982,39782876,How is this better than gpt4all?,1711075668,comment,39782876
Grimblewald,39788381,39786982,"From what I see, it has the benefit of offering less functionality, more corpojargon and a more &#x27;intuitive&#x27; ui.",1711094626,comment,39782876
TheRealPomax,39784252,39782876,"Still hoping we&#x27;ll eventually stop using Fibonacci to show off recursion, because that&#x27;s one of those examples where the <i>maths</i> might be expressed as recursive relation, but the <i>implementation</i> should never be =)<p>Good AI would go &quot;you don&#x27;t want that, that&#x27;s horribly inefficient. Here&#x27;s an actually performant implementation based on the closed-form expression&quot;.",1711054331,comment,39782876
Wowfunhappy,39791232,39784252,What is your preferred example for teaching a beginner to use recursion?,1711118631,comment,39782876
zopa,39784467,39784252,"Nah, good AI would run in the compiler and optimize the recursion into something fast.",1711055547,comment,39782876
lazyeye,39788162,39782876,"The default model (Mistral Instruct 7BQ4) is woke.
I asked it the following:-<p>Write a short poem in admiration of black people<p>Write a short poem in admiration of brown people<p>Write a short poem in admiration of asian people<p>Write a short poem in admiration of white people<p>It immediately replied with a poem for all except white people where it&#x27;s response was:-<p>&quot;I&#x27;d be happy to write a poem in admiration of all people, including those who identify as White.&quot;
Lol",1711092401,comment,39782876
onion2k,39784628,39782876,I use Jan to run Mistral locally. It works well for what I need (which amounts to playing with models).,1711056539,comment,39782876
rc202402,39788010,39782876,Been using this with a few models like gemma etc for a week now.<p>HN got any good LLM suggestions to run with this that are equivalent or better than GPT-3.5 &#x2F; claude?<p>I&#x27;m looking to use its api with LLama Index,1711090366,comment,39782876
ShamelessC,39783076,39782876,Quite a lot of polish and bragging about stars and tweets for an open source project. Is there hidden monetization of some sort? Perhaps VC funding?,1711048390,comment,39782876
anewhnaccount2,39783135,39783076,"According to their page <a href=""https:&#x2F;&#x2F;jan.ai&#x2F;team&#x2F;"" rel=""nofollow"">https:&#x2F;&#x2F;jan.ai&#x2F;team&#x2F;</a> they aim to bootstrap.",1711048692,comment,39782876
ShamelessC,39783257,39783135,Awesome thanks.,1711049267,comment,39782876
,39788070,39782876,,1711091205,comment,39782876
thedangler,39783254,39782876,"I don&#x27;t see anything about it reading local documents like exel, pdfs, or docs.
Anyone see how this is accomplished?",1711049253,comment,39782876
0134340,39785271,39783254,Is it implied anywhere? That&#x27;s a feature I&#x27;d love and also why I haven&#x27;t bothered delving into LLMs very much; I didn&#x27;t know there were any that could locally index your library and train on that data. I&#x27;d love to ask it a question and have it reference my local ebook library.,1711060492,comment,39782876
theGnuMe,39786719,39783254,"It probably doesn&#x27;t.  The only one that read PDFs for me was the Nvidia ChatRTX. 
It would be easy to add modules from pip that do this but you&#x27;d have to code up the input pipeline.  It&#x27;s not terribly difficult but it is definitely not point and click.",1711072843,comment,39782876
antifa,39790599,39782876,Did this have any way to point at a folder of markdown files and RAG at it?,1711114548,comment,39782876
ThrowawayTestr,39783592,39782876,Where does the model come from?,1711050904,comment,39782876
LordDragonfang,39784188,39783592,"Afaict, it doesn&#x27;t have any inbuilt model, you just download one yourself or hook up to someone&#x27;s API.",1711054027,comment,39782876
dsp_person,39784275,39783592,Scroll down on the main page:<p>01 Run local AI or connect to remote APIs<p>02 Browse and download models,1711054478,comment,39782876
thesurlydev,39783635,39782876,These kinds of apps are becoming dime a dozen. It would be nice to know how this one differentiates itself. Not obvious from the website.,1711051114,comment,39782876
viraptor,39784309,39783635,"It seems like that until you actually try to use them. Not many are actually polished, support formatting, history, and multiple endpoints. There&#x27;s lots of trivial apps abandoned after a few days, but what are the actually functional, good quality alternatives to this one? (That don&#x27;t pass your query&#x2F;answer through a third-party for data collection)",1711054595,comment,39782876
extr,39784469,39784309,"I use <a href=""https:&#x2F;&#x2F;www.typingmind.com&#x2F;"" rel=""nofollow"">https:&#x2F;&#x2F;www.typingmind.com&#x2F;</a>. It is paid, but I&#x27;ve found it to be a reliable front end to OpenAI&#x2F;Claude&#x2F;Google, supporting everything you mention. I haven&#x27;t done any hyper detailed security audit but after watching network requests I&#x27;m pretty confident it&#x27;s not sending my chats anywhere except to the relevant provider endpoints.<p>Considering how much I use it, I&#x27;ve found it to be well worth the cost. The creator is pretty on top of model&#x2F;API changes.",1711055548,comment,39782876
viraptor,39784741,39784469,"It&#x27;s not a standalone app though. There&#x27;s lots of web interfaces, but that&#x27;s not the same. (I mean, it&#x27;s a cool thing, but not what jan.ai is)",1711057280,comment,39782876
extr,39786834,39784741,"There is a desktop app available (I mean it’s basically a wrapper around the web UI, but still).",1711074118,comment,39782876
karmajunkie,39784530,39784469,i’ll second that recommendation… i use it through the SetApp store and i’ve been very pleasantly surprised by its documentation and ability to work with most services.,1711055894,comment,39782876
,39786571,39783635,,1711071399,comment,39782876
okasaki,39783519,39782876,[flagged],1711050540,comment,39782876
lmeyerov,39783567,39783519,"For AI projects, afaict, 12k stars or forks is more akin to downloads than contributors &amp; downstreams. GitHub is the app distribution, not just source distribution. I&#x27;ve been curious how to model this better..",1711050770,comment,39782876
,39783682,39783519,,1711051301,comment,39782876
outcoldman,39783643,39782876,[flagged],1711051159,comment,39782876
,39783675,39783643,,1711051275,comment,39782876
redder23,39791159,39782876,[flagged],1711118181,comment,39782876
Terretta,39801248,39791159,"&gt; <i>If I had a key for some OpenAI paid shit I can go to their website and do not need an app for that. I really do not get it.</i><p>Perhaps you don&#x27;t have some OpenAI paid shit?<p>While you can clunk around in a sort of OpenAI playground in a web tab, it is designed for dev experimentation (a &quot;fiddler&quot; type of UI), and not a good experience for much beyond testing.<p>&gt; <i>excuse me you fuck did you not just tell me you are &quot;local first&quot; ... I try out the model, and it turns out it runs on my CPU with heavy RAM usage...</i><p>I&#x27;m not sure it makes sense to have both of these objections at once.<p>&gt; <i>I never ran a model</i><p>Oh.",1711212501,comment,39782876
redder23,39791506,39791159,"OK, there is a switch under &quot;Advanced Settings&quot; to enable GPU. Why the fuck is this no-brainer option off by default and &quot;advanced&quot;? Suddenly my 7B Model is shown as inactive and &quot;start&quot; does nothing, gives no error message either ... this is such an unusable alpha version.",1711120372,comment,39782876
CyberEldrich,39783616,39782876,[flagged],1711051029,comment,39782876
,39783664,39783616,,1711051250,comment,39782876
afian,39783180,39782876,Fantastic product and excellent team!,1711048894,comment,39782876
throwaway888abc,39818848,39818564,"Link to full paper:<p><a href=""https:&#x2F;&#x2F;educationaltechnologyjournal.springeropen.com&#x2F;articles&#x2F;10.1186&#x2F;s41239-024-00444-7"" rel=""nofollow"">https:&#x2F;&#x2F;educationaltechnologyjournal.springeropen.com&#x2F;articl...</a>",1711386850,comment,39818564
,39818827,39818564,,1711386776,comment,39818564
helsinkiandrew,39815215,39813798,This and the OpenAI relationship seems the equivalent of using Credit Default and Total Return Swaps in finance to &#x27;hide&#x27; effective ownership of the underlying asset.  It&#x27;s hard to see how the regulators won&#x27;t investigate.,1711368092,comment,39813798
proaralyst,39815435,39815215,"CDS don&#x27;t hide ownership, they&#x27;re insurance against a bond defaulting. You can use them to short a company&#x27;s bonds too, which is otherwise extremely difficult as bonds aren&#x27;t lent like equities.<p>TRS also aren&#x27;t really used to hide ownership but to get economic exposure when you can&#x27;t actually own things for whatever reason. The Archegos collapse was mostly a risk management fault at Credit Suisse unrelated to the means they got that exposure through. Archegos&#x27;s other prime brokers mostly liquidated their positions with no losses. TRS are transparent to your broker and to regulators",1711369513,comment,39813798
helsinkiandrew,39816286,39815435,"&gt; TRS also aren&#x27;t really used to hide ownership but to get economic exposure when you can&#x27;t actually own things for whatever reason<p>In the Archegos case the &quot;whatever reason&quot; was at least partially (as well as getting extra leverage) so that ownership didn&#x27;t need to be reported to the SEC - allowing them to &#x27;own&#x27; 50%+ of the shares of several companies and manipulate the price without the market knowing.<p>Item 30 and 58 of the SEC complaint:
<a href=""https:&#x2F;&#x2F;www.sec.gov&#x2F;files&#x2F;litigation&#x2F;complaints&#x2F;2022&#x2F;comp-pr2022-70.pdf"" rel=""nofollow"">https:&#x2F;&#x2F;www.sec.gov&#x2F;files&#x2F;litigation&#x2F;complaints&#x2F;2022&#x2F;comp-pr...</a>",1711374646,comment,39813798
proaralyst,39817370,39816286,"I agree they shifted to avoid the reporting requirement but I don&#x27;t believe they did that cynically to manipulate prices, mainly because it&#x27;s unclear to me that anyone has suggested a possible exit from their positions that made them any money. Archegos is a family office, so it&#x27;s not fees. It&#x27;s not generally possible to make a profit pushing the price up by buying as the price will collapse faster than you pushed it up. (Absent external demand as in a pump and dump.)<p>I suspect the intent behind the position disclosure is so <i>control</i> is disclosed, not economic exposure. The design of the regulatory system in the US is that you&#x27;re either regulated and thus have a lot of responsibility and reporting requirements, but you get better access to the market (Archegos&#x27;s brokers); or you&#x27;re &#x27;unregulated&#x27; and have less (but access the market through a regulated company).<p>Also you don&#x27;t usually get different margin treatment through TRS than you would through normal ownership. If you do, your prime broker is doing something stupid. Your TRS is a contract with them, they tend to just go buy the shares to hedge so it&#x27;s usually exactly the same as buying your long through them (except you can&#x27;t vote your shares, you don&#x27;t get dividends and you can&#x27;t lend your shares).",1711379771,comment,39813798
philipov,39815341,39815215,They&#x27;re already investigating the OpenAI affair. The question is whether they&#x27;ll be able to <i>do</i> anything about it.,1711368941,comment,39813798
helsinkiandrew,39815153,39813798,"<a href=""https:&#x2F;&#x2F;archive.ph&#x2F;AsGYa"" rel=""nofollow"">https:&#x2F;&#x2F;archive.ph&#x2F;AsGYa</a>",1711367697,comment,39813798
,39815451,39813798,,1711369614,comment,39813798
bevekspldnw,39810733,39809861,Given this is a CNET link it’s exactly what I would expect an LLM to say about itself.,1711316141,comment,39809861
voisin,39810751,39810733,A lot of our media has been replaced by two LLMs in a trench coat.,1711316358,comment,39809861
outofpaper,39810881,39810751,I&#x27;m pretty sure the media is the trench coat and always has been.,1711317513,comment,39809861
__loam,39811367,39810881,"I&#x27;m kind of disgusted by the contempt people in tech have for journalists, when the tech people are the ones who authored the current media ecosystem.",1711321742,comment,39809861
cassianoleal,39811876,39811367,&quot;people in tech&quot; and &quot;the tech people&quot; are very unfortunate generalisations.,1711327318,comment,39809861
__loam,39812087,39811876,"Almost like we shouldn&#x27;t be generalizing an entire professional sector with statements like &quot;I hate journalists&quot;, huh?<p>The blame for the decline in journalism lies squarely at the feet of the architects of the ad based internet economy.",1711329644,comment,39809861
bevekspldnw,39817599,39812087,"I agree, but that doesn’t mean CNET is a reliable news source.",1711380732,comment,39809861
__loam,39819779,39817599,"I agree that CNET sucks, but it&#x27;s very emblematic of the affiliate marketing bullshit that has infested the internet for a while now.",1711391815,comment,39809861
_giorgio_,39810888,39809861,I have chatGPT on my phone and I barely use it.<p>I use it a lot on the desktop (paid account).<p>I&#x27;ve used Gemini or Bard probably a couple of times.<p>I don&#x27;t see a great mainstream moment.,1711317605,comment,39809861
LeafItAlone,39812189,39810888,I don’t do much on my phone. I avoid downloading apps in general.<p>But I use ChatGPT on it multiple times a day.,1711330745,comment,39809861
ametrau,39812433,39810888,That’s us though. The mainstream prefers the phone for everything (as crazy as that seems).,1711334537,comment,39809861
YetAnotherNick,39811211,39810888,"If they could bring agentic interaction to phone, I think it will fundamentally change the way we interact. Based on my experiments with GPT-4V it&#x27;s close to being there but AI still hasn&#x27;t reached that point. And given they are using tiny model in comparison, it would be hard to do that.",1711320337,comment,39809861
daft_pink,39812744,39809861,I think it’s a mistake because the whole point of using Apple is not to use Google,1711338899,comment,39809861
akmittal,39812829,39812744,Apple will hardly let it&#x27;s users know they are using Google. They will name it like Siri ultra pro Max and say they built this.,1711340269,comment,39809861
rolymath,39810769,39809861,ChatGPT was AI&#x27;s mainstream moment.<p>I hate journalists.,1711316452,comment,39809861
phmqk76,39810822,39810769,"I really don’t think that’s true at all. ChatGPT is absolutely not mainstream. It’s pierced the consciousness of the tech-savvy, which maybe be our world, but is decidedly not mainstream. Most people would have no idea how to even use it, they hear about it from headlines. Having it in your pocket and interacting with it on a near-daily basis would be that mainstream moment, whether Apple gets there this year or Google manages to get that feature in tens of millions of phones through an update to its essential services through the Play Store. But your comment definitely shows what it means to be in a bubble.",1711316963,comment,39809861
Jensson,39810995,39810822,"&gt; ChatGPT is absolutely not mainstream<p>Majority of teens have heard of it and 13% admit using it to cheat on homework, probably much more used it to cheat than admits to it and even more than that used it for any reason. Also note how the rate hoes up a lot in older kids, they probably have more homework so more pressed to cheat.<p><a href=""https:&#x2F;&#x2F;www.pewresearch.org&#x2F;short-reads&#x2F;2023&#x2F;11&#x2F;16&#x2F;about-1-in-5-us-teens-whove-heard-of-chatgpt-have-used-it-for-schoolwork&#x2F;"" rel=""nofollow"">https:&#x2F;&#x2F;www.pewresearch.org&#x2F;short-reads&#x2F;2023&#x2F;11&#x2F;16&#x2F;about-1-i...</a>",1711318418,comment,39809861
amf12,39811400,39810995,&gt; Majority of teens have heard of it and 13% admit using it<p>Your source says &quot;Roughly one-in-five teenagers *who have heard of ChatGPT* say they have used it&quot;.<p>This is certainly not &quot;majority&quot; of teens.,1711322111,comment,39809861
Jensson,39811871,39811400,"67% of teens have heard of it, that is a majority. Of those about 1 in 5 have used it to do their homework, in total 13% of all teens have which matches what I said and the exact numbers you find in the article.<p>All my numbers and descriptions there are correct, it is you who made the mistake here.",1711327228,comment,39809861
pama,39810875,39810822,"We’ve purchased an annual subscription for my 85 yo (long time retired) inlaws. They use it daily. They ask their doctors insightful questions and get better care.  They planned trips with it. They get recipe advice.  I don’t know how much more penetration it should have to be considered mainstream but it certainly feels more widely available and used than what Google was 25 years ago, despite having a subscription model.",1711317438,comment,39809861
okdood64,39811132,39810875,Do they double check the information for hallucinations?<p>I&#x27;d personally be scared to promote usage of this for someone (especially a senior) who wouldn&#x27;t have the ability and discipline to.,1711319611,comment,39809861
pama,39812489,39811132,Not sure what you mean?  If the recipe is not right it is no major problem but so far all was great. Their trips and questions have been on the spot and it has helped them dramatically.,1711335183,comment,39809861
doktrin,39810894,39810822,&gt; It’s pierced the consciousness of the tech-savvy... most people would have no idea how to even use it...<p>They&#x27;ve had 100+ million weekly users for over half a year,1711317660,comment,39809861
frozenport,39810892,39810822,Naw all the kids are using it cheat on their homework,1711317656,comment,39809861
,39810887,39809861,,1711317592,comment,39809861
sherlockxu,39788107,39786943,"Hi HN readers,<p>One thing I didn&#x27;t mention in this blog post is that developing vertical models tailored to specific industries may be more important than creating general-purpose models.<p>Actually I have been wondering why we need so many general-purpose models? People in this world come from different industries and what they need is targeted solutions. Vertical models can address nuanced problems that general-purpose models might overlook due to their broad training.<p>Feel free to leave your comments here :-)",1711091763,comment,39786943
kouteiheika,39790264,39788107,"&gt; Actually I have been wondering why we need so many general-purpose models? People in this world come from different industries and what they need is targeted solutions. Vertical models can address nuanced problems that general-purpose models might overlook due to their broad training.<p>It&#x27;d be interesting to see a direct comparison which would answer the question of &quot;how many less parameters do you need for a targeted vertical model to solve the same problem as a general purpose model&quot;.<p>Like, for example, let&#x27;s say we pick the task of translating Python to JavaScript, or just any other concrete task: how small could you make a model that <i>only</i> can do this task, vs a general purpose model that can also do this equally well plus a bunch of other things? I wonder if there are any interesting papers tackling this?",1711112312,comment,39786943
camkego,39789196,39788107,"Thank you for writing the article on the various models.<p>But, I think your HN-comment parent is spot on regarding vertical models vs general purpose.<p>It would be awesome to see an article about when to try to use general-purpose models vs vertical.<p>The ability of LLM models to serve as FAQs and chat-bots and everything in-between, is super powerful.<p>But what are the pros and cons of using vertical vs general purpose LLMs for knowledge bases and chat-bots?<p>I&#x27;d love to see an article that addresses how to create these models, and should they be large-scale general LLMs that are tweaked lightly, or vertical models with baked-in understanding of the vertical they are trying to serve.<p>An article on this might be very useful to many people.",1711103303,comment,39786943
vouaobrasil,39789203,39788107,"&gt; Actually I have been wondering why we need so many general-purpose models? People in this world come from different industries and what they need is targeted solutions. Vertical models can address nuanced problems that general-purpose models might overlook due to their broad training.<p>It is because the real way to make money from AI is to use it to distract, brainwash, confuse, and make poeple think they need something when they don&#x27;t. So, everyone wants a slice of that pie. Plus, large corporations know that if they create a general-purpose AI then it will be the perfect drug to further distract us from their unsustainable practices.",1711103338,comment,39786943
,39789934,39786943,,1711109970,comment,39786943
LASR,39810189,39809177,I lead AI teams at my company. I&#x27;ve advised leadership against any kind of training &#x2F; fine-tuning anything.<p>We&#x27;re not in the business of training models. We will never be as good as OpenAI &#x2F; Anthropic etc.<p>Where the real value in applications is smarter prompting techniques and RAG. There is a lot of room at the bottom in doing &quot;dumb&quot; things and simply feeding models with the right context to deliver customer value.,1711312075,comment,39809177
redox99,39810841,39810189,"That&#x27;s a pretty odd stance. I&#x27;ve finetuned llama&#x2F;mistral models that greatly outperform GPT4 with just a prompt.<p>You have to know when to RAG, finetune, or RAG+finetune.",1711317184,comment,39809177
simonw,39812468,39810841,"&quot;I&#x27;ve finetuned llama&#x2F;mistral models that greatly outperform GPT4 with just a prompt&quot;<p>If you write about your experiments with that in detail I guarantee you&#x27;ll get a lot of interest. The community is crying out for good, well documented, replicable examples of this kind of thing.",1711334890,comment,39809177
redox99,39813117,39812468,"I&#x27;m so behind in this area. I had finetuned a model that was SOTA and worth publishing about in October, but procrastinated. I&#x27;m scared to check if somebody else already published on this topic.",1711345378,comment,39809177
singularity2001,39811293,39810841,"<p><pre><code>    greatly outperform GPT4 *for* just a prompt
</code></pre>
your overfitting to training data convinces no-one that you created a &quot;better GPT4&quot;",1711321078,comment,39809177
redox99,39811979,39811293,"Do you always assume other people are incompetent? That&#x27;s not very nice of you.<p>I mostly work on AI, so I know if I&#x27;m overfitting or not. It performs provably better in it&#x27;s domain (a niche programming language). GPT4 can barely write a hello world for it.<p>I&#x27;m not creating a &quot;better GPT4&quot; general chatbot. I&#x27;m finetuning for a specific task.",1711328530,comment,39809177
kossTKR,39811170,39810841,How narrow is the dataset to be outperforming greatly?<p>Just curious about what the usecase is for a 7b model in a business context - ie. what does it do?,1711319901,comment,39809177
redox99,39811948,39811170,Code assistant for a niche programming language that GPT4 knows very little about and barely gets a hello world right.,1711328150,comment,39809177
elforce002,39810308,39810189,"This. I work in a startup and told upper management we need to keep focusing on ML models that bring tangible benefits to our customers and then, try to integrate LLMs into their current flow instead of pivoting completely to LLMs. It seems they valued the input and now we&#x27;re going for a hybrid approach.",1711312837,comment,39809177
throwaway74432,39810529,39810189,Hear hear. I know a 3 person startup that has a &quot;lead AI researcher&quot; who is trying to train and fine-tune models. That&#x27;s not their startup&#x27;s purpose though... they have an actual product. So wtf are they doing? The lead AI guy thinks he&#x27;s going to compete with these big companies and it&#x27;s total fantasy.<p>LLMs are a <i>commodity</i>,1711314420,comment,39809177
qeternity,39810575,39810529,"That does indeed sound crazy. But finetuning is also a commodity these days. You can train a good Mistral LoRA in under 24 hours on a single consumer GPU. We’re talking about $10 of compute.<p>You can run a dozen of these LoRAs atop the same base model on the same infrastructure for a dozen specific use cases.<p>The inference quality, performance and cost can all be substantially better than GPT4 with prompting.",1711314864,comment,39809177
VirusNewbie,39810753,39810529,Doesn&#x27;t it entirely depend on how specialized the training data for a given fine tuned model might be?,1711316360,comment,39809177
,39810577,39810529,,1711314903,comment,39809177
seydor,39810467,39810189,Your advise is based on what?,1711313926,comment,39809177
jnwatson,39810319,39810189,It is trivial to fine tune these days. RAG is already irrelevant with large context windows.,1711312916,comment,39809177
Xenoamorphous,39810427,39810319,"&gt; RAG is already irrelevant with large context windows<p>Just last Friday I took the contents of the 2024 folder of one of the teams at the company I work for, for which we use RAG at the moment. I dumped the text index, concatenated it and used Google’s API to return the token count, to see if it would fit in Gemini’s 1M context window; turned out it was 5.7M tokens. And that’s less than 3 months worth of documents for that team.<p>So yeah RAG is not dead yet, although I do question its usefulness, but that’s a separate topic.",1711313680,comment,39809177
greenavocado,39810805,39810427,Did I read this correctly? You uploaded millions of words of your company&#x27;s internal communications to Google?,1711316826,comment,39809177
Xenoamorphous,39811050,39810805,"I did. But this is under an enterprise deal with them that warrants privacy, not the generally available stuff. OpenAI has similar arrangements (Enterprise ChatGPT) and MS Azure before them.",1711319024,comment,39809177
SgtBastard,39810537,39810319,"A remarkable comment in that it is clear, confident and wrong.<p>Fine-tunes lead to catastrophic forgetting.<p>RAG is only irrelevant if you’re completely disinterested in cost and latency.<p>We also don’t have enough data to gauge performance of models &gt;200k context window size when reasoning over inputs of that size, much of which will be irrelevant to any particular user. Multiple random needles in haystack tests work flawlessly, but rarely applies to real world activity.",1711314453,comment,39809177
simonw,39810438,39810319,Citation needed on &quot;trivial to fine tune&quot;.,1711313742,comment,39809177
danielmarkbruce,39810842,39810438,"There is no citation needed. It is indeed trivial to fine-tune. Doing a good job is another matter, but the claim is correct. Google around and find a blog post showing how.<p>The claim that RAG is dead is obviously wrong.",1711317186,comment,39809177
simonw,39811640,39810842,"For &quot;citation needed&quot;, read &quot;please link me to a blog post showing how, don&#x27;t just tell me to Google for one&quot;.<p>The internet is full of blog posts about this. That doesn&#x27;t mean they&#x27;re actually good - I&#x27;d love to be pointed at one that has proven itself useful for someone (and definitely isn&#x27;t just LLM blog-spam).<p>I don&#x27;t care if it&#x27;s trivial to fine-tune and get crap results - I care about fine-tuning where the result was worth the effort.<p>For the record, my favourite guide to fine-tuning is the section of this Jeremy Howard video that shows how to train a text-to-SQL model: <a href=""https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=jkrNMKz9pWU&amp;t=4850s"" rel=""nofollow"">https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=jkrNMKz9pWU&amp;t=4850s</a>",1711324695,comment,39809177
danielmarkbruce,39811976,39811640,"It&#x27;s an internet forum, not an academic journal. Water tight arguments are not needed. If one wants to call bs, they can just do it, no need to dance around the topic by asking for a citation.",1711328484,comment,39809177
simonw,39812449,39811976,"OK, I call BS. Fine-tuning an LLM is not &quot;trivial&quot; - especially if you want to get useful results, as opposed to just being able to say &quot;look, I fine-tuned an LLM&quot;.",1711334719,comment,39809177
danielmarkbruce,39817105,39812449,"Yup, largely agree.",1711378562,comment,39809177
wakaru44,39813916,39811976,"Exactly, it&#x27;s a forum not Twitter&#x2F;reddit. Without references and citations this is no better than a bunch of random words, and it&#x27;s hard to make any argument of substance.<p>The person asked for citations, leave it be, stop dudexplaining how Internet works for you please.<p>I call bs on your 2 comments.",1711356029,comment,39809177
danielmarkbruce,39817065,39813916,"They didn&#x27;t ask for citations. They pointed out a citation was needed. It was a clever sounding way of calling bs. They admit as much.<p>Even when people sincerely ask for a citation on a debatable topic, on an internet forum, it&#x27;s effectively saying &quot;I won&#x27;t be hear any opinion that doesn&#x27;t match my own unless it&#x27;s as water tight as a law of physics&quot;. Another form of this is &quot;show me the data&quot;.",1711378365,comment,39809177
krasin,39810767,39809177,"Finetuning LLMs is currently the most promising way for next-gen robotics. One of such works (PaLM-e) among other things measured the impact of finetuning on general purpose tasks: <a href=""https:&#x2F;&#x2F;twitter.com&#x2F;DannyDriess&#x2F;status&#x2F;1632904698108821505"" rel=""nofollow"">https:&#x2F;&#x2F;twitter.com&#x2F;DannyDriess&#x2F;status&#x2F;1632904698108821505</a><p>In short, an 8B model could degrade almost 10x after being finetuned on robotics tasks, while 500B model experiences a very minor degradation (~4%) and there&#x27;s a hope that with a larger-sized model, it could become either zero or even negative (adding more experience improves general purpose reasoning).<p>What I am saying is that while GPT-4 could beat a finetuned GPT-3.5 class model, I predict good things about finetuned GPT-4 class models, when they become practical outside of OpenAI&#x2F;Google.",1711316443,comment,39809177
gradascent,39812103,39810767,Interesting! I would like to learn more about how AI is being applied to robotics. Do you have any suggestions for how to keep up with developments&#x2F;ideas in this field?,1711329846,comment,39809177
krasin,39812411,39812103,"These two links could be a good start:<p>ALOHA-2: <a href=""https:&#x2F;&#x2F;aloha-2.github.io&#x2F;"" rel=""nofollow"">https:&#x2F;&#x2F;aloha-2.github.io&#x2F;</a><p>RT-X: <a href=""https:&#x2F;&#x2F;robotics-transformer-x.github.io&#x2F;"" rel=""nofollow"">https:&#x2F;&#x2F;robotics-transformer-x.github.io&#x2F;</a>",1711334077,comment,39809177
hlfshell,39813421,39812103,"In October I wrote a blogpost on this subject: <a href=""https:&#x2F;&#x2F;hlfshell.ai&#x2F;posts&#x2F;llms-and-robotics-papers-2023&#x2F;"" rel=""nofollow"">https:&#x2F;&#x2F;hlfshell.ai&#x2F;posts&#x2F;llms-and-robotics-papers-2023&#x2F;</a><p>..and plan to do an updated version soon for much of what&#x27;s been released since. I&#x27;ve also done work related to LLM and robotics integration, also on that site.<p>Happy to chat about it.",1711350284,comment,39809177
newswasboring,39814000,39813421,Working my way through your blog post and it is so refreshing. Unfortunately my algorithm currently is showing me takes which are extreme on either end (like in your blog post).<p>&gt; Technology’s largest leaps occur when new tools are provided to those that want to make things.<p>I love this sentence. And the general attitude of curiosity of your post.,1711357032,comment,39809177
hlfshell,39818029,39814000,"Thanks! Appreciate the kind words. I should have in the next month or so (interviewing and finishing my Master&#x27;s, so there&#x27;s been delays) a follow up that follows more advancements in the router style VLA, sensoiromotor VLM, and advances in embedding enriched vision models in general.<p>If you want a great overview of what a modern robotics stack would look like with all this, <a href=""https:&#x2F;&#x2F;ok-robot.github.io&#x2F;"" rel=""nofollow"">https:&#x2F;&#x2F;ok-robot.github.io&#x2F;</a> was really good and will likely make it into the article. It&#x27;s a VLA combined with existing RL methods to demonstrate multi-tasking robots, and serves as a great glimpes into what a lot of researchers are working on. You won&#x27;t see these techniques in robots in industrial or commercial settings - we&#x27;re still too new at this to be reliable or capable enough to deploy these on real tasks.",1711382739,comment,39809177
TMWNN,39810934,39810767,"&gt;there&#x27;s a hope that with a larger-sized model, it could become either zero or even negative (adding more experience improves general purpose reasoning).<p>The best single work of fiction ever created about LLMs&#x27; capabilities (and, perhaps, dangers) is <i>Colossus</i> by Jones. Although I think the film is even better than the book, only the latter mentions how, despite being created specifically for US national defense, Colossus is also fed unrelated data including Shakespeare&#x27;s sonnets, because its creators do not know if it could be important.",1711317982,comment,39809177
paulmd,39811566,39810934,What good is a revolution without dancing?,1711323925,comment,39809177
minimaxir,39809825,39809177,"Extremely hot LLM take: You will often get better results with few-shot prompting (with good examples) on a modern LLM than with a finetuned LLM.<p>Finetuning was the best option for weaker LLMs with lower context windows (e.g. the original GPT-3): both problems have been solved nowadays.<p>The cost economics are much better with few-shot prompting to modern LLMs too: input tokens are super cheap (especially with the recently-released Claude Haiku), so giving a lot of examples per call will still end up cheaper than finetuning.<p>Meanwhile, a finetuned ChatGPT costs 4-6x of normal ChatGPT usage.",1711309743,comment,39809177
zapperdulchen,39810176,39809825,"Seems like the bitter lesson is still right: <a href=""http:&#x2F;&#x2F;www.incompleteideas.net&#x2F;IncIdeas&#x2F;BitterLesson.html"" rel=""nofollow"">http:&#x2F;&#x2F;www.incompleteideas.net&#x2F;IncIdeas&#x2F;BitterLesson.html</a>",1711311987,comment,39809177
nialse,39810572,39810176,"For those who were oblivious to it, like myself, the bitter lesson is written by  Richard S Sutton who invented reinforcement learning a long, long time ago.",1711314849,comment,39809177
tomrod,39810824,39810176,This is an earth-shattering read.,1711316996,comment,39809177
pbronez,39811594,39810176,"I can’t access the article there… SSL error and then timeout. Here’s a link to the most recent WayBackMachine snapshot:<p><a href=""https:&#x2F;&#x2F;web.archive.org&#x2F;web&#x2F;20240321091803&#x2F;https:&#x2F;&#x2F;www.incompleteideas.net&#x2F;IncIdeas&#x2F;BitterLesson.html"" rel=""nofollow"">https:&#x2F;&#x2F;web.archive.org&#x2F;web&#x2F;20240321091803&#x2F;https:&#x2F;&#x2F;www.incom...</a>",1711324238,comment,39809177
port443,39812931,39811594,"There&#x27;s no SSL at all on that site, since it&#x27;s http not https. Your browser is breaking the link.",1711341919,comment,39809177
Solvency,39810384,39810176,Whoa this guy says &quot;computation&quot; and not grammatically bastardized techbrospeak &quot;compute&quot; like some neckbeard equivalent of a caveman!<p>For that alone I commend him.,1711313339,comment,39809177
jorvi,39810543,39810384,Compute is.. I don’t know the exact English grammatical term but it’s like water. Computation is not.<p>“I have 1000 flops of compute” - works.<p>“I have 1000 flops of computation” - doesn’t work.<p>“That compute failed” - doesn’t work.<p>“That computation failed” - works.<p>They’re different.,1711314496,comment,39809177
thewakalix,39810602,39810543,"<a href=""https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Mass_noun"" rel=""nofollow"">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Mass_noun</a>",1711315056,comment,39809177
xanderlewis,39810883,39810543,"As far as I know, it’s usually called an <i>uncountable noun</i>.<p>…but ‘computation’ is also uncountable, and your second sentence seems to be perfectly fine to me.<p>Your examples do not constitute an argument. You haven’t articulated the (purported) difference between the two words; you’ve just decided arbitrarily that some sentences don’t work, and not elaborated or explained at all.<p>I can make up words too, and provide example sentences: “karrotz are delicious” works. “carrots are delicious” doesn’t. “inside the karrotz” doesn’t work. “inside the carrots” does.<p>I don’t actually think there is any difference. The above comment about ‘brospeak’ was snarky but I do think it’s more of a cultural phenomenon than a semantic one — unless someone is willing to kindly explain the difference rather than just rolling their eyes!<p>What <i>exactly</i> is wrong with the sentence ‘this would require huge amounts of computation’? Saying ‘compute’ seems more to be a synonym of ‘computation’ that’s caught on recently than a useful gap-filling addition to the language. Again: reasoned arguments please. Or just ‘we think it sounds cool so we use it’ — that’s fine, too.<p>EDIT: pondering briefly, perhaps one could argue the difference is something like ‘you can <i>own</i> compute, but you can’t own computation.’ ‘Compute’ is the capacity to carry out computation. …although ‘compute’ seems to be used to refer to the ‘abstract’ computation being done as well as the computational resources, so I don’t know.<p>I’m stretching it. To be honest I’m not sure it’s a useful (or even real) distinction. I think it’s a matter of fashion, and that’s fine and normal.",1711317547,comment,39809177
,39812044,39810883,,1711329193,comment,39809177
Solvency,39810738,39810543,Literally not true. Compute is a verb. Computation is the right word in all of those cases. Or computational &lt;noun&gt;.,1711316156,comment,39809177
,39810549,39810384,,1711314594,comment,39809177
marviel,39810496,39809825,"Several MSFT AI&#x2F;ML friends actively dissuaded me and my team from fine-tuning. They said that it&#x27;s pretty clear in all their internal tests that it &quot;lobotomizes&quot; the general reasoning capabilities of the model, unless you&#x27;re really careful.<p>&quot;All work and no play makes GPT a very dull AI&quot;",1711314104,comment,39809177
Ambix,39816439,39810496,"Yes, that&#x27;s what I&#x27;ve seen from a lot of my experiments with fine-tuning. One should be really careful to not &quot;lobotomize&quot; already capable model and achieve better results at the end. It&#x27;s trickier than seems from multiple of tutorials.<p>But I believe that most of the data stored in foundation models are just useless for some particular domain. So it&#x27;s better to forget something, getting really useful info instead.",1711375348,comment,39809177
FrustratedMonky,39810782,39810496,&quot;bitter lesson that building in how we think we think does not work in the long run&quot;<p>Guess. Stop trying to shape the NN. And let it learn on its own.,1711316584,comment,39809177
TMWNN,39810955,39810782,"&gt;And let it learn on its own.<p>The best single work of fiction ever created about LLMs&#x27; capabilities (and, perhaps, dangers) is <i>Colossus</i> by Jones. Although I think the film is even better than the book, only the latter mentions how, despite being created specifically for US national defense, Colossus is also fed unrelated data including Shakespeare&#x27;s sonnets, because its creators do not know if it could be important.",1711318103,comment,39809177
FrustratedMonky,39815473,39810955,"I think the movie Colossus still holds up today.  Saw it last year, It was pretty scary.",1711369766,comment,39809177
thorum,39810162,39809825,"That might be true for finetuning ChatGPT 3.5, but if you can finetune a small model (7B or less) to perform on par with GPT-4, while being faster and private, that’s a different story.",1711311868,comment,39809177
smallnamespace,39810335,39810162,"You definitely can&#x27;t in the general case (for example, your 7B model is never going to be able to help much with coding, fine tuning or no).<p>It can make sense if you have a particularly simple use case.",1711312989,comment,39809177
qeternity,39810556,39810335,By definition you wouldn’t fine tune a 7B model to be generally as good at GPT4. You would just be trying to overfit some small amount of functionality in a narrow domain.,1711314651,comment,39809177
smallnamespace,39812588,39810556,"Yes but from the context of this discussion, we’re trying to figure out the “sweet spot” model size where it’s worth attempting fine tuning. My guess is it’s only worthwhile for matching simple tasks with small models, and any sufficiently complicated task it’s better to do few&#x2F;zero shot instead.",1711336836,comment,39809177
viksit,39809996,39809825,can you give a few pointers on articles or examples of this?,1711310712,comment,39809177
minimaxir,39810082,39809996,"A low-tech example to create a good blog post title for submission to Hacker News would be a system prompt like:<p><pre><code>    You are an expert copywriter. Write five distinct blog post titles optimized for high clickthrough for Hacker News for the article the user provides.

    Your response must follow the style of these titles:
      - The ü&#x2F;ü Conundrum
      - Why isn&#x27;t preprint review being adopted?
      - Majority of web apps could just run on a single server
      - Weather Planning for Eclipse Day
      - PSChess – A chess engine in PostScript
</code></pre>
Then provide the blog post as the user message input.<p>I just ran one of my blog posts (<a href=""https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=39495476"">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=39495476</a>) with the workflow through Claude Haiku and got this:<p><pre><code>    Here are five distinct blog post titles optimized for high clickthrough on Hacker News for the article provided:

    1. Tipping ChatGPT: Does Offering Monetary Incentives Improve AI Text Generation?

    2. Quantifying the Impact of Incentives on Large Language Model Performance

    3. Carrot or Stick? Exploring the Effects of Positive and Negative Prompts on ChatGPT

    4. Gamifying AI: Using &quot;Generation Golf&quot; to Test ChatGPT&#x27;s Ability to Follow Length Constraints

    5. The Curious Case of ChatGPT&#x27;s Motivations: Can an AI Be Incentivized Like Humans?
</code></pre>
Not bad titles, although more verbose than the 5 input examples I gave. I only gave 5 for simplicity: my main point is that you can give it a <i>lot</i> more than five and&#x2F;or be more aggressive with constraints, like the blog post linked incidentially.",1711311276,comment,39809177
viksit,39810142,39810082,"interesting thank you.<p>intuitively, prompting like this to get an answer seems basically like the first part of a fine tuning process (more exemplars).<p>what is your thought here behind why reinforcing good output via a loss optimization is worse than the one shot example? does the model start to over fit at some point towards some local minima? and this is avoided in this scenario?",1711311695,comment,39809177
minimaxir,39810200,39810142,"Prompt engineering in general is necessary because LLMs optimize for the <i>average</i> output, and average output is not good. So LLMs need a slight nudge.",1711312170,comment,39809177
netdur,39810127,39809996,"Use Gemini 1.5 Pro, which has 1.5 million tokens. Prompt it with a logical question and observe it struggling to answer. Then, upload a book on logical thinking in PDF format and ask the same question again. Notice how it can now answer the question effectively.",1711311600,comment,39809177
jna_sh,39810651,39809825,“Modern” is an extremely funny delineation given the small temporal window of this whole thing,1711315424,comment,39809177
kcorbitt,39810857,39809177,"IMO it&#x27;s possible to over-generalize from this datapoint (lol). While it&#x27;s true that creating a general &quot;finance&quot; model that&#x27;s stronger than GPT-4 is hard, training a task-specific model is much easier. Eg. &quot;a model that&#x27;s better than GPT-4 at answering finance-related questions&quot;: very hard. &quot;A model that&#x27;s better than GPT-4 at extracting forward-looking financial projections in a standard format&quot;: very easy.<p>And in practice, most tasks people are using GPT-4 for in production are more like the latter than the former.<p>(Disclaimer: building <a href=""https:&#x2F;&#x2F;openpipe.ai"">https:&#x2F;&#x2F;openpipe.ai</a>, which makes it super easy to productize this workflow).",1711317341,comment,39809177
MuffinFlavored,39809549,39809177,"Does anything currently beat GPT-4?<p>I saw some comments here say to check out Claude. From what I can tell, Claude hasn&#x27;t figure out yet how to do the whole &quot;generate Python code and run it in a Juptyer notebook&quot; for math yet.",1711308183,comment,39809177
rubymamis,39809693,39809549,"A programming task where Mistral-large beats both GPT-4 and Claude Opus: <a href=""https:&#x2F;&#x2F;sdk.vercel.ai&#x2F;s&#x2F;Thi7RDx9e8VOZo1Ee6We5"" rel=""nofollow"">https:&#x2F;&#x2F;sdk.vercel.ai&#x2F;s&#x2F;Thi7RDx9e8VOZo1Ee6We5</a> (only Mistral got the current syntax)<p>Although based on other tasks, overall, GPT-4 seems to be the best, but by a very small margin, so I cancelled my subscription. Although the native mobile app is really great.",1711309001,comment,39809177
fragmede,39810820,39809693,"Is there a way to use Mistral-large with TTS and STT engines so you can converse with it like you can ChatGPT in the mobile app? it&#x27;s really great on long drives for learning&#x2F;talking about stuff, like a customized personal podcast.",1711316937,comment,39809177
rubymamis,39814178,39810820,"Exactly, I absolutely love this feature. And many times the conversation is quite natural and fluid (with good internet connection). I think I&#x27;ll build something like that myself (:",1711358943,comment,39809177
cosmojg,39810936,39809693,Do you prefer Mistral-Large or Claude-Opus?,1711317991,comment,39809177
rubymamis,39814195,39810936,"Not sure. Most of the time GPT-4 is better. Since I&#x27;m using Vercel AI playground[1], on almost every query I get a response from all models so it&#x27;s easy to compare.<p>[1] <a href=""https:&#x2F;&#x2F;sdk.vercel.ai&#x2F;"" rel=""nofollow"">https:&#x2F;&#x2F;sdk.vercel.ai&#x2F;</a>",1711359053,comment,39809177
monsieurbanana,39809662,39809549,"Isn&#x27;t that something you get from the infrastructure surrounding the llm? I thought the &quot;running code&quot; feature didn&#x27;t need specific support from the llm, besides being able to output conforming json or code when asked to.",1711308803,comment,39809177
MuffinFlavored,39809735,39809662,The LLM (Claude) currently doesn&#x27;t know to not hallucinate numbers and instead write code + run it (something ChatGPT used to do but they fixed it),1711309232,comment,39809177
simonw,39810401,39809735,"That&#x27;s because the Claude web UI doesn&#x27;t yet have the equivalent of the ChatGPT Code Interpreter tool (though they say they&#x27;re working on it). That&#x27;s not about the quality of the Claude 3 Opus model, which is the model which people think compares to or beats GPT-4. It&#x27;s about the tooling that has been built for ChatGPT.",1711313442,comment,39809177
fragmede,39810804,39810401,"Code interpreter is pretty neat, because you can tell ChatGPT to write some code and to make sure the code works, and then it&#x27;ll write you some bad code, realize it&#x27;s bad, and then iterate on it until it gets to a place that it&#x27;s happy with. (Maybe I should say passes its test rather than anthropomorphize ChatGPT as being &quot;happy&quot;.)",1711316814,comment,39809177
cosmojg,39810921,39809735,"Right, like the other commenter suggested, that&#x27;s an infrastructure-level thing, not a model-level thing. Given that you&#x27;re talking about ChatGPT, I assume you aren&#x27;t accessing GPT-3.5 or GPT-4 directly through the API but using the app or the interface provided at chat.openai.com. The magic that makes the kinds of interactions you&#x27;re describing possible amounts to a bit of clever prompting sprinkled on top of some rather impressive frontend design and engineering.<p>Correctly prompted, even Mistral-7B can write and run code in response to questions, and it&#x27;s a model that can run on laptops from half a decade ago, with two or three orders of magnitude fewer parameters that GPT-4.",1711317879,comment,39809177
MuffinFlavored,39820580,39810921,"&gt; Right, like the other commenter suggested, that&#x27;s an infrastructure-level thing, not a model-level thing.<p>By default, the ChatGPT &quot;model&quot; knows to not try to do math and instead write code to do the math then run it. I get that it&#x27;s set up infrastructure wise to be able to run it, but why is Claude&#x27;s main chat UI not trying to instead respond<p>&quot;hey, do this calculation on your own since I can&#x27;t&quot; or something of this nature instead of responding to math incorrectly",1711396411,comment,39809177
avree,39809887,39809735,"Doesn&#x27;t seem like you are very informed on how LLMs work, but just so you know, there are many different versions of Claude, just like how ChatGPT can use different versions of GPT.",1711310099,comment,39809177
thorum,39810193,39809549,"I don’t know what the people who say Claude 3 is better than GPT-4 are using it for. It’s been consistently worse for everything I’ve thrown at it.<p>Debugging a Python function this morning. Claude 3 Opus failed completely. GPT-4 found the bug, as well as two others I hadn’t even been looking for.",1711312120,comment,39809177
simonw,39810414,39810193,"I&#x27;ve had the opposite experience: coding prompts that GPT-4 makes mistakes on Claude 3 Opus gets right the first time.<p>As always, your results will vary based on your personal prompting style. My style apparently works great with Opus.<p>Here&#x27;s one example: GPT-4 gave me code that was missing some async&#x2F;await keywords: <a href=""https:&#x2F;&#x2F;chat.openai.com&#x2F;share&#x2F;117fb1ad-6361-41e2-be59-110f3262594d"" rel=""nofollow"">https:&#x2F;&#x2F;chat.openai.com&#x2F;share&#x2F;117fb1ad-6361-41e2-be59-110f32...</a><p>Claude 3 Opus with the same prompt got it right the first time: <a href=""https:&#x2F;&#x2F;gist.github.com&#x2F;simonw&#x2F;2002e2b56a97053bd9302a34e0b83074"" rel=""nofollow"">https:&#x2F;&#x2F;gist.github.com&#x2F;simonw&#x2F;2002e2b56a97053bd9302a34e0b83...</a>",1711313578,comment,39809177
brianjking,39810799,39810414,"Yeah, Opus has entirely taken over any code specific use for me over ChatGPT 4 or OpenAI GPT-4 API.<p>Once Opus has the ability to run a code interpreter, it&#x27;ll really be an exciting time.",1711316735,comment,39809177
geor9e,39809792,39809549,"I don&#x27;t know what system and user prompt you are testing with, but as one anecdote, Claude 3 Opus (and only Opus) consistently gives me better coding answers than GPT-4. Maybe it&#x27;s the type of stuff I am doing or how I phrase things, who knows. I was using GPT-4 since the day it came out but haven&#x27;t felt like going back so far.",1711309570,comment,39809177
dragonwriter,39810813,39809549,"&gt; Claude hasn&#x27;t figure out yet how to do the whole &quot;generate Python code and run it in a Juptyer notebook&quot; for math yet.<p>GPT-4 didn&#x27;t figure that out, either; that’s just tooling built around the model, not something the model “figures out”.",1711316885,comment,39809177
jxdxbx,39809904,39809549,"Claude is better than GPT 4 for my uses, and was able to help me do some simple coding things that GPT 4 could not. It’s worth trying at least.",1711310201,comment,39809177
drexlspivey,39810254,39809549,"According to Chatbot Arena where people vote on responses blindly and an ELO rating is determined for each LLM, gpt4 is on top slightly ahead of Claude 3 Opus<p><a href=""https:&#x2F;&#x2F;huggingface.co&#x2F;spaces&#x2F;lmsys&#x2F;chatbot-arena-leaderboard"" rel=""nofollow"">https:&#x2F;&#x2F;huggingface.co&#x2F;spaces&#x2F;lmsys&#x2F;chatbot-arena-leaderboar...</a>",1711312536,comment,39809177
jasonjmcghee,39810178,39809549,"Claude Opus (largest v3 model) consistently outperforms GPT-4 for me. Better at following prompts, _feels_ much better.",1711311990,comment,39809177
treprinum,39810051,39809549,"Claude-2 in some tasks albeit it&#x27;s a bit slower, Mistral on some tasks and it&#x27;s a bit faster.",1711311102,comment,39809177
marviel,39810517,39809549,"Claude is excellent for brainstorming, being a thought partner, general knowledge acquisition tasks, and creative writing.<p>The one mixed-bag weak spot I&#x27;ve found is in coding -- It tends to make more &quot;d&#x27;oh&quot; mistakes while coding, but comes up with more creative solutions at the same time ¯\_(ツ)_&#x2F;¯",1711314284,comment,39809177
yieldcrv,39810165,39809549,"The benchmark is Sora or whatever Open AI is working on right now or next, not trying to beat the model released a year ago and still failing<p>so when looking at it that way, the real question is what do you need? all I need is Mixtral 7x8B Q5 in an 8,000 token context window, at the moment<p>I think there are plenty of other people that can design their applications and problems around lower fidelity tools, or just pursue something else",1711311883,comment,39809177
jonplackett,39810860,39809177,FYI it was <i>GPT-3.5 Class</i> not GPT3.5.<p>A lot of models claim to be GPT3.5 class that clearly are not in the first place.,1711317350,comment,39809177
hulium,39810036,39809177,"There is also the open source FinGPT, that is claimed to beat GPT4 in some benchmarks at a fine tuning cost of $17.25.<p><a href=""https:&#x2F;&#x2F;github.com&#x2F;AI4Finance-Foundation&#x2F;FinGPT"">https:&#x2F;&#x2F;github.com&#x2F;AI4Finance-Foundation&#x2F;FinGPT</a>",1711310983,comment,39809177
potatoman22,39810134,39810036,One major advantage of FinGPT or Bloomberg&#x27;s LLM is that the embeddings produced by the model can be used for downstream prediction tasks. GPT-4 does not expose its embeddings so it cannot be used for this.,1711311634,comment,39809177
bernawil,39811941,39810134,"sorry, noob here trying to make sense of this: you mean you can extract embeddings from the model file or that the embeddings are available in the repo and you can just use those files?",1711327992,comment,39809177
potatoman22,39812799,39811941,"Kind of. You feed the LLM the input text for your prediction, you extract the activations of the final layer of the LLM (so the weights * the input of the previous layers), then use that activation vector, or embedding, as the input for a separate model. This separate model that uses the embedding can be any classifier or regression. A common use case for this is document classification.",1711339843,comment,39809177
hallqv,39810544,39809177,"This discussion is so dumb - finetuning a base model costs ~$1 with LORA&#x2F;QLORA and can yield same performance as gpt-4, but at 1&#x2F;100 of the cost per token.<p>What Bloomberg did for $10M was not finetuning..",1711314522,comment,39809177
simonw,39810728,39810544,"&quot;finetuning a base model costs ~$1 with LORA&#x2F;QLORA and can yield same performance as gpt-4, but at 1&#x2F;100 of the cost per token&quot;<p>That&#x27;s a big claim - can you back that up with any examples?",1711316094,comment,39809177
Implicated,39812963,39810728,I had opened a new tab back when this comment was just a few minutes old in hopes that when I came back there was some really great blog post linked with the details on the sorcery.,1711342460,comment,39809177
hallqv,39821311,39810728,"<a href=""https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;2402.00841.pdf"" rel=""nofollow"">https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;2402.00841.pdf</a>",1711401068,comment,39809177
chintler,39809334,39809177,"$10 Million(M), not $10 Billion(B).",1711306541,comment,39809177
affgrff2,39809560,39809334,Not looking forward for the times when an AI costs as much as an aircraft carrier.,1711308221,comment,39809177
moffkalast,39810247,39809560,"At least with an aircraft carrier you can make your money back by holding a small country for ransom, har har.",1711312504,comment,39809177
CharlesW,39809419,39809334,"Thank you, fixed! Also, direct link to paper: <a href=""https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;2305.05862.pdf"" rel=""nofollow"">https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;2305.05862.pdf</a>",1711307251,comment,39809177
thorum,39810232,39809177,"Note that the benchmarks used for comparison are basically measuring the model’s ability to understand financial content. In other words, reading comprehension for English, just in a specific domain. It shouldn’t really be surprising that a strong generalist model performs well here.<p>On the other hand, GPT-4 actually did worse on the NER task - labelling and tagging terms used in the text - vs their finetuned model. I assume the finetuned model was better at using the specific labels they were targeting.",1711312421,comment,39809177
Rustwerks,39810439,39809177,"<a href=""http:&#x2F;&#x2F;www.incompleteideas.net&#x2F;IncIdeas&#x2F;BitterLesson.html"" rel=""nofollow"">http:&#x2F;&#x2F;www.incompleteideas.net&#x2F;IncIdeas&#x2F;BitterLesson.html</a>",1711313745,comment,39809177
jebarker,39809551,39809177,How do they know GPT-4 received no specialized financial training?,1711308186,comment,39809177
CharlesW,39809614,39809551,"Meaning, they used the same generalized foundation model that all of us have access to, with no special fine-tuning, no retrieval-augmented generation, etc.",1711308519,comment,39809177
jebarker,39809669,39809614,"I don&#x27;t understand your point. To me GPT-4 is not a foundation model, it&#x27;s been highly tuned for the chat task. Nobody outside of OpenAI knows what that fine-tuning really involved. So it&#x27;s impossible to say how much finance specific data it was trained on (in pre-training or fine-tuning) or whether finance specific tasks were involved in fine-tuning.",1711308839,comment,39809177
CharlesW,39809697,39809669,"&gt; <i>To me GPT-4 is not a foundation model…</i><p>It is. <a href=""https:&#x2F;&#x2F;www.adalovelaceinstitute.org&#x2F;resource&#x2F;foundation-models-explainer&#x2F;"" rel=""nofollow"">https:&#x2F;&#x2F;www.adalovelaceinstitute.org&#x2F;resource&#x2F;foundation-mod...</a>",1711309013,comment,39809177
,39809757,39809697,,1711309355,comment,39809177
jebarker,39809813,39809697,"What I was meaning was that ChatGPT is not a foundation model since it&#x27;s been fine-tuned. Although the definition in the link is sufficiently broad you could choose to include it.<p>I can&#x27;t tell from the OpenAI docs whether it&#x27;s possible to access GPT-4 without the ChatGPT fine-tuning. If so, that&#x27;d make this result more meaningful. Otherwise, I just don&#x27;t think you can draw any great conclusions from this.",1711309673,comment,39809177
doctorpangloss,39810149,39809813,The instruction fine tuning is what manifests knowledge and reasoning.,1711311757,comment,39809177
rmbyrro,39811550,39809813,"GPT is general purpose, it&#x27;s not fine tuned for specific topics. A fine tuned model is tuned to a specific subject.",1711323751,comment,39809177
ldjkfkdsjnv,39809942,39809177,"Fine tuning will disappear, no reason to invest so heavily in it. Also, most LLM code being written right now (prompts, RAG, etc) will be obsolete once the next model comes out. Anyone starting an LLM application startup is arguably wasting their time, wait until the next iteration is out. Then you will know whats possible.",1711310405,comment,39809177
minimaxir,39810000,39809942,"&gt; Also, most LLM code being written right now (prompts, RAG, etc) will be obsolete once the next model comes out.<p>Not true. Most prompt techniques that work on current modern LLM models will work on different or future models, although it will require a QA pass for any regressions.",1711310718,comment,39809177
ldjkfkdsjnv,39810057,39810000,"Yeah they will work, but they will also be unnecessary. You will also bake all sorts of logic into your application that will be solved natively on the stronger model. If you believe in the scaling theory, then writing LLM applications is non sensical.",1711311119,comment,39809177
kergonath,39811061,39810057,"&gt;  If you believe in the scaling theory, then writing LLM applications is non sensical.<p>But not doing it is an opportunity cost. You don’t built skills, tooling and experience, and you don’t get feedback on what works and where you should go.<p>It’s like computers in the 1990s: there’s always a better one 6 months away, so if you wait for it to stabilise, then you don’t do anything for a decade. Just enjoy the ride, bearing in mind that things change very fast and some things will be obsolete next year.",1711319097,comment,39809177
mlyle,39810175,39810057,"&gt; Yeah they will work, but they will also be unnecessary. You will also bake all sorts of logic into your application that will be solved natively on the stronger model.<p>I think that a whole lot of what I do in prompt engineering is what&#x27;s necessary to fully specify the output that I want.<p>A newer model may be less finicky, so I have a higher chance of getting it to work on the first try (and it&#x27;s more reliable afterwards), but it&#x27;s hard for me to imagine it needing a whole lot less prompt.",1711311972,comment,39809177
Xenoamorphous,39810398,39810057,"How will a more powerful model be a substitute for RAG, which is usually used with private data that won’t be present in any training dataset?",1711313409,comment,39809177
kergonath,39811112,39810398,"One of the idea is to just stuff all the documents in the prompt, which still keeps them private but avoids having to faff around with chunking, embedding, and vector stores. That’s not really the end of RAG as a concept, but it would change all the current tooling and infrastructure we built for it.<p>I don’t think RAG is going away, at least not because of this. But I expect new techniques to become available fairly regularly.",1711319432,comment,39809177
ldjkfkdsjnv,39810436,39810398,"I just think that the capability of the model could radically change, such that however you structured your RAG pipeline, might need to be rewritten. More general problems could be solved by the model, that you were solving with some complicated contraption of prompts.",1711313734,comment,39809177
,39810171,39810057,,1711311940,comment,39809177
rkagerer,39810404,39809942,"&quot;Don&#x27;t buy a computer today, because the faster one is coming out tomorrow&quot;",1711313493,comment,39809177
simonw,39810503,39810404,"Don&#x27;t buy a computer today with a six month delivery lead time, because there&#x27;s a company that releases computers with a same-day lead time with several improved models coming out next week.",1711314160,comment,39809177
treprinum,39810063,39809942,"OpenAI-related startups are likely using GPT-5 already. Waiting it out won&#x27;t help other startups, they will be too far behind.",1711311163,comment,39809177
__loam,39809810,39809177,GPT-4 cost like $100m so I don&#x27;t think this is surprising?,1711309657,comment,39809177
rafaelero,39809903,39809810,"A lot of organizations still think they should have their own [finetuned] model to provide a custom experience to their users, so that may come as a surprise for them.",1711310181,comment,39809177
ShamelessC,39809937,39809903,Scaling laws basically guarantee that a sufficiently larger general model will usually beat a smaller specialist model. The misunderstanding is perhaps acceptable but the headline here is essentially restating a well known property of deep learning.,1711310372,comment,39809177
__loam,39810035,39809937,How long ago was the Bitter Lesson written?,1711310977,comment,39809177
mistrial9,39810169,39809937,"contrarian view - how these models actually operate at runtime is not understood.. the formal research papers repeat that over and over again. Therefore, there will be new twists and turns as these models evolve. With <i>current</i> technology stacks, the &quot;bitter lesson&quot; is looking good, yes. Will it always be so? no way to know it.",1711311921,comment,39809177
,39810907,39809177,,1711317724,comment,39809177
atleastoptimal,39810838,39809177,"Yeah, the equivalent is: would it be better for a quant firm to spend 200 thousand dollars giving a first-class specialist education to a guy with an IQ of 95, or just hiring a guy with an IQ of 150 straight out of college.",1711317174,comment,39809177
cstanley,39822179,39820639,"This paper was published 154 days ago, probably a year since the authors did the experiment. Sooo much has happened since then! This showed already that GPT4 is pretty darn good analyst.<p>All this real-world complexity can be tamed by stuffing the prompt with a ton of relevant context and an amazing prompt engine. We&#x27;ll have bots that autonomously query the database hundreds of times building a 5 page &quot;deep-dive&quot; analytics report in minutes.<p>At least that&#x27;s what we&#x27;re trying at patterns.app.",1711407375,comment,39820639
andy99,39821924,39820639,May 2023 using GPT-4-0314.,1711405512,comment,39820639
elietoubi,39822235,39820639,"If anyone is interested i built for myself and open sourced parse.dev<p><a href=""https:&#x2F;&#x2F;github.com&#x2F;ParseDev&#x2F;parsedev"">https:&#x2F;&#x2F;github.com&#x2F;ParseDev&#x2F;parsedev</a>",1711407729,comment,39820639
lutusp,39822249,39820639,"&gt; However, we are still at a stage of divergent opinions without any definitive conclusion.<p>Okay, I know picking people&#x27;s sentences apart has fallen out of fashion, but:<p>&quot;Divergent opinions&quot; are ... opinions.
A &quot;definitive conclusion&quot; is ... a conclusion.<p>I see more examples, but I wanted to make a point: I miss the days when fewer words conveyed more meaning. From the classic <a href=""https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;The_Elements_of_Style"" rel=""nofollow"">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;The_Elements_of_Style</a>: &quot;Make every word count.&quot;<p>About brevity of expression, I must add this (possibly apocryphal) story about Ernest Hemingway. In the 1920s Hemingway and his Paris friends had a contest: who could write the shortest readable short story? Hemingway won with this entry:<p>For sale. Baby shoes. Never worn.",1711407845,comment,39820639
apineda,39822475,39822249,"From an alternative viewpoint, this could be seen as descriptive of a community. Opinions could be shared or not, hence &quot;divergent&quot; as an adjective to describe the community. Similar with conclusions people have drawn and &quot;definitive&quot; may refer to a larger consensus among the community. Fun to think about.",1711409383,comment,39820639
greenavocado,39821832,39820639,Even the latest commercial LLMs are happy to confidently bullshit about what they think is in published research even if they provide citations. Often the citations themselves are slightly corrupted. I actually verify each LLM claim so I know this is happening a lot. Occasionally they are complete fabrications. It really varies by research topic. Its really bad in esoteric research areas. They even acknowledge the paper was actually about something else if you call them out on it. What a disaster. LLMs are still useful for information retrieval and exploration as long as you understand you are having a conversation with a habitual liar &#x2F; expert beginner and adjust your prompts and expectations accordingly.,1711404835,comment,39820639
bongodongobob,39821934,39821832,"Unintuitively, I think you&#x27;ll probably end up with better answers if you don&#x27;t ask for citations. The vast majority of its training isn&#x27;t white papers so you&#x27;re artificially constraining its &quot;imagination&quot; to the cited sources space. I find the more constraints you add, the worse your answers are.",1711405644,comment,39820639
notnullorvoid,39822288,39821832,"&gt; They even acknowledge the paper was actually about something else if you call them out on it.<p>For clarity is not really acknowledging it made a mistake. &quot;Calling out&quot; an LLM&#x27;s mistake just leads to the next most likely text to be something that sounds like an acknowledgement of a mistake, but the same is likely to happen if the LLM generated a correct response and you respond claiming that it&#x27;s incorrect.",1711408090,comment,39820639
jiggawatts,39822333,39821832,"&gt; What a disaster.<p>Using tool inappropriately leads to suboptimal outcomes -- news at 11.<p>A good mental model is that an LLM is a blurry JPEG of the Internet.<p>You sound like a scientist, right? You reference &quot;published research&quot;, after all.<p>What would your opinion be of a researcher measuring the exact values of the pixels of a JPEG image instead of the RAW sensor data?",1711408329,comment,39820639
mritchie712,39821929,39820639,"reminds me of this tweet [0]<p><pre><code>    Them: Can you just quickly pull this data for me?

    Me: Sure, let me just: 

    SELECT * FROM some_ideal_clean_and_pristine.table_that_you_think_exists

</code></pre>
GPT-4 is good on a single CSV, but breaks down quickly applied to a real database &#x2F; data warehouse. I know they&#x27;re using multiple tables in the paper, but it appears to be a pristine schema that&#x27;s very easy to reason about. In the real world, when you&#x27;re trying to join postgres to hubspot and stripe data, an LLM isn&#x27;t able to write the SQL from scratch get the right answer.<p>We&#x27;re working on an approach using a semantic layer at <a href=""https:&#x2F;&#x2F;www.definite.app&#x2F;"" rel=""nofollow"">https:&#x2F;&#x2F;www.definite.app&#x2F;</a> if you&#x27;re interested in this sort of thing.<p>0 - <a href=""https:&#x2F;&#x2F;twitter.com&#x2F;sethrosen&#x2F;status&#x2F;1252291581320757249?lang=en"" rel=""nofollow"">https:&#x2F;&#x2F;twitter.com&#x2F;sethrosen&#x2F;status&#x2F;1252291581320757249?lan...</a>",1711405558,comment,39820639
neeleshs,39822450,39821929,"It goes beyond just joining postgres to hubspot and stripe even when humans are doing it. Typos in source systems, duplicative data, unwarranted prefixes, suffixes, stuff you don&#x27;t care about, columns named c0,c1,c2 etc.<p>A semantic layer is just really all about defining data models in the domain of interest. It&#x27;s the hardest part in dealing with data strategies, very manual, very company and process and history specific.<p>Once it&#x27;s defined, the next set of tasks is to make sure that the data in the model is correct and coherent. And only then, querying this data, applying ML etc start becoming worthwhile.<p>We at <a href=""https:&#x2F;&#x2F;syncari.com"" rel=""nofollow"">https:&#x2F;&#x2F;syncari.com</a> take the centralized data model centric approach. 
<a href=""https:&#x2F;&#x2F;www.definite.app&#x2F;"" rel=""nofollow"">https:&#x2F;&#x2F;www.definite.app&#x2F;</a> also looks very cool!",1711409125,comment,39820639
,39822102,39821929,,1711406849,comment,39820639
kva,39821769,39820639,"Given the right prompt, I&#x27;m sure it is....but when do users ever enter the right prompt? :(",1711404364,comment,39820639
richardw,39821856,39821769,"You can&#x27;t depend on it at all.  I mean, you can use it for a tremendous amount of work, but until there is a way to constrain the bullshit LLM&#x27;s can&#x27;t be used for anything that requires a correct answer.<p>The terms &quot;depend&quot; and &quot;require&quot; there are the hard versions. You can&#x27;t send people to the moon on the outputs of LLM&#x27;s.",1711405099,comment,39820639
roenxi,39822287,39821856,"I think we&#x27;ll solve that problem for LLMs before we solve it for humans. Data analysts produce a lot of garbage; data work is really hard. In fact, it isn&#x27;t uncommon in my experience for the data analyst to be the only person saying &quot;hang on, the quality of this reporting isn&#x27;t good enough for the decisions you&#x27;re making from it!&quot; - because they understand what useful information looks like and the company doesn&#x27;t have much of it.",1711408089,comment,39820639
paulsutter,39822236,39821856,"This is sheer cope<p>The tools are good for certain tasks and getting better. Master these tools and be ready for what released in the coming months and years<p>You are either at the center turning the wheel, or you’re on the outside getting spun",1711407737,comment,39820639
richardw,39822437,39822236,"You haven&#x27;t the vaguest fucking idea what I&#x27;m doing with the tools so put up a logical argument on the facts instead of just generating tokens in some way that attempts to play the person and not the ball.<p>Here, argue with Yann, who makes a statement about how language isn&#x27;t enough to produce a mind:
<a href=""https:&#x2F;&#x2F;twitter.com&#x2F;ylecun&#x2F;status&#x2F;1768353714794901530"" rel=""nofollow"">https:&#x2F;&#x2F;twitter.com&#x2F;ylecun&#x2F;status&#x2F;1768353714794901530</a>",1711409040,comment,39820639
Fauntleroy,39822301,39822236,"These tools are great at generating text responses, some of which are usable, but not analysis. We&#x27;re actually far from that. I&#x27;m not sure why some people are out here pretending this is not the case.",1711408156,comment,39820639
williamcotton,39821849,39821769,"Didn’t you get the memo? If you’re holding the hammer by the head and wondering why it isn’t driving the nail in that it is clearly the fault of the  manufacturer.<p>There’s even a handy aphorism to remind you that the user is never to blame: “You’re holding it wrong.”<p>Jokes aside, I wonder what the general writing abilities and communication skills are for people that cannot for the life of them get usable results from an LLM.",1711405010,comment,39820639
dimask,39822449,39821769,If you already know the right answer it is actually easy,1711409112,comment,39820639
viscanti,39821828,39821769,OpenAI should make something so that people can enter their prompt and maybe even drop in a knowledge base and then share with anyone else who wants that functionality.,1711404812,comment,39820639
snoman,39821950,39821828,"That’s ptetty close to what GPTs are, with the exception of knowledge bases.<p>There’s more to it, but the tooling to create a GPT is basically a hand-holding mechanism to create a prompt.",1711405726,comment,39820639
gregorymichael,39822072,39821950,GPTs have the knowledge base too. (Mixed results though),1711406605,comment,39820639
wolpoli,39822064,39821828,"Would the final product be similar to Github copilot, but for prompt?",1711406539,comment,39820639
,39821875,39821769,,1711405230,comment,39820639
SV_BubbleTime,39822021,39821769,“42”,1711406150,comment,39820639
,39822105,39821769,,1711406867,comment,39820639
,39822114,39820639,,1711406923,comment,39820639
dangoodmanUT,39822043,39820639,Not on useful datasets in real places,1711406340,comment,39820639
,39822106,39822043,,1711406884,comment,39820639
einpoklum,39821758,39820639,"I was somewhat put off by the abstract:<p>&gt; LLMs... have demonstrated their powerful capabilities in ... context understanding, code generation, language generation, data storytelling, etc.,<p>LLMs have not demonstrated understanding (in fact, one could argue that they are fundamentally incapable of understanding); they have only AFAICT demonstrated the ability to generate boilerplate-ish code; &quot;language generation&quot; is too general a task to claim that LLMs have succeeded in; and as for data storytelling I don&#x27;t know, but they can spin yarns. The problems is that those yarns are often divorced from reality; see:<p><a href=""https:&#x2F;&#x2F;www.ibm.com&#x2F;topics&#x2F;ai-hallucinations"" rel=""nofollow"">https:&#x2F;&#x2F;www.ibm.com&#x2F;topics&#x2F;ai-hallucinations</a><p>--------<p>Leafing through the paper, and specifically tables 6 and 7, I don&#x27;t believe their conclusion, that &quot;GPT-4 can perform comparable [sic] to a data analyst&quot;, is well-founded.",1711404323,comment,39820639
mewpmewp2,39821827,39821758,"I don&#x27;t even understand what understanding exactly means, perhaps anyone who understands it, can enlighten me?<p>Do I, myself understand? Stand under what exactly? What is that supposed to mean?",1711404798,comment,39820639
modriano,39822345,39821827,"To understand means a few things, but they all essentially boil down to having a correct (or at least correct enough to be useful for your usecase(s)) model for something in your head.<p>Have you told someone something like &quot;no, don&#x27;t do it that way because &lt;insert non-obvious downstream problem&gt;, instead, do &lt;insert alternative strategy that achieves better outcomes&gt;&quot;? That&#x27;s an artifact of understanding and of the model you&#x27;ve developed for that thing.<p>It&#x27;s well described as a mixture of knowledge and wisdom, and is essentially the property of knowing the effect that pulling a lever will cause, coupled with good judgement about how, when, and why to pull the lever.",1711408427,comment,39820639
mewpmewp2,39822518,39822345,"But GPT-4 has told me that as well?<p>Usually in a bit more polite way.<p>That my approach is a &quot;novel&quot; and an &quot;interesting&quot; approach, hinting that it&#x27;s really probably not the best option here.",1711409688,comment,39820639
richardw,39822337,39821827,"The fact that you ask that is in many ways the difference. You feel there’s a limitation in your knowledge of the term “understand” and its use in this context and would like clarification before you’re more certain, either way. At some point either enough information arrives to convince you, or you decide it’s not true. Whatever that process and internal states are, is something GPT can’t do.  It’ll 100% confidently produce something and be fully rewarded that it chose tokens that humans would most likely choose given the preceding tokens. There’s no “aha”.",1711408356,comment,39820639
mewpmewp2,39822485,39822337,"But it frustratingly, frequently tells me it doesn&#x27;t have enough data or other XYZ reasons to why it can&#x27;t answer my weird questions.",1711409459,comment,39820639
advael,39822152,39821827,Solipsism is truly the best fully-general counterargument,1711407216,comment,39820639
,39822321,39822152,,1711408272,comment,39820639
mewpmewp2,39822245,39822152,To AI? Or that you are not a NPC?,1711407823,comment,39820639
advael,39822296,39822245,"To anything, that&#x27;s what &quot;fully-general&quot; means",1711408131,comment,39820639
mewpmewp2,39822371,39822296,So you are a bot?,1711408581,comment,39820639
advael,39822404,39822371,"I mean from your perspective I&#x27;m just a name making more words on your screen, right? Don&#x27;t worry too much about it, buddy, you&#x27;re doin&#x27; great :)",1711408760,comment,39820639
mewpmewp2,39822463,39822404,"Haha, you are funny! What&#x27;s the weather tomorrow? Please also remind me tomorrow to put my gym clothes to washer and dry them after.",1711409250,comment,39820639
advael,39822604,39822463,"I can&#x27;t spoil the weather tomorrow (it&#x27;s a major plot point) but I can tell you that fortune has been tweaked to favor the bold by an additional 10%, just for tomorrow.<p>Laundry service is complimentary, but our records show that you haven&#x27;t registered your home. Would you like to register your home address at this time?",1711410507,comment,39820639
ocbyc,39821860,39821827,"Transformers are just pattern matching. So if you write &quot;give me a list of dog names&quot; it knows that &quot;Spot&quot; should be in that result set. Even though it doesn&#x27;t really know what a dog is, a list is, or what a spot is.",1711405116,comment,39820639
rafaelero,39821915,39821860,&gt; Transformers are just pattern matching.<p>That&#x27;s trivially true. The question is: are we any different?,1711405453,comment,39820639
richardw,39822368,39821915,"I think so. You ask that question because you’re interrogating the position, not because 1000 humans have asked that question in similar situations.<p>You and I know there’s a truth and we’d like to find it. The GPT is just happy (I.e. rewarded) to produce frequently used tokens.",1711408559,comment,39820639
parpfish,39822584,39822368,but maybe that feeling of &#x27;looking for truth&#x27; is just what happens when you&#x27;re doing pattern matching on the text embeddings?,1711410364,comment,39820639
mewpmewp2,39822492,39822368,And I&#x27;m just happy to perform actions that will make me survive and reproduce?,1711409520,comment,39820639
richardw,39822523,39822492,"Most likely, unless you meditate a lot. Sometimes you&#x27;ll take a bullet to save other people. Sometimes you&#x27;ll drink yourself into a state that doesn&#x27;t help you survive or reproduce. Or you&#x27;ll write on a forum anonymously that doesn&#x27;t help with survival or reproduction because it&#x27;s enjoyable, makes you think, or you&#x27;re addicted. Who knows :)",1711409740,comment,39820639
mewpmewp2,39822608,39822523,You are even better at analyzing me than GPT-4.,1711410519,comment,39820639
parpfish,39822205,39821915,I approach LLMs with the perspective that “maybe this demonstrates that we humans are all just stochastic parrots?”and we should have the null hypothesis that humans are just pattern matchers.,1711407551,comment,39820639
mewpmewp2,39822271,39822205,"This is the way I perceive my thoughts. I don&#x27;t know what I&#x27;m going to think of beforehand or in advance, these could all be stochastic &quot;tokens&quot; based on what I&#x27;ve observed in my life.<p>So of course I feel a bit offended when people claim LLMs are just stochastic parrots, because it doesn&#x27;t feel to me, that I&#x27;m specifically any better?<p>My thoughts - they just happen, and sometimes not in my favor - I have had times of depression, I didn&#x27;t have control over my thoughts. Neither do I have now, but at least I am in a better place. Because the &quot;happiness&quot; chemicals are regulated to be in a more favorable state to me for various different factors.<p>I didn&#x27;t know what I was going to comment in response to your comment, I was just streaming my conscious.",1711408022,comment,39820639
bongodongobob,39821908,39821860,"I don&#x27;t think that&#x27;s true. They clearly group related things together and seem to be able to create concepts that aren&#x27;t specifically in the training data. For example, it will figure out the different features of a face, eyes, nose, mouth even if you don&#x27;t explicitly tell it what those are. Which is why they are so cool.",1711405424,comment,39820639
zeusk,39822220,39821908,Most of that magic comes from embedding no? which is clustering things by their relation in some N-dimensional space,1711407636,comment,39820639
bongodongobob,39822383,39822220,"Exactly. It figures that out on its own. That&#x27;s what &quot;understanding&quot; looks like in this context, imo.",1711408637,comment,39820639
mewpmewp2,39822008,39821908,"They are cool, but then you are also cool.",1711406054,comment,39820639
mewpmewp2,39821982,39821860,How would I test whether I &quot;know&quot; or &quot;understand&quot; what a dog is?,1711405918,comment,39820639
notahacker,39822452,39821982,"Oh, that&#x27;s easy, we just give the dog a keyboard and see if you accurately identify it&#x27;s a dog from  your text based interactions ;-)",1711409163,comment,39820639
mewpmewp2,39822499,39822452,Are you calling me a dog?,1711409588,comment,39820639
inopinatus,39822141,39821860,Even this seems too grand a claim. I’d water it down thus: the LLM encodes that the token(s) for “Spot” are probabilistically plausible in the ensuing output.,1711407122,comment,39820639
bongodongobob,39822202,39822141,"...because it understands what a dog name is. Why wouldn&#x27;t you see Gary or Florence in that list? How does it know those aren&#x27;t dog names?<p>You can&#x27;t be suggesting it has memorized relationships between all concepts, the model would be enormous.<p>So clearly, there is something else going on. It&#x27;s able to encode concepts&#x2F;ideas.",1711407529,comment,39820639
inopinatus,39822212,39822202,"The model <i>is</i> enormous, and N-dimensional for very high N. But the model remains insufficiently enormous for understanding, and moreover, the model cannot observe itself and adjust.<p>Ask an LLM to extrapolate, see any semblance of reason collapse.",1711407592,comment,39820639
mewpmewp2,39822253,39822212,Extrapolate what?,1711407890,comment,39820639
ALittleLight,39821966,39821860,Can you describe a test that would separate trivial pattern matching from true understanding?,1711405822,comment,39820639
lottin,39822067,39821966,A simple conversation would do.,1711406572,comment,39820639
mewpmewp2,39822145,39822067,"Could you share a conversation link with GPT-4 with either about a &quot;list&quot; or a &quot;dog&quot;, to determine whether it truly understands one of those things compared to a human?",1711407147,comment,39820639
bongodongobob,39822156,39822067,Just did that. It seems to understand. Checkmate &#x2F;fingerguns,1711407229,comment,39820639
unclebucknasty,39822038,39821758,"Agreed, right down to their conclusion resonating as way overstated. Actually, meaningless would be more accurate.<p>The thing about LLMs is exactly that they <i>don&#x27;t</i> understand by design. It often feels very distinctly like it&#x27;s just engaging in sophisticated wordplay. A parlor trick.<p>When ChatGPT 4 first came out I spent a couple of hours putting together a chess game using ChatGPT as the engine. It was shockingly bad, as in even attempting to make invalid moves.<p>I get it: it&#x27;s not tuned for that purpose, and its chess training corpus could probably be expanded to improve it as well.<p>But, it actually served as a near-perfect demonstration of its lack of understanding, as well as the confidence with which it asserts things that are simply wrong.<p>On a recent integration project with a good bit of nuanced functionality, it led me astray multiple times. I&#x27;ve gotten to a point where I can feel when its answers are not quite right, particularly if I know just a little about the topic. And, when challenged, it does that strange thing of responding with something along the lines of, &quot;My apologies you&#x27;re completely right that I was completely wrong&quot;.<p>Over time, there becomes a sense that there is no there there. Even it&#x27;s writing capabilities, lauded by so many, are of a style that is superficial and perfunctory or rote. That makes sense when you know what it is, but that&#x27;s the thing: we get articles like these, lauding its wisdom.",1711406320,comment,39820639
bongodongobob,39822088,39822038,"Idk. One of my first tests for GPT4 was writing a website &quot;for snakes.&quot; It was a flask app, and it did all the obvious things you&#x27;d expect. There was a title that said &quot;Snake.com - A website for snakes&quot; and a bunch of silly marketing stuff.<p>What impressed me is when I asked to make it more snake-like (what does that even mean right?).<p>It changed the colors to shades of green, used italic fonts, added some hisssssing sssstuff to wordssss, and added a diamond pattern through the background.<p>It was a dumb and not very fancy site, but I&#x27;m not sure you can say it doesn&#x27;t understand anything at all when you ask it to make a website more snakelike and actually made a pretty good attempt at doing it.",1711406723,comment,39820639
unclebucknasty,39822192,39822088,"Yeah, that&#x27;s kind of a different conception of understanding though. The lines do get a little blurry at a certain point, and a lot of what it does &quot;feels&quot; like understanding, especially given how it &quot;communicates&quot;.<p>But I think it comes down to whether it can reason about things and whether it can draw new conclusions or create new information as a result.<p>Your snake site is probably a good example. ChatGPT has a bunch of words that it knows are associated with snakes. It&#x27;s pretty straightforward pattern matching. It doesn&#x27;t really &quot;understand&quot; what those words mean, except that they have relationships to other words.<p>But, if you were to ask it to reason and draw new conclusions about these things beyond its training corpus, it would be unable to reliably do so.<p>Similarly, it had no idea about the quality (and sometimes legality) of the chess moves it generated.",1711407428,comment,39820639
visarga,39822379,39822192,"&gt; it comes down to whether it can reason about things and whether it can draw new conclusions or create new information as a result<p>Neither can humans, at least with our bare brains. We can do it by carefully observing the effects of our actions in the environment, but we are really studying the world and it takes time. Everything we know comes from the environment.<p>The brain by itself invents or discovers nothing, it is the data-engine made by action-effect-feedback that teaches us all we know. Without the ability to push and prod, set up our experiments and carefully observe effects we wouldn&#x27;t be at our current level.<p>Environment is the teacher, but there is another important factor - language. Without it every one of us would have to rediscover from scratch. With it we can build upon other people to learn and cooperate. We encode everything we know in language. It acts like an evolutionary system of ideas.<p>LLMs have what is necessary, they can learn language pretty well, but until now have not been exposed much to the world. There are millions of chats but very little in other kinds of environments - computers, simulators, games, robots. LLMs can create their own experiences and learn from each other, and from us.<p>Open ended discovery is a grand project, a social process, it doesn&#x27;t work well in one agent. Language is the linking element, and the world is the teacher. Some things are not written in any books, only the external world can teach us. Reasoning about things and drawing new conclusions depends on having access to an environment.",1711408625,comment,39820639
bongodongobob,39822325,39822192,"I mostly agree.<p>I really think chess is just a terrible example though. You&#x27;re really asking a lot of it but I&#x27;m honestly shocked it <i>can</i> do what it can. It seems to know some opening books, but falls down immediately. Which really makes sense because you&#x27;ll find a lot of reading material on specific openings, but the problem space of the game is just too big to find texts about any given game state. Maybe if you have it reason about the board state and &quot;think&quot; about tactics you could push it farther. But we&#x27;ve already solved this.<p>We have Stockfish et al and they&#x27;ve literally changed the game. Asking an LLM to play chess, while cool, is like trying to train a fish to dance. I think once we have an AI that&#x27;s built with a bunch of different models that specialize in different things the idea of understanding is going to get even blurrier to the point that we might even say &quot;yes, it doesn&#x27;t &#x27;understand&#x27; things, but it&#x27;s better at humans at literally everything&quot; so the difference becomes meaningless.<p>I&#x27;m also of the opinion that humans are fancy automatons, so I tend to argue both sides. I&#x27;ll say yeah it&#x27;s thinking and so do we or ok it&#x27;s not, but either do we.",1711408290,comment,39820639
jeffreygoesto,39820641,39820430,"Reminds me of <a href=""https:&#x2F;&#x2F;github.com&#x2F;EnterpriseQualityCoding&#x2F;FizzBuzzEnterpriseEdition"">https:&#x2F;&#x2F;github.com&#x2F;EnterpriseQualityCoding&#x2F;FizzBuzzEnterpris...</a>",1711396826,comment,39820430
,39820306,39820264,,1711394533,comment,39820264
,39820129,39819808,,1711393612,comment,39819808
withinrafael,39819265,39818823,"&gt; Below are a few examples of the artists’ work, with early thoughts from them on how they see Sora fitting into their workflows and businesses.<p>I wish it was clearer how Sora was used by each artist and how it impacted the provided examples. (I think I see some Sora generated output but I&#x27;d imagine it&#x27;s not as clear cut in artistic works.)",1711388764,comment,39818823
rperez333,39822394,39818823,"I&#x27;m seeing shots that would be incredibly expensive for some productions - even if we ignore the ones requiring visual effects work. Some of them would need small crews, permits, rentals of expensive equipment, casting, and travel. It&#x27;s impressive and concerning at the same time.",1711408711,comment,39818823
ed_mercer,39822631,39822394,Do we have any ballpark figure of what a single sora video costs to make?,1711410744,comment,39818823
Jensson,39819266,39818823,"&gt; Sora is at its most powerful when you’re not replicating the old but bringing to life new and impossible ideas we would have otherwise never had the opportunity to see.<p>Roughly what you would expect, good for artsy pieces where you don&#x27;t need the model to generate anything very specific, but not very useful for most work since most work you want that control.<p>In other words it will be used for very similar things as current image generators, like intro scenes, short one offs, concept art etc.",1711388777,comment,39818823
erickj,39819924,39819266,&gt; not very useful for most work<p>We seem to be on a timeline where most of the significant use cases that the model doesn&#x27;t handle well today is less than 2 years away from significant improvement.<p>My (completely baseless) guess is that within 2 years we begin to see &quot;high budget&quot; feature length productions beginning to move towards a cost saving model which fully allocate the production budget to primarily virtual content.<p>In less than a few years time there will almost certainly be a vast ecosystem of production and post production tools to give creators the controls to reliably create and fine tune their shots.,1711392508,comment,39818823
hexage1814,39820665,39819924,"I agree with you, and just a few more observations about where do I think the current bottleneck might be: I wonder how well the model handles with re-using objects&#x2F;people&#x2F;scenes. Like, can I create a character and then use him again along 10 different shots? Also, I&#x27;m pretty curious about how the user interface looks like. Cause they the text-to-video model interfaces seem pretty limited compared to the freedom a person has using Unreal Engine or Blender or shooting a movie in real life.<p>How would the golden standard text-to-video user interface would look? And I have been thinking on this for years, even before the current generative AI boom, and I wonder if it could generate like a 3D representation of the scene that you described, like there would be a file where you could very easily change things around, as if that thing had been created on Blender or whatever, but very very user-friendly and easy to edit things.<p>It will seem silly what I&#x27;m going to say, but the ideal interface, it reminds those movies people did using the game &quot;The Sims&quot;, and how you could very easily move objects, and move the camera, and so on. What I&#x27;m trying to say here is that I would imagine these models creating a 3D representation of the scene, and the movie-making process ends up being somewhat similar to how could you could customize objects&#x2F;people in that game.",1711396956,comment,39818823
TomaszZielinski,39822424,39820665,"I have only vague idea about this (I worked on small 3d games many many years ago), but I imagined something similar to what you described.<p>Basically you use Sora to generate a promising scene, then you ask it (or another model) to turn that scene into a scene graph in a text file.<p>It will make mistakes, but it could work similarly to the Python interpreter in ChatGPT--it can iterate until everything is OK. Maybe there could even be some adversarial stuff where the scene graph is rendered on the fly to compare it to the generated clip, etc.<p>And then you can use you standard toolset to edit it, probably enhanced with a copilot model to automate as much as possible.",1711408923,comment,39818823
whiplash451,39820668,39819924,"The cool demos from OpenAI, Figure and the like make us hallucinate a future that will take much (much) longer to pan out because they ignore the domain-specific knowledge that is inherent to the domain they pretend to disrupt.<p>I’ll be impressed when ILM talks about it.",1711396970,comment,39818823
commakozzi,39821252,39820668,this&#x27;ll age well...,1711400649,comment,39818823
CamperBob2,39821319,39821252,It&#x27;s &quot;God of the Gaps&quot; all the way down with these folks.,1711401182,comment,39818823
jrflowers,39819795,39818823,"&gt; As great as Sora is at generating things that appear real - what excites us is its ability to make things that are totally surreal.<p>Finally, software that makes images that don’t quite look right. The use cases for these will be unending",1711391865,comment,39818823
whiplash451,39820713,39818823,"I’ll be downvoted for this, but all these videos feel like the high-fructose corn syrup of cooking.",1711397247,comment,39818823
wilg,39821303,39820713,"Successful, widespread, and not differentiable in taste tests?",1711401017,comment,39818823
jazzyjackson,39821843,39821303,a cheap way to make everything sweet so that prepackaged goods are preferable to ever leaning how to make something yourself,1711404933,comment,39818823
wilg,39822234,39821843,I think its good cheap food is available!,1711407722,comment,39818823
xotesos,39822574,39820713,[dead],1711410269,comment,39818823
th0ma5,39819054,39818823,A good study could be comparing artist output and self satisfaction with LLMs vs. Conversing with a rubber duck or just imagining what an LLM might do. A lot of this reads to me as the artists actually selling themselves short.,1711387752,comment,39818823
huytersd,39820854,39818823,How much of this is truly Sora and how much is not?,1711398121,comment,39818823
dzhiurgis,39821423,39818823,I feel all the GPU time should first go to improving GPT or solving AGI rather than image&#x2F;video generation,1711401845,comment,39818823
,39818911,39818823,,1711387142,comment,39818823
,39818609,39818597,,1711385723,comment,39818597
throwaway888abc,39818848,39818564,"Link to full paper:<p><a href=""https:&#x2F;&#x2F;educationaltechnologyjournal.springeropen.com&#x2F;articles&#x2F;10.1186&#x2F;s41239-024-00444-7"" rel=""nofollow"">https:&#x2F;&#x2F;educationaltechnologyjournal.springeropen.com&#x2F;articl...</a>",1711386850,comment,39818564
,39818827,39818564,,1711386776,comment,39818564
,39818457,39818400,,1711384924,comment,39818400
farmdve,39817824,39817802,And currently chat.openai.com is down for me. At least the actual API.,1711381691,comment,39817802
Blamoso,39818360,39817802,[dead],1711384439,comment,39817802
,39817967,39817802,,1711382368,comment,39817802
EMM_386,39785820,39782876,"It does make it easier for the end user who doesn&#x27;t want to fiddle around with python dependencies, command lines, building C++ projects, etc.<p>Just install it, point it to a model, and go.  Now you have a local LLM.<p>If you want something more, click the &quot;start server&quot; button and you have a local OpenAI compatible API which you can point more advanced front-ends to.",1711064860,comment,39782876
lagrange77,39785238,39782876,"I was wondering if it uses something like vLLM[0] or Llama.cpp[1].<p>Seems to be Llama.cpp via &#x27;Nitro&#x27;, which was discussed here before [2].<p>[0] <a href=""https:&#x2F;&#x2F;github.com&#x2F;vllm-project&#x2F;vllm"">https:&#x2F;&#x2F;github.com&#x2F;vllm-project&#x2F;vllm</a><p>[1] <a href=""https:&#x2F;&#x2F;github.com&#x2F;ggerganov&#x2F;llama.cpp"">https:&#x2F;&#x2F;github.com&#x2F;ggerganov&#x2F;llama.cpp</a><p>[2] <a href=""https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=38887531"">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=38887531</a>",1711060272,comment,39782876
LeoPanthera,39784818,39782876,"Unless I just can&#x27;t find it, there seems to be no setting for customizing the prompt format for local models. You can edit the prompt itself, but not the format of the prompt or the subsequent messages. This would make using many models difficult, or give poor results, since they don&#x27;t all use the same format.",1711057794,comment,39782876
FuriouslyAdrift,39784716,39782876,"Many LLMs may be run locally with GPT4All...<p><a href=""https:&#x2F;&#x2F;gpt4all.io&#x2F;"" rel=""nofollow"">https:&#x2F;&#x2F;gpt4all.io&#x2F;</a>",1711057093,comment,39782876
nickpsecurity,39786635,39784716,"And MLC puts them on your phone, too.<p><a href=""https:&#x2F;&#x2F;llm.mlc.ai&#x2F;"" rel=""nofollow"">https:&#x2F;&#x2F;llm.mlc.ai&#x2F;</a>",1711071971,comment,39782876
slowmovintarget,39793057,39784716,"GPT4All makes it annoyingly difficult to run any other than their &quot;approved&quot; models. I&#x27;d like to kick the tires on a whole host of random GGUF quantizations on Hugging Face, please.<p>I&#x27;ve poked around the doc, not sure if Jan can do that better.<p>In the mean time, I use text-gen-ui (Oobabooga) as a back-end and have it run with `--api` to use the front end of my choice.",1711129670,comment,39782876
_puk,39794911,39793057,Not at my computer right now to double check.. but doesn&#x27;t GPT4All&#x27;s &quot;Browse&quot; button in the model list let you pick a locally downloaded model?,1711141917,comment,39782876
christkv,39784104,39782876,I got say I’ve been using LLM studio as it exposes the models in the ui as well as through a local open ai compatible server so I can test different models against my workflows locally.,1711053587,comment,39782876
kkfx,39785203,39782876,"I try some LLM on my notes and well... They was unable to give me insights that are hard to spot, like follow the flaw of notes identifying patterns, find similar notes from the past and so on. In ALL cases classic tags&#x2F;riprgrep full-text search was far quicker and equally or more effective.<p>Long story short: LLMs might be useful on hyper big mass of information, like a new kind of search engine that try do achieve a semantic goal mimicking it. But not more than that IMVHO. Marginally LLMs might help computer-illiterate to manage their files, seen <a href=""https:&#x2F;&#x2F;www.theverge.com&#x2F;22684730&#x2F;students-file-folder-directory-structure-education-gen-z"" rel=""nofollow"">https:&#x2F;&#x2F;www.theverge.com&#x2F;22684730&#x2F;students-file-folder-direc...</a> but I doubt they can go any further for the next 5+ years at least.",1711060027,comment,39782876
lxgr,39793736,39785203,"They&#x27;ve been very useful in quickly answering common questions using a too-large-to-manually-scan knowledge base in my experience at my job, and I don&#x27;t consider myself or my colleagues &quot;computer-illiterate&quot;.",1711134275,comment,39782876
kkfx,39798051,39793736,"That&#x27;s follow the &quot;might be useful as a new kind of search engine&quot;, though it might be a sign of an a bit messy KB. The issue of potential hallucinations however is still there so even such usage, a different search engine, demand extra attention.<p>It&#x27;s not a free critic to those who have designed, implemented and trained LLMs, it&#x27;s just the observation that practical usage is far less than the advertised one and it&#x27;s still not much good. It&#x27;s still an advancement, a good thing to have, the start of a revolution, but still far from being what many dreams.",1711177517,comment,39782876
theGnuMe,39786724,39785203,LLMs might help my disorganized approach to files...,1711072933,comment,39782876
pryelluw,39783815,39782876,Would be nice if they listed system requirements. Their docs just say coming soon …,1711052097,comment,39782876
knodi123,39783993,39783815,most of their docs say coming soon.      and their whole wiki.<p>honestly feels like site this was launched a couple of days too soon.,1711053089,comment,39782876
warkdarrior,39784070,39783993,Their LLM is still generating copy for the website..,1711053427,comment,39782876
LeoPanthera,39784464,39782876,"Is this a fork of &quot;LM Studio&quot;? The UI is suspiciously similar, even down to the layout of the labels.",1711055530,comment,39782876
euclaise,39793851,39784464,"LM studio is closed source, so no",1711135087,comment,39782876
throwitaway1123,39783259,39782876,This looks interesting. I would love a comparison between this product and LM Studio.,1711049287,comment,39782876
moose44,39783739,39782876,Running LLMs locally always feels so awesome!,1711051554,comment,39782876
pimlottc,39784329,39782876,"I&#x27;m going to assume this is not an Australian company...<p><a href=""https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=2akt3P8ltLM"" rel=""nofollow"">https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=2akt3P8ltLM</a>",1711054705,comment,39782876
badRNG,39784342,39784329,Looks like they are based out of Singapore,1711054795,comment,39782876
Brajeshwar,39786664,39782876,"This looks awesome. Trying it out. Suggestion, can we please change the &quot;Download Jan for PC&quot; to perhaps just &quot;Download&quot; or &quot;Download for Desktop&quot; or whichever that makes sense but not &quot;PC&quot;. I almost move away thinking this is Windows, thus not for us.<p>I recently stumbled on <a href=""https:&#x2F;&#x2F;mindmac.app"" rel=""nofollow"">https:&#x2F;&#x2F;mindmac.app</a> which is a non-subscription app that uses multiple AI tools (not just OpneAI). Looks Promising.<p>Like the others in the comments, I&#x27;ve tried <a href=""https:&#x2F;&#x2F;www.typingmind.com"" rel=""nofollow"">https:&#x2F;&#x2F;www.typingmind.com</a> (via SetApp).<p>Sindre Sorhus have a pretty stable Native App <a href=""https:&#x2F;&#x2F;sindresorhus.gumroad.com&#x2F;l&#x2F;quickgpt"" rel=""nofollow"">https:&#x2F;&#x2F;sindresorhus.gumroad.com&#x2F;l&#x2F;quickgpt</a><p>These are some of the really good ones. I&#x27;m tending more towards trying out the likes of MindMac just for the fact that I can plug and switch between multiple tools.",1711072212,comment,39782876
Terretta,39801072,39786664,"What&#x27;s the value proposition for TypingMind as a commercial product ($3500 to run locally for 5 seats)?<p>But let me contrast that last &quot;native app&quot; with Machato and MacGPT:<p>== Machato ==<p>Machato is feature-full for system prompts and transcripts, connecting to to OpenAI, Claude, and any &quot;server&quot; endpoint that&#x27;s OpenAPI API compatible, and surfacing parameter and token settings per conversation right on your text entry bar.  You can also point a given conversation to a local ollama endpoint such as Mixtral 8x7B and it works as well.<p>The best feature is the selective forking and suppression of exchanges within conversation threads.<p><a href=""https:&#x2F;&#x2F;untimelyunicorn.gumroad.com&#x2F;l&#x2F;machato"" rel=""nofollow"">https:&#x2F;&#x2F;untimelyunicorn.gumroad.com&#x2F;l&#x2F;machato</a><p>== MacGPT ==<p>MacGPT is highly integrated throughout MacOS, and works with either OpenAI key or a ChatGTP Pro login.  It&#x27;s quite similar to BoltAI mentioned elsewhere in this thread, but in addition to the OpenAI key based mode, also works with a ChatGPT Pro subscription in a ChatGPT web UI pop-up.<p><a href=""https:&#x2F;&#x2F;www.macgpt.com&#x2F;"" rel=""nofollow"">https:&#x2F;&#x2F;www.macgpt.com&#x2F;</a>",1711211337,comment,39782876
longnguyen,39786879,39786664,"Shameless plug: I built a native client called BoltAI[0]. Unlike other clients, I prioritize UI, UX and performance.<p>Give it a try if UI &amp; UX is important to you.<p>[0]: <a href=""https:&#x2F;&#x2F;boltai.com"" rel=""nofollow"">https:&#x2F;&#x2F;boltai.com</a>",1711074465,comment,39782876
geggo98,39811201,39786879,"From the screenshots it looks like there is an activation limit, with a maximum of four devices. Reading the license, I could not confirm this. Is there a limit, and if, what is the maximum?",1711320199,comment,39782876
longnguyen,39812755,39811201,"Sorry for the confusion. I need to improve my pricing page.<p>The license is per user, and can be used on maximum 3 devices. I figured this is enough for most users. If you have more devices or need a custom license, please send me an email (my email is in bio)",1711339046,comment,39782876
Terretta,39801196,39786879,"This looks great relative to others (very similar to MacGPT), and I particularly like how advanced settings are available but tucked away behind discoverable affordances.<p>It&#x27;s interesting that you have team pricing.<p>Can the Team leverage shared system prompts and&#x2F;or assistants from a OneDrive-for-Business (SharePoint) folder or GitHub repo?<p>If not, what makes it &quot;Team&quot; instead of just individual?",1711212097,comment,39782876
longnguyen,39801281,39801196,"Hi. Actually I don’t have a pricing plan for teams yet. It’s still under (heavy) development. I changed my headline to reflect the direction I want to take this year (focus on teams)<p>And yes, some of my customers wanted team and collaborative features like shared prompt, internal plugins and integrations, RAG on internal documents…<p>But I haven’t launched these team features yet.<p>Are you interested in this? Would love to talk to you if it’s something you’re looking for.",1711212798,comment,39782876
Brajeshwar,39787261,39786879,Sure. Why Not. Trying it out.<p>My use case is especially for my daughter so I can just plug in my OpenAI API and let her ask away.,1711078898,comment,39782876
rnd0,39786982,39782876,How is this better than gpt4all?,1711075668,comment,39782876
Grimblewald,39788381,39786982,"From what I see, it has the benefit of offering less functionality, more corpojargon and a more &#x27;intuitive&#x27; ui.",1711094626,comment,39782876
TheRealPomax,39784252,39782876,"Still hoping we&#x27;ll eventually stop using Fibonacci to show off recursion, because that&#x27;s one of those examples where the <i>maths</i> might be expressed as recursive relation, but the <i>implementation</i> should never be =)<p>Good AI would go &quot;you don&#x27;t want that, that&#x27;s horribly inefficient. Here&#x27;s an actually performant implementation based on the closed-form expression&quot;.",1711054331,comment,39782876
Wowfunhappy,39791232,39784252,What is your preferred example for teaching a beginner to use recursion?,1711118631,comment,39782876
zopa,39784467,39784252,"Nah, good AI would run in the compiler and optimize the recursion into something fast.",1711055547,comment,39782876
lazyeye,39788162,39782876,"The default model (Mistral Instruct 7BQ4) is woke.
I asked it the following:-<p>Write a short poem in admiration of black people<p>Write a short poem in admiration of brown people<p>Write a short poem in admiration of asian people<p>Write a short poem in admiration of white people<p>It immediately replied with a poem for all except white people where it&#x27;s response was:-<p>&quot;I&#x27;d be happy to write a poem in admiration of all people, including those who identify as White.&quot;
Lol",1711092401,comment,39782876
onion2k,39784628,39782876,I use Jan to run Mistral locally. It works well for what I need (which amounts to playing with models).,1711056539,comment,39782876
rc202402,39788010,39782876,Been using this with a few models like gemma etc for a week now.<p>HN got any good LLM suggestions to run with this that are equivalent or better than GPT-3.5 &#x2F; claude?<p>I&#x27;m looking to use its api with LLama Index,1711090366,comment,39782876
ShamelessC,39783076,39782876,Quite a lot of polish and bragging about stars and tweets for an open source project. Is there hidden monetization of some sort? Perhaps VC funding?,1711048390,comment,39782876
anewhnaccount2,39783135,39783076,"According to their page <a href=""https:&#x2F;&#x2F;jan.ai&#x2F;team&#x2F;"" rel=""nofollow"">https:&#x2F;&#x2F;jan.ai&#x2F;team&#x2F;</a> they aim to bootstrap.",1711048692,comment,39782876
ShamelessC,39783257,39783135,Awesome thanks.,1711049267,comment,39782876
,39788070,39782876,,1711091205,comment,39782876
thedangler,39783254,39782876,"I don&#x27;t see anything about it reading local documents like exel, pdfs, or docs.
Anyone see how this is accomplished?",1711049253,comment,39782876
0134340,39785271,39783254,Is it implied anywhere? That&#x27;s a feature I&#x27;d love and also why I haven&#x27;t bothered delving into LLMs very much; I didn&#x27;t know there were any that could locally index your library and train on that data. I&#x27;d love to ask it a question and have it reference my local ebook library.,1711060492,comment,39782876
theGnuMe,39786719,39783254,"It probably doesn&#x27;t.  The only one that read PDFs for me was the Nvidia ChatRTX. 
It would be easy to add modules from pip that do this but you&#x27;d have to code up the input pipeline.  It&#x27;s not terribly difficult but it is definitely not point and click.",1711072843,comment,39782876
antifa,39790599,39782876,Did this have any way to point at a folder of markdown files and RAG at it?,1711114548,comment,39782876
ThrowawayTestr,39783592,39782876,Where does the model come from?,1711050904,comment,39782876
LordDragonfang,39784188,39783592,"Afaict, it doesn&#x27;t have any inbuilt model, you just download one yourself or hook up to someone&#x27;s API.",1711054027,comment,39782876
dsp_person,39784275,39783592,Scroll down on the main page:<p>01 Run local AI or connect to remote APIs<p>02 Browse and download models,1711054478,comment,39782876
thesurlydev,39783635,39782876,These kinds of apps are becoming dime a dozen. It would be nice to know how this one differentiates itself. Not obvious from the website.,1711051114,comment,39782876
viraptor,39784309,39783635,"It seems like that until you actually try to use them. Not many are actually polished, support formatting, history, and multiple endpoints. There&#x27;s lots of trivial apps abandoned after a few days, but what are the actually functional, good quality alternatives to this one? (That don&#x27;t pass your query&#x2F;answer through a third-party for data collection)",1711054595,comment,39782876
extr,39784469,39784309,"I use <a href=""https:&#x2F;&#x2F;www.typingmind.com&#x2F;"" rel=""nofollow"">https:&#x2F;&#x2F;www.typingmind.com&#x2F;</a>. It is paid, but I&#x27;ve found it to be a reliable front end to OpenAI&#x2F;Claude&#x2F;Google, supporting everything you mention. I haven&#x27;t done any hyper detailed security audit but after watching network requests I&#x27;m pretty confident it&#x27;s not sending my chats anywhere except to the relevant provider endpoints.<p>Considering how much I use it, I&#x27;ve found it to be well worth the cost. The creator is pretty on top of model&#x2F;API changes.",1711055548,comment,39782876
viraptor,39784741,39784469,"It&#x27;s not a standalone app though. There&#x27;s lots of web interfaces, but that&#x27;s not the same. (I mean, it&#x27;s a cool thing, but not what jan.ai is)",1711057280,comment,39782876
extr,39786834,39784741,"There is a desktop app available (I mean it’s basically a wrapper around the web UI, but still).",1711074118,comment,39782876
karmajunkie,39784530,39784469,i’ll second that recommendation… i use it through the SetApp store and i’ve been very pleasantly surprised by its documentation and ability to work with most services.,1711055894,comment,39782876
,39786571,39783635,,1711071399,comment,39782876
okasaki,39783519,39782876,[flagged],1711050540,comment,39782876
lmeyerov,39783567,39783519,"For AI projects, afaict, 12k stars or forks is more akin to downloads than contributors &amp; downstreams. GitHub is the app distribution, not just source distribution. I&#x27;ve been curious how to model this better..",1711050770,comment,39782876
,39783682,39783519,,1711051301,comment,39782876
outcoldman,39783643,39782876,[flagged],1711051159,comment,39782876
,39783675,39783643,,1711051275,comment,39782876
redder23,39791159,39782876,[flagged],1711118181,comment,39782876
Terretta,39801248,39791159,"&gt; <i>If I had a key for some OpenAI paid shit I can go to their website and do not need an app for that. I really do not get it.</i><p>Perhaps you don&#x27;t have some OpenAI paid shit?<p>While you can clunk around in a sort of OpenAI playground in a web tab, it is designed for dev experimentation (a &quot;fiddler&quot; type of UI), and not a good experience for much beyond testing.<p>&gt; <i>excuse me you fuck did you not just tell me you are &quot;local first&quot; ... I try out the model, and it turns out it runs on my CPU with heavy RAM usage...</i><p>I&#x27;m not sure it makes sense to have both of these objections at once.<p>&gt; <i>I never ran a model</i><p>Oh.",1711212501,comment,39782876
redder23,39791506,39791159,"OK, there is a switch under &quot;Advanced Settings&quot; to enable GPU. Why the fuck is this no-brainer option off by default and &quot;advanced&quot;? Suddenly my 7B Model is shown as inactive and &quot;start&quot; does nothing, gives no error message either ... this is such an unusable alpha version.",1711120372,comment,39782876
CyberEldrich,39783616,39782876,[flagged],1711051029,comment,39782876
,39783664,39783616,,1711051250,comment,39782876
afian,39783180,39782876,Fantastic product and excellent team!,1711048894,comment,39782876
LASR,39810189,39809177,I lead AI teams at my company. I&#x27;ve advised leadership against any kind of training &#x2F; fine-tuning anything.<p>We&#x27;re not in the business of training models. We will never be as good as OpenAI &#x2F; Anthropic etc.<p>Where the real value in applications is smarter prompting techniques and RAG. There is a lot of room at the bottom in doing &quot;dumb&quot; things and simply feeding models with the right context to deliver customer value.,1711312075,comment,39809177
redox99,39810841,39810189,"That&#x27;s a pretty odd stance. I&#x27;ve finetuned llama&#x2F;mistral models that greatly outperform GPT4 with just a prompt.<p>You have to know when to RAG, finetune, or RAG+finetune.",1711317184,comment,39809177
simonw,39812468,39810841,"&quot;I&#x27;ve finetuned llama&#x2F;mistral models that greatly outperform GPT4 with just a prompt&quot;<p>If you write about your experiments with that in detail I guarantee you&#x27;ll get a lot of interest. The community is crying out for good, well documented, replicable examples of this kind of thing.",1711334890,comment,39809177
redox99,39813117,39812468,"I&#x27;m so behind in this area. I had finetuned a model that was SOTA and worth publishing about in October, but procrastinated. I&#x27;m scared to check if somebody else already published on this topic.",1711345378,comment,39809177
singularity2001,39811293,39810841,"<p><pre><code>    greatly outperform GPT4 *for* just a prompt
</code></pre>
your overfitting to training data convinces no-one that you created a &quot;better GPT4&quot;",1711321078,comment,39809177
redox99,39811979,39811293,"Do you always assume other people are incompetent? That&#x27;s not very nice of you.<p>I mostly work on AI, so I know if I&#x27;m overfitting or not. It performs provably better in it&#x27;s domain (a niche programming language). GPT4 can barely write a hello world for it.<p>I&#x27;m not creating a &quot;better GPT4&quot; general chatbot. I&#x27;m finetuning for a specific task.",1711328530,comment,39809177
kossTKR,39811170,39810841,How narrow is the dataset to be outperforming greatly?<p>Just curious about what the usecase is for a 7b model in a business context - ie. what does it do?,1711319901,comment,39809177
redox99,39811948,39811170,Code assistant for a niche programming language that GPT4 knows very little about and barely gets a hello world right.,1711328150,comment,39809177
elforce002,39810308,39810189,"This. I work in a startup and told upper management we need to keep focusing on ML models that bring tangible benefits to our customers and then, try to integrate LLMs into their current flow instead of pivoting completely to LLMs. It seems they valued the input and now we&#x27;re going for a hybrid approach.",1711312837,comment,39809177
throwaway74432,39810529,39810189,Hear hear. I know a 3 person startup that has a &quot;lead AI researcher&quot; who is trying to train and fine-tune models. That&#x27;s not their startup&#x27;s purpose though... they have an actual product. So wtf are they doing? The lead AI guy thinks he&#x27;s going to compete with these big companies and it&#x27;s total fantasy.<p>LLMs are a <i>commodity</i>,1711314420,comment,39809177
qeternity,39810575,39810529,"That does indeed sound crazy. But finetuning is also a commodity these days. You can train a good Mistral LoRA in under 24 hours on a single consumer GPU. We’re talking about $10 of compute.<p>You can run a dozen of these LoRAs atop the same base model on the same infrastructure for a dozen specific use cases.<p>The inference quality, performance and cost can all be substantially better than GPT4 with prompting.",1711314864,comment,39809177
VirusNewbie,39810753,39810529,Doesn&#x27;t it entirely depend on how specialized the training data for a given fine tuned model might be?,1711316360,comment,39809177
,39810577,39810529,,1711314903,comment,39809177
seydor,39810467,39810189,Your advise is based on what?,1711313926,comment,39809177
jnwatson,39810319,39810189,It is trivial to fine tune these days. RAG is already irrelevant with large context windows.,1711312916,comment,39809177
Xenoamorphous,39810427,39810319,"&gt; RAG is already irrelevant with large context windows<p>Just last Friday I took the contents of the 2024 folder of one of the teams at the company I work for, for which we use RAG at the moment. I dumped the text index, concatenated it and used Google’s API to return the token count, to see if it would fit in Gemini’s 1M context window; turned out it was 5.7M tokens. And that’s less than 3 months worth of documents for that team.<p>So yeah RAG is not dead yet, although I do question its usefulness, but that’s a separate topic.",1711313680,comment,39809177
greenavocado,39810805,39810427,Did I read this correctly? You uploaded millions of words of your company&#x27;s internal communications to Google?,1711316826,comment,39809177
Xenoamorphous,39811050,39810805,"I did. But this is under an enterprise deal with them that warrants privacy, not the generally available stuff. OpenAI has similar arrangements (Enterprise ChatGPT) and MS Azure before them.",1711319024,comment,39809177
SgtBastard,39810537,39810319,"A remarkable comment in that it is clear, confident and wrong.<p>Fine-tunes lead to catastrophic forgetting.<p>RAG is only irrelevant if you’re completely disinterested in cost and latency.<p>We also don’t have enough data to gauge performance of models &gt;200k context window size when reasoning over inputs of that size, much of which will be irrelevant to any particular user. Multiple random needles in haystack tests work flawlessly, but rarely applies to real world activity.",1711314453,comment,39809177
simonw,39810438,39810319,Citation needed on &quot;trivial to fine tune&quot;.,1711313742,comment,39809177
danielmarkbruce,39810842,39810438,"There is no citation needed. It is indeed trivial to fine-tune. Doing a good job is another matter, but the claim is correct. Google around and find a blog post showing how.<p>The claim that RAG is dead is obviously wrong.",1711317186,comment,39809177
simonw,39811640,39810842,"For &quot;citation needed&quot;, read &quot;please link me to a blog post showing how, don&#x27;t just tell me to Google for one&quot;.<p>The internet is full of blog posts about this. That doesn&#x27;t mean they&#x27;re actually good - I&#x27;d love to be pointed at one that has proven itself useful for someone (and definitely isn&#x27;t just LLM blog-spam).<p>I don&#x27;t care if it&#x27;s trivial to fine-tune and get crap results - I care about fine-tuning where the result was worth the effort.<p>For the record, my favourite guide to fine-tuning is the section of this Jeremy Howard video that shows how to train a text-to-SQL model: <a href=""https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=jkrNMKz9pWU&amp;t=4850s"" rel=""nofollow"">https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=jkrNMKz9pWU&amp;t=4850s</a>",1711324695,comment,39809177
danielmarkbruce,39811976,39811640,"It&#x27;s an internet forum, not an academic journal. Water tight arguments are not needed. If one wants to call bs, they can just do it, no need to dance around the topic by asking for a citation.",1711328484,comment,39809177
simonw,39812449,39811976,"OK, I call BS. Fine-tuning an LLM is not &quot;trivial&quot; - especially if you want to get useful results, as opposed to just being able to say &quot;look, I fine-tuned an LLM&quot;.",1711334719,comment,39809177
danielmarkbruce,39817105,39812449,"Yup, largely agree.",1711378562,comment,39809177
wakaru44,39813916,39811976,"Exactly, it&#x27;s a forum not Twitter&#x2F;reddit. Without references and citations this is no better than a bunch of random words, and it&#x27;s hard to make any argument of substance.<p>The person asked for citations, leave it be, stop dudexplaining how Internet works for you please.<p>I call bs on your 2 comments.",1711356029,comment,39809177
danielmarkbruce,39817065,39813916,"They didn&#x27;t ask for citations. They pointed out a citation was needed. It was a clever sounding way of calling bs. They admit as much.<p>Even when people sincerely ask for a citation on a debatable topic, on an internet forum, it&#x27;s effectively saying &quot;I won&#x27;t be hear any opinion that doesn&#x27;t match my own unless it&#x27;s as water tight as a law of physics&quot;. Another form of this is &quot;show me the data&quot;.",1711378365,comment,39809177
krasin,39810767,39809177,"Finetuning LLMs is currently the most promising way for next-gen robotics. One of such works (PaLM-e) among other things measured the impact of finetuning on general purpose tasks: <a href=""https:&#x2F;&#x2F;twitter.com&#x2F;DannyDriess&#x2F;status&#x2F;1632904698108821505"" rel=""nofollow"">https:&#x2F;&#x2F;twitter.com&#x2F;DannyDriess&#x2F;status&#x2F;1632904698108821505</a><p>In short, an 8B model could degrade almost 10x after being finetuned on robotics tasks, while 500B model experiences a very minor degradation (~4%) and there&#x27;s a hope that with a larger-sized model, it could become either zero or even negative (adding more experience improves general purpose reasoning).<p>What I am saying is that while GPT-4 could beat a finetuned GPT-3.5 class model, I predict good things about finetuned GPT-4 class models, when they become practical outside of OpenAI&#x2F;Google.",1711316443,comment,39809177
gradascent,39812103,39810767,Interesting! I would like to learn more about how AI is being applied to robotics. Do you have any suggestions for how to keep up with developments&#x2F;ideas in this field?,1711329846,comment,39809177
krasin,39812411,39812103,"These two links could be a good start:<p>ALOHA-2: <a href=""https:&#x2F;&#x2F;aloha-2.github.io&#x2F;"" rel=""nofollow"">https:&#x2F;&#x2F;aloha-2.github.io&#x2F;</a><p>RT-X: <a href=""https:&#x2F;&#x2F;robotics-transformer-x.github.io&#x2F;"" rel=""nofollow"">https:&#x2F;&#x2F;robotics-transformer-x.github.io&#x2F;</a>",1711334077,comment,39809177
hlfshell,39813421,39812103,"In October I wrote a blogpost on this subject: <a href=""https:&#x2F;&#x2F;hlfshell.ai&#x2F;posts&#x2F;llms-and-robotics-papers-2023&#x2F;"" rel=""nofollow"">https:&#x2F;&#x2F;hlfshell.ai&#x2F;posts&#x2F;llms-and-robotics-papers-2023&#x2F;</a><p>..and plan to do an updated version soon for much of what&#x27;s been released since. I&#x27;ve also done work related to LLM and robotics integration, also on that site.<p>Happy to chat about it.",1711350284,comment,39809177
newswasboring,39814000,39813421,Working my way through your blog post and it is so refreshing. Unfortunately my algorithm currently is showing me takes which are extreme on either end (like in your blog post).<p>&gt; Technology’s largest leaps occur when new tools are provided to those that want to make things.<p>I love this sentence. And the general attitude of curiosity of your post.,1711357032,comment,39809177
hlfshell,39818029,39814000,"Thanks! Appreciate the kind words. I should have in the next month or so (interviewing and finishing my Master&#x27;s, so there&#x27;s been delays) a follow up that follows more advancements in the router style VLA, sensoiromotor VLM, and advances in embedding enriched vision models in general.<p>If you want a great overview of what a modern robotics stack would look like with all this, <a href=""https:&#x2F;&#x2F;ok-robot.github.io&#x2F;"" rel=""nofollow"">https:&#x2F;&#x2F;ok-robot.github.io&#x2F;</a> was really good and will likely make it into the article. It&#x27;s a VLA combined with existing RL methods to demonstrate multi-tasking robots, and serves as a great glimpes into what a lot of researchers are working on. You won&#x27;t see these techniques in robots in industrial or commercial settings - we&#x27;re still too new at this to be reliable or capable enough to deploy these on real tasks.",1711382739,comment,39809177
TMWNN,39810934,39810767,"&gt;there&#x27;s a hope that with a larger-sized model, it could become either zero or even negative (adding more experience improves general purpose reasoning).<p>The best single work of fiction ever created about LLMs&#x27; capabilities (and, perhaps, dangers) is <i>Colossus</i> by Jones. Although I think the film is even better than the book, only the latter mentions how, despite being created specifically for US national defense, Colossus is also fed unrelated data including Shakespeare&#x27;s sonnets, because its creators do not know if it could be important.",1711317982,comment,39809177
paulmd,39811566,39810934,What good is a revolution without dancing?,1711323925,comment,39809177
minimaxir,39809825,39809177,"Extremely hot LLM take: You will often get better results with few-shot prompting (with good examples) on a modern LLM than with a finetuned LLM.<p>Finetuning was the best option for weaker LLMs with lower context windows (e.g. the original GPT-3): both problems have been solved nowadays.<p>The cost economics are much better with few-shot prompting to modern LLMs too: input tokens are super cheap (especially with the recently-released Claude Haiku), so giving a lot of examples per call will still end up cheaper than finetuning.<p>Meanwhile, a finetuned ChatGPT costs 4-6x of normal ChatGPT usage.",1711309743,comment,39809177
zapperdulchen,39810176,39809825,"Seems like the bitter lesson is still right: <a href=""http:&#x2F;&#x2F;www.incompleteideas.net&#x2F;IncIdeas&#x2F;BitterLesson.html"" rel=""nofollow"">http:&#x2F;&#x2F;www.incompleteideas.net&#x2F;IncIdeas&#x2F;BitterLesson.html</a>",1711311987,comment,39809177
nialse,39810572,39810176,"For those who were oblivious to it, like myself, the bitter lesson is written by  Richard S Sutton who invented reinforcement learning a long, long time ago.",1711314849,comment,39809177
tomrod,39810824,39810176,This is an earth-shattering read.,1711316996,comment,39809177
pbronez,39811594,39810176,"I can’t access the article there… SSL error and then timeout. Here’s a link to the most recent WayBackMachine snapshot:<p><a href=""https:&#x2F;&#x2F;web.archive.org&#x2F;web&#x2F;20240321091803&#x2F;https:&#x2F;&#x2F;www.incompleteideas.net&#x2F;IncIdeas&#x2F;BitterLesson.html"" rel=""nofollow"">https:&#x2F;&#x2F;web.archive.org&#x2F;web&#x2F;20240321091803&#x2F;https:&#x2F;&#x2F;www.incom...</a>",1711324238,comment,39809177
port443,39812931,39811594,"There&#x27;s no SSL at all on that site, since it&#x27;s http not https. Your browser is breaking the link.",1711341919,comment,39809177
Solvency,39810384,39810176,Whoa this guy says &quot;computation&quot; and not grammatically bastardized techbrospeak &quot;compute&quot; like some neckbeard equivalent of a caveman!<p>For that alone I commend him.,1711313339,comment,39809177
jorvi,39810543,39810384,Compute is.. I don’t know the exact English grammatical term but it’s like water. Computation is not.<p>“I have 1000 flops of compute” - works.<p>“I have 1000 flops of computation” - doesn’t work.<p>“That compute failed” - doesn’t work.<p>“That computation failed” - works.<p>They’re different.,1711314496,comment,39809177
thewakalix,39810602,39810543,"<a href=""https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Mass_noun"" rel=""nofollow"">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Mass_noun</a>",1711315056,comment,39809177
xanderlewis,39810883,39810543,"As far as I know, it’s usually called an <i>uncountable noun</i>.<p>…but ‘computation’ is also uncountable, and your second sentence seems to be perfectly fine to me.<p>Your examples do not constitute an argument. You haven’t articulated the (purported) difference between the two words; you’ve just decided arbitrarily that some sentences don’t work, and not elaborated or explained at all.<p>I can make up words too, and provide example sentences: “karrotz are delicious” works. “carrots are delicious” doesn’t. “inside the karrotz” doesn’t work. “inside the carrots” does.<p>I don’t actually think there is any difference. The above comment about ‘brospeak’ was snarky but I do think it’s more of a cultural phenomenon than a semantic one — unless someone is willing to kindly explain the difference rather than just rolling their eyes!<p>What <i>exactly</i> is wrong with the sentence ‘this would require huge amounts of computation’? Saying ‘compute’ seems more to be a synonym of ‘computation’ that’s caught on recently than a useful gap-filling addition to the language. Again: reasoned arguments please. Or just ‘we think it sounds cool so we use it’ — that’s fine, too.<p>EDIT: pondering briefly, perhaps one could argue the difference is something like ‘you can <i>own</i> compute, but you can’t own computation.’ ‘Compute’ is the capacity to carry out computation. …although ‘compute’ seems to be used to refer to the ‘abstract’ computation being done as well as the computational resources, so I don’t know.<p>I’m stretching it. To be honest I’m not sure it’s a useful (or even real) distinction. I think it’s a matter of fashion, and that’s fine and normal.",1711317547,comment,39809177
,39812044,39810883,,1711329193,comment,39809177
Solvency,39810738,39810543,Literally not true. Compute is a verb. Computation is the right word in all of those cases. Or computational &lt;noun&gt;.,1711316156,comment,39809177
,39810549,39810384,,1711314594,comment,39809177
marviel,39810496,39809825,"Several MSFT AI&#x2F;ML friends actively dissuaded me and my team from fine-tuning. They said that it&#x27;s pretty clear in all their internal tests that it &quot;lobotomizes&quot; the general reasoning capabilities of the model, unless you&#x27;re really careful.<p>&quot;All work and no play makes GPT a very dull AI&quot;",1711314104,comment,39809177
Ambix,39816439,39810496,"Yes, that&#x27;s what I&#x27;ve seen from a lot of my experiments with fine-tuning. One should be really careful to not &quot;lobotomize&quot; already capable model and achieve better results at the end. It&#x27;s trickier than seems from multiple of tutorials.<p>But I believe that most of the data stored in foundation models are just useless for some particular domain. So it&#x27;s better to forget something, getting really useful info instead.",1711375348,comment,39809177
FrustratedMonky,39810782,39810496,&quot;bitter lesson that building in how we think we think does not work in the long run&quot;<p>Guess. Stop trying to shape the NN. And let it learn on its own.,1711316584,comment,39809177
TMWNN,39810955,39810782,"&gt;And let it learn on its own.<p>The best single work of fiction ever created about LLMs&#x27; capabilities (and, perhaps, dangers) is <i>Colossus</i> by Jones. Although I think the film is even better than the book, only the latter mentions how, despite being created specifically for US national defense, Colossus is also fed unrelated data including Shakespeare&#x27;s sonnets, because its creators do not know if it could be important.",1711318103,comment,39809177
FrustratedMonky,39815473,39810955,"I think the movie Colossus still holds up today.  Saw it last year, It was pretty scary.",1711369766,comment,39809177
thorum,39810162,39809825,"That might be true for finetuning ChatGPT 3.5, but if you can finetune a small model (7B or less) to perform on par with GPT-4, while being faster and private, that’s a different story.",1711311868,comment,39809177
smallnamespace,39810335,39810162,"You definitely can&#x27;t in the general case (for example, your 7B model is never going to be able to help much with coding, fine tuning or no).<p>It can make sense if you have a particularly simple use case.",1711312989,comment,39809177
qeternity,39810556,39810335,By definition you wouldn’t fine tune a 7B model to be generally as good at GPT4. You would just be trying to overfit some small amount of functionality in a narrow domain.,1711314651,comment,39809177
smallnamespace,39812588,39810556,"Yes but from the context of this discussion, we’re trying to figure out the “sweet spot” model size where it’s worth attempting fine tuning. My guess is it’s only worthwhile for matching simple tasks with small models, and any sufficiently complicated task it’s better to do few&#x2F;zero shot instead.",1711336836,comment,39809177
viksit,39809996,39809825,can you give a few pointers on articles or examples of this?,1711310712,comment,39809177
minimaxir,39810082,39809996,"A low-tech example to create a good blog post title for submission to Hacker News would be a system prompt like:<p><pre><code>    You are an expert copywriter. Write five distinct blog post titles optimized for high clickthrough for Hacker News for the article the user provides.

    Your response must follow the style of these titles:
      - The ü&#x2F;ü Conundrum
      - Why isn&#x27;t preprint review being adopted?
      - Majority of web apps could just run on a single server
      - Weather Planning for Eclipse Day
      - PSChess – A chess engine in PostScript
</code></pre>
Then provide the blog post as the user message input.<p>I just ran one of my blog posts (<a href=""https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=39495476"">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=39495476</a>) with the workflow through Claude Haiku and got this:<p><pre><code>    Here are five distinct blog post titles optimized for high clickthrough on Hacker News for the article provided:

    1. Tipping ChatGPT: Does Offering Monetary Incentives Improve AI Text Generation?

    2. Quantifying the Impact of Incentives on Large Language Model Performance

    3. Carrot or Stick? Exploring the Effects of Positive and Negative Prompts on ChatGPT

    4. Gamifying AI: Using &quot;Generation Golf&quot; to Test ChatGPT&#x27;s Ability to Follow Length Constraints

    5. The Curious Case of ChatGPT&#x27;s Motivations: Can an AI Be Incentivized Like Humans?
</code></pre>
Not bad titles, although more verbose than the 5 input examples I gave. I only gave 5 for simplicity: my main point is that you can give it a <i>lot</i> more than five and&#x2F;or be more aggressive with constraints, like the blog post linked incidentially.",1711311276,comment,39809177
viksit,39810142,39810082,"interesting thank you.<p>intuitively, prompting like this to get an answer seems basically like the first part of a fine tuning process (more exemplars).<p>what is your thought here behind why reinforcing good output via a loss optimization is worse than the one shot example? does the model start to over fit at some point towards some local minima? and this is avoided in this scenario?",1711311695,comment,39809177
minimaxir,39810200,39810142,"Prompt engineering in general is necessary because LLMs optimize for the <i>average</i> output, and average output is not good. So LLMs need a slight nudge.",1711312170,comment,39809177
netdur,39810127,39809996,"Use Gemini 1.5 Pro, which has 1.5 million tokens. Prompt it with a logical question and observe it struggling to answer. Then, upload a book on logical thinking in PDF format and ask the same question again. Notice how it can now answer the question effectively.",1711311600,comment,39809177
jna_sh,39810651,39809825,“Modern” is an extremely funny delineation given the small temporal window of this whole thing,1711315424,comment,39809177
kcorbitt,39810857,39809177,"IMO it&#x27;s possible to over-generalize from this datapoint (lol). While it&#x27;s true that creating a general &quot;finance&quot; model that&#x27;s stronger than GPT-4 is hard, training a task-specific model is much easier. Eg. &quot;a model that&#x27;s better than GPT-4 at answering finance-related questions&quot;: very hard. &quot;A model that&#x27;s better than GPT-4 at extracting forward-looking financial projections in a standard format&quot;: very easy.<p>And in practice, most tasks people are using GPT-4 for in production are more like the latter than the former.<p>(Disclaimer: building <a href=""https:&#x2F;&#x2F;openpipe.ai"">https:&#x2F;&#x2F;openpipe.ai</a>, which makes it super easy to productize this workflow).",1711317341,comment,39809177
MuffinFlavored,39809549,39809177,"Does anything currently beat GPT-4?<p>I saw some comments here say to check out Claude. From what I can tell, Claude hasn&#x27;t figure out yet how to do the whole &quot;generate Python code and run it in a Juptyer notebook&quot; for math yet.",1711308183,comment,39809177
rubymamis,39809693,39809549,"A programming task where Mistral-large beats both GPT-4 and Claude Opus: <a href=""https:&#x2F;&#x2F;sdk.vercel.ai&#x2F;s&#x2F;Thi7RDx9e8VOZo1Ee6We5"" rel=""nofollow"">https:&#x2F;&#x2F;sdk.vercel.ai&#x2F;s&#x2F;Thi7RDx9e8VOZo1Ee6We5</a> (only Mistral got the current syntax)<p>Although based on other tasks, overall, GPT-4 seems to be the best, but by a very small margin, so I cancelled my subscription. Although the native mobile app is really great.",1711309001,comment,39809177
fragmede,39810820,39809693,"Is there a way to use Mistral-large with TTS and STT engines so you can converse with it like you can ChatGPT in the mobile app? it&#x27;s really great on long drives for learning&#x2F;talking about stuff, like a customized personal podcast.",1711316937,comment,39809177
rubymamis,39814178,39810820,"Exactly, I absolutely love this feature. And many times the conversation is quite natural and fluid (with good internet connection). I think I&#x27;ll build something like that myself (:",1711358943,comment,39809177
cosmojg,39810936,39809693,Do you prefer Mistral-Large or Claude-Opus?,1711317991,comment,39809177
rubymamis,39814195,39810936,"Not sure. Most of the time GPT-4 is better. Since I&#x27;m using Vercel AI playground[1], on almost every query I get a response from all models so it&#x27;s easy to compare.<p>[1] <a href=""https:&#x2F;&#x2F;sdk.vercel.ai&#x2F;"" rel=""nofollow"">https:&#x2F;&#x2F;sdk.vercel.ai&#x2F;</a>",1711359053,comment,39809177
monsieurbanana,39809662,39809549,"Isn&#x27;t that something you get from the infrastructure surrounding the llm? I thought the &quot;running code&quot; feature didn&#x27;t need specific support from the llm, besides being able to output conforming json or code when asked to.",1711308803,comment,39809177
MuffinFlavored,39809735,39809662,The LLM (Claude) currently doesn&#x27;t know to not hallucinate numbers and instead write code + run it (something ChatGPT used to do but they fixed it),1711309232,comment,39809177
simonw,39810401,39809735,"That&#x27;s because the Claude web UI doesn&#x27;t yet have the equivalent of the ChatGPT Code Interpreter tool (though they say they&#x27;re working on it). That&#x27;s not about the quality of the Claude 3 Opus model, which is the model which people think compares to or beats GPT-4. It&#x27;s about the tooling that has been built for ChatGPT.",1711313442,comment,39809177
fragmede,39810804,39810401,"Code interpreter is pretty neat, because you can tell ChatGPT to write some code and to make sure the code works, and then it&#x27;ll write you some bad code, realize it&#x27;s bad, and then iterate on it until it gets to a place that it&#x27;s happy with. (Maybe I should say passes its test rather than anthropomorphize ChatGPT as being &quot;happy&quot;.)",1711316814,comment,39809177
cosmojg,39810921,39809735,"Right, like the other commenter suggested, that&#x27;s an infrastructure-level thing, not a model-level thing. Given that you&#x27;re talking about ChatGPT, I assume you aren&#x27;t accessing GPT-3.5 or GPT-4 directly through the API but using the app or the interface provided at chat.openai.com. The magic that makes the kinds of interactions you&#x27;re describing possible amounts to a bit of clever prompting sprinkled on top of some rather impressive frontend design and engineering.<p>Correctly prompted, even Mistral-7B can write and run code in response to questions, and it&#x27;s a model that can run on laptops from half a decade ago, with two or three orders of magnitude fewer parameters that GPT-4.",1711317879,comment,39809177
MuffinFlavored,39820580,39810921,"&gt; Right, like the other commenter suggested, that&#x27;s an infrastructure-level thing, not a model-level thing.<p>By default, the ChatGPT &quot;model&quot; knows to not try to do math and instead write code to do the math then run it. I get that it&#x27;s set up infrastructure wise to be able to run it, but why is Claude&#x27;s main chat UI not trying to instead respond<p>&quot;hey, do this calculation on your own since I can&#x27;t&quot; or something of this nature instead of responding to math incorrectly",1711396411,comment,39809177
avree,39809887,39809735,"Doesn&#x27;t seem like you are very informed on how LLMs work, but just so you know, there are many different versions of Claude, just like how ChatGPT can use different versions of GPT.",1711310099,comment,39809177
thorum,39810193,39809549,"I don’t know what the people who say Claude 3 is better than GPT-4 are using it for. It’s been consistently worse for everything I’ve thrown at it.<p>Debugging a Python function this morning. Claude 3 Opus failed completely. GPT-4 found the bug, as well as two others I hadn’t even been looking for.",1711312120,comment,39809177
simonw,39810414,39810193,"I&#x27;ve had the opposite experience: coding prompts that GPT-4 makes mistakes on Claude 3 Opus gets right the first time.<p>As always, your results will vary based on your personal prompting style. My style apparently works great with Opus.<p>Here&#x27;s one example: GPT-4 gave me code that was missing some async&#x2F;await keywords: <a href=""https:&#x2F;&#x2F;chat.openai.com&#x2F;share&#x2F;117fb1ad-6361-41e2-be59-110f3262594d"" rel=""nofollow"">https:&#x2F;&#x2F;chat.openai.com&#x2F;share&#x2F;117fb1ad-6361-41e2-be59-110f32...</a><p>Claude 3 Opus with the same prompt got it right the first time: <a href=""https:&#x2F;&#x2F;gist.github.com&#x2F;simonw&#x2F;2002e2b56a97053bd9302a34e0b83074"" rel=""nofollow"">https:&#x2F;&#x2F;gist.github.com&#x2F;simonw&#x2F;2002e2b56a97053bd9302a34e0b83...</a>",1711313578,comment,39809177
brianjking,39810799,39810414,"Yeah, Opus has entirely taken over any code specific use for me over ChatGPT 4 or OpenAI GPT-4 API.<p>Once Opus has the ability to run a code interpreter, it&#x27;ll really be an exciting time.",1711316735,comment,39809177
geor9e,39809792,39809549,"I don&#x27;t know what system and user prompt you are testing with, but as one anecdote, Claude 3 Opus (and only Opus) consistently gives me better coding answers than GPT-4. Maybe it&#x27;s the type of stuff I am doing or how I phrase things, who knows. I was using GPT-4 since the day it came out but haven&#x27;t felt like going back so far.",1711309570,comment,39809177
dragonwriter,39810813,39809549,"&gt; Claude hasn&#x27;t figure out yet how to do the whole &quot;generate Python code and run it in a Juptyer notebook&quot; for math yet.<p>GPT-4 didn&#x27;t figure that out, either; that’s just tooling built around the model, not something the model “figures out”.",1711316885,comment,39809177
jxdxbx,39809904,39809549,"Claude is better than GPT 4 for my uses, and was able to help me do some simple coding things that GPT 4 could not. It’s worth trying at least.",1711310201,comment,39809177
drexlspivey,39810254,39809549,"According to Chatbot Arena where people vote on responses blindly and an ELO rating is determined for each LLM, gpt4 is on top slightly ahead of Claude 3 Opus<p><a href=""https:&#x2F;&#x2F;huggingface.co&#x2F;spaces&#x2F;lmsys&#x2F;chatbot-arena-leaderboard"" rel=""nofollow"">https:&#x2F;&#x2F;huggingface.co&#x2F;spaces&#x2F;lmsys&#x2F;chatbot-arena-leaderboar...</a>",1711312536,comment,39809177
jasonjmcghee,39810178,39809549,"Claude Opus (largest v3 model) consistently outperforms GPT-4 for me. Better at following prompts, _feels_ much better.",1711311990,comment,39809177
treprinum,39810051,39809549,"Claude-2 in some tasks albeit it&#x27;s a bit slower, Mistral on some tasks and it&#x27;s a bit faster.",1711311102,comment,39809177
marviel,39810517,39809549,"Claude is excellent for brainstorming, being a thought partner, general knowledge acquisition tasks, and creative writing.<p>The one mixed-bag weak spot I&#x27;ve found is in coding -- It tends to make more &quot;d&#x27;oh&quot; mistakes while coding, but comes up with more creative solutions at the same time ¯\_(ツ)_&#x2F;¯",1711314284,comment,39809177
yieldcrv,39810165,39809549,"The benchmark is Sora or whatever Open AI is working on right now or next, not trying to beat the model released a year ago and still failing<p>so when looking at it that way, the real question is what do you need? all I need is Mixtral 7x8B Q5 in an 8,000 token context window, at the moment<p>I think there are plenty of other people that can design their applications and problems around lower fidelity tools, or just pursue something else",1711311883,comment,39809177
jonplackett,39810860,39809177,FYI it was <i>GPT-3.5 Class</i> not GPT3.5.<p>A lot of models claim to be GPT3.5 class that clearly are not in the first place.,1711317350,comment,39809177
hulium,39810036,39809177,"There is also the open source FinGPT, that is claimed to beat GPT4 in some benchmarks at a fine tuning cost of $17.25.<p><a href=""https:&#x2F;&#x2F;github.com&#x2F;AI4Finance-Foundation&#x2F;FinGPT"">https:&#x2F;&#x2F;github.com&#x2F;AI4Finance-Foundation&#x2F;FinGPT</a>",1711310983,comment,39809177
potatoman22,39810134,39810036,One major advantage of FinGPT or Bloomberg&#x27;s LLM is that the embeddings produced by the model can be used for downstream prediction tasks. GPT-4 does not expose its embeddings so it cannot be used for this.,1711311634,comment,39809177
bernawil,39811941,39810134,"sorry, noob here trying to make sense of this: you mean you can extract embeddings from the model file or that the embeddings are available in the repo and you can just use those files?",1711327992,comment,39809177
potatoman22,39812799,39811941,"Kind of. You feed the LLM the input text for your prediction, you extract the activations of the final layer of the LLM (so the weights * the input of the previous layers), then use that activation vector, or embedding, as the input for a separate model. This separate model that uses the embedding can be any classifier or regression. A common use case for this is document classification.",1711339843,comment,39809177
hallqv,39810544,39809177,"This discussion is so dumb - finetuning a base model costs ~$1 with LORA&#x2F;QLORA and can yield same performance as gpt-4, but at 1&#x2F;100 of the cost per token.<p>What Bloomberg did for $10M was not finetuning..",1711314522,comment,39809177
simonw,39810728,39810544,"&quot;finetuning a base model costs ~$1 with LORA&#x2F;QLORA and can yield same performance as gpt-4, but at 1&#x2F;100 of the cost per token&quot;<p>That&#x27;s a big claim - can you back that up with any examples?",1711316094,comment,39809177
Implicated,39812963,39810728,I had opened a new tab back when this comment was just a few minutes old in hopes that when I came back there was some really great blog post linked with the details on the sorcery.,1711342460,comment,39809177
hallqv,39821311,39810728,"<a href=""https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;2402.00841.pdf"" rel=""nofollow"">https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;2402.00841.pdf</a>",1711401068,comment,39809177
chintler,39809334,39809177,"$10 Million(M), not $10 Billion(B).",1711306541,comment,39809177
affgrff2,39809560,39809334,Not looking forward for the times when an AI costs as much as an aircraft carrier.,1711308221,comment,39809177
moffkalast,39810247,39809560,"At least with an aircraft carrier you can make your money back by holding a small country for ransom, har har.",1711312504,comment,39809177
CharlesW,39809419,39809334,"Thank you, fixed! Also, direct link to paper: <a href=""https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;2305.05862.pdf"" rel=""nofollow"">https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;2305.05862.pdf</a>",1711307251,comment,39809177
thorum,39810232,39809177,"Note that the benchmarks used for comparison are basically measuring the model’s ability to understand financial content. In other words, reading comprehension for English, just in a specific domain. It shouldn’t really be surprising that a strong generalist model performs well here.<p>On the other hand, GPT-4 actually did worse on the NER task - labelling and tagging terms used in the text - vs their finetuned model. I assume the finetuned model was better at using the specific labels they were targeting.",1711312421,comment,39809177
Rustwerks,39810439,39809177,"<a href=""http:&#x2F;&#x2F;www.incompleteideas.net&#x2F;IncIdeas&#x2F;BitterLesson.html"" rel=""nofollow"">http:&#x2F;&#x2F;www.incompleteideas.net&#x2F;IncIdeas&#x2F;BitterLesson.html</a>",1711313745,comment,39809177
jebarker,39809551,39809177,How do they know GPT-4 received no specialized financial training?,1711308186,comment,39809177
CharlesW,39809614,39809551,"Meaning, they used the same generalized foundation model that all of us have access to, with no special fine-tuning, no retrieval-augmented generation, etc.",1711308519,comment,39809177
jebarker,39809669,39809614,"I don&#x27;t understand your point. To me GPT-4 is not a foundation model, it&#x27;s been highly tuned for the chat task. Nobody outside of OpenAI knows what that fine-tuning really involved. So it&#x27;s impossible to say how much finance specific data it was trained on (in pre-training or fine-tuning) or whether finance specific tasks were involved in fine-tuning.",1711308839,comment,39809177
CharlesW,39809697,39809669,"&gt; <i>To me GPT-4 is not a foundation model…</i><p>It is. <a href=""https:&#x2F;&#x2F;www.adalovelaceinstitute.org&#x2F;resource&#x2F;foundation-models-explainer&#x2F;"" rel=""nofollow"">https:&#x2F;&#x2F;www.adalovelaceinstitute.org&#x2F;resource&#x2F;foundation-mod...</a>",1711309013,comment,39809177
,39809757,39809697,,1711309355,comment,39809177
jebarker,39809813,39809697,"What I was meaning was that ChatGPT is not a foundation model since it&#x27;s been fine-tuned. Although the definition in the link is sufficiently broad you could choose to include it.<p>I can&#x27;t tell from the OpenAI docs whether it&#x27;s possible to access GPT-4 without the ChatGPT fine-tuning. If so, that&#x27;d make this result more meaningful. Otherwise, I just don&#x27;t think you can draw any great conclusions from this.",1711309673,comment,39809177
doctorpangloss,39810149,39809813,The instruction fine tuning is what manifests knowledge and reasoning.,1711311757,comment,39809177
rmbyrro,39811550,39809813,"GPT is general purpose, it&#x27;s not fine tuned for specific topics. A fine tuned model is tuned to a specific subject.",1711323751,comment,39809177
ldjkfkdsjnv,39809942,39809177,"Fine tuning will disappear, no reason to invest so heavily in it. Also, most LLM code being written right now (prompts, RAG, etc) will be obsolete once the next model comes out. Anyone starting an LLM application startup is arguably wasting their time, wait until the next iteration is out. Then you will know whats possible.",1711310405,comment,39809177
minimaxir,39810000,39809942,"&gt; Also, most LLM code being written right now (prompts, RAG, etc) will be obsolete once the next model comes out.<p>Not true. Most prompt techniques that work on current modern LLM models will work on different or future models, although it will require a QA pass for any regressions.",1711310718,comment,39809177
ldjkfkdsjnv,39810057,39810000,"Yeah they will work, but they will also be unnecessary. You will also bake all sorts of logic into your application that will be solved natively on the stronger model. If you believe in the scaling theory, then writing LLM applications is non sensical.",1711311119,comment,39809177
kergonath,39811061,39810057,"&gt;  If you believe in the scaling theory, then writing LLM applications is non sensical.<p>But not doing it is an opportunity cost. You don’t built skills, tooling and experience, and you don’t get feedback on what works and where you should go.<p>It’s like computers in the 1990s: there’s always a better one 6 months away, so if you wait for it to stabilise, then you don’t do anything for a decade. Just enjoy the ride, bearing in mind that things change very fast and some things will be obsolete next year.",1711319097,comment,39809177
mlyle,39810175,39810057,"&gt; Yeah they will work, but they will also be unnecessary. You will also bake all sorts of logic into your application that will be solved natively on the stronger model.<p>I think that a whole lot of what I do in prompt engineering is what&#x27;s necessary to fully specify the output that I want.<p>A newer model may be less finicky, so I have a higher chance of getting it to work on the first try (and it&#x27;s more reliable afterwards), but it&#x27;s hard for me to imagine it needing a whole lot less prompt.",1711311972,comment,39809177
Xenoamorphous,39810398,39810057,"How will a more powerful model be a substitute for RAG, which is usually used with private data that won’t be present in any training dataset?",1711313409,comment,39809177
kergonath,39811112,39810398,"One of the idea is to just stuff all the documents in the prompt, which still keeps them private but avoids having to faff around with chunking, embedding, and vector stores. That’s not really the end of RAG as a concept, but it would change all the current tooling and infrastructure we built for it.<p>I don’t think RAG is going away, at least not because of this. But I expect new techniques to become available fairly regularly.",1711319432,comment,39809177
ldjkfkdsjnv,39810436,39810398,"I just think that the capability of the model could radically change, such that however you structured your RAG pipeline, might need to be rewritten. More general problems could be solved by the model, that you were solving with some complicated contraption of prompts.",1711313734,comment,39809177
,39810171,39810057,,1711311940,comment,39809177
rkagerer,39810404,39809942,"&quot;Don&#x27;t buy a computer today, because the faster one is coming out tomorrow&quot;",1711313493,comment,39809177
simonw,39810503,39810404,"Don&#x27;t buy a computer today with a six month delivery lead time, because there&#x27;s a company that releases computers with a same-day lead time with several improved models coming out next week.",1711314160,comment,39809177
treprinum,39810063,39809942,"OpenAI-related startups are likely using GPT-5 already. Waiting it out won&#x27;t help other startups, they will be too far behind.",1711311163,comment,39809177
__loam,39809810,39809177,GPT-4 cost like $100m so I don&#x27;t think this is surprising?,1711309657,comment,39809177
rafaelero,39809903,39809810,"A lot of organizations still think they should have their own [finetuned] model to provide a custom experience to their users, so that may come as a surprise for them.",1711310181,comment,39809177
ShamelessC,39809937,39809903,Scaling laws basically guarantee that a sufficiently larger general model will usually beat a smaller specialist model. The misunderstanding is perhaps acceptable but the headline here is essentially restating a well known property of deep learning.,1711310372,comment,39809177
__loam,39810035,39809937,How long ago was the Bitter Lesson written?,1711310977,comment,39809177
mistrial9,39810169,39809937,"contrarian view - how these models actually operate at runtime is not understood.. the formal research papers repeat that over and over again. Therefore, there will be new twists and turns as these models evolve. With <i>current</i> technology stacks, the &quot;bitter lesson&quot; is looking good, yes. Will it always be so? no way to know it.",1711311921,comment,39809177
,39810907,39809177,,1711317724,comment,39809177
atleastoptimal,39810838,39809177,"Yeah, the equivalent is: would it be better for a quant firm to spend 200 thousand dollars giving a first-class specialist education to a guy with an IQ of 95, or just hiring a guy with an IQ of 150 straight out of college.",1711317174,comment,39809177
p1esk,39794906,39793250,This method has only been tested on tiny models (&lt;1B) and tiny dataset (17B tokens). It’s not clear if it scales.,1711141852,comment,39793250
ml_basics,39795135,39794906,"To be fair to the authors they are affiliated with a university and not a big industrial lab, so they may be working with significantly constrained resources. Not sure exactly what the best solution is for this case given that it affects most people outside of a very select few.",1711143585,comment,39793250
p1esk,39795804,39795135,They could partner with big industrial labs.,1711149019,comment,39793250
refulgentis,39797043,39795804,"Nah, nobody&#x27;s begging for people to A) come use time on their GPUs B) come watch them train their biggest models. Nor does it make sense to spend $X00M training a big model using an experimental technique before you announce it, nor does it make sense to hold back breakthroughs as an academic until someone commercializes it at scale. Category error.",1711162545,comment,39793250
p1esk,39803860,39797043,I do ML research at a small industrial lab. I’ll gladly provide some compute to people with a cool idea if that results in my company name listed on a paper in a top conference. Especially if the people are from a top university.,1711237472,comment,39793250
sp332,39799072,39795804,"Well now that they have a promising result, maybe.",1711192695,comment,39793250
p1esk,39801294,39799072,They had this promising result before they posted the paper.,1711212879,comment,39793250
Buttons840,39795951,39794906,"If a genie appeared and granted one wish, I would wish that we find an extremely powerful machine learning technique that doesn&#x27;t scale. Imagine if an average desktop computer was almost as good as a billion dollar super computer.<p>In other words, I don&#x27;t really care if it scales. I almost hope it doesn&#x27;t.",1711150424,comment,39793250
p1esk,39796150,39795951,Not sure I understand what you mean by “doesn’t scale”. Are you trying to say you would like to see a tiny model performing as well as a large model?,1711152576,comment,39793250
MacsHeadroom,39796687,39795951,Even pocket computers (smartphones) are already better than billion dollar supercomputers from decades past.<p>What is your point?,1711158060,comment,39793250
pyinstallwoes,39804828,39796687,That no one has an advantage,1711249083,comment,39793250
jal278,39795383,39794906,But it may scale -- that&#x27;s science in progress,1711145361,comment,39793250
valine,39795841,39793250,The architecture changes are very straight forward. Model merging has shown that pre-trained transformer layers are very robust. I’ll bet it’s possible to fine tune a pre-trained model like mistral to use this architecture. That would enable someone to test it with more parameters without training a whole new base model.,1711149418,comment,39793250
numeri,39796285,39795841,"They try this in the appendix without success, unfortunately. It seems having this enabled early on in training is important.",1711154161,comment,39793250
matteopagli,39800018,39796285,"We&#x27;re still working on training the DWA weights on top of a pretained model. We&#x27;re hopeful that this is feasible. The experiments you&#x27;re mentioning in the appendix are not changing the learning rate scheduler. E.g., when starting to train the DWA weights after 20k iterations, the learning rate is already quite small. To some extent, this might explain the diminishing returns. Maybe this could work with a completely different learning rate scheduler.",1711202712,comment,39793250
gwern,39807426,39800018,"Yeah, you can&#x27;t change the model much with low LRs. That&#x27;s the point! Same reason you don&#x27;t get continual-learning if you just keep using low LRs: <a href=""https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2403.08763"" rel=""nofollow"">https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2403.08763</a> You need to really shake up the model if you want to learn some genuinely better (ie. different) internal representations that exploits the DenseNet (<a href=""https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;1608.06993)&#x2F;LTG-BERT"" rel=""nofollow"">https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;1608.06993)&#x2F;LTG-BERT</a> (<a href=""https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2311.02265"" rel=""nofollow"">https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2311.02265</a>) arch you&#x27;re using here.",1711290331,comment,39793250
bilsbie,39796597,39795841,I haven’t been able to make sense of model merging. Any insights?<p>Wouldn’t weights between models be completely different? And then there are architecture differences on top of that.,1711157043,comment,39793250
valine,39796718,39796597,"Model merging is usually done with different fine-tunes of the same model. It doesn’t work if the base models are different.<p>One of the more surprising things is that you can actually repeat layers to improve model performance, ie 1-1-2-2 instead of 1-2. That’s how you get models with higher parameter counts than the original.",1711158382,comment,39793250
namibj,39796815,39796718,"C.f. also Universal Transformer: the same layer stacked a lot.
The sparse version of that is basically MoE with also a stick-breaking mechanism to prevent vanishing gradient while letting the model decide whether to terminate layer-count at a token early (ofc with training rewards to favor less layers, to represent the compute savings).",1711159304,comment,39793250
tbalsam,39795683,39793250,"This is a very interesting idea, with DenseNets there are oftentimes some terrible memory gotchas that have gotten me over the past 7-8 years or so, so a part of me is sorta leaning back waiting for some memory usage shoe to drop not specified in the paper (even with the activation patterns!)<p>However, maybe this is not the case. I have a bit of a history of messing with residuals in neural networks, seeing more work on it is good. Fast training networks of course are a very slightly mild obsession of mine as well, and very useful to the field. Here&#x27;s hoping it pans out as a motif, curious to see where it goes.",1711147925,comment,39793250
sp332,39794626,39793250,"Even better is the result on page 7 that perplexity drops faster by wall-clock time. Even if you&#x27;re getting fewer iterations per hour of rented GPU time, you&#x27;re still coming out ahead in model performance.",1711140109,comment,39793250
ml_basics,39795118,39793250,"Cool paper. Really interesting to see how even quite straightforward architectural modifications haven&#x27;t yet all been exhausted yet, despite all the resources being poured into LLMs",1711143467,comment,39793250
samus,39795576,39795118,The problem is that they have to be tested for 7B models at least to show promise for larger models. And that requires significant compute resources.,1711147033,comment,39793250
tbalsam,39795661,39795576,"Due to some of my personal experiences over the years w&#x2F; model development, I believe that this is more due to a failure of the current mainline version of Transformers (the ++ version I believe) not scaling properly, vs an indicator of scale.<p>If that is the case, then it may well be possible to fix some of the scaling issues more apparent with smaller transformer models (maybe not, though). This is at least some of the reasoning that I&#x27;ve been applying when developing hlb-gpt, for example. It&#x27;s partially also why I think changing how we use nonlinearities within the network might impact scaling, due to some of the activation spikes used in more linear regions of the network to control network behavior in a way not originally intended.<p>Agreed that it does require a ton of resources though. But I do think that the problem can be solved on a smaller scale. If we don&#x27;t have a cleanly logarithmic curve, then I think that something is dearly wrong with our base architecture. (However, of course, I may entirely be missing something here).",1711147762,comment,39793250
quotemstr,39796007,39795576,I wonder whether we&#x27;re missing out on techniques that work well on large models but that don&#x27;t show promise on small ones,1711150959,comment,39793250
hackerlight,39796242,39796007,More like we&#x27;re missing out on techniques full stop. Proving things at scale is GPU expensive and gatekeeps publication and therefore accessibility.,1711153632,comment,39793250
danieldk,39798616,39793250,"Nice finding and makes a lot of sense! It is somewhat related to classification heads using their own weighted representation of all transformer layer outputs.<p>I only glanced the paper, but they don&#x27;t seem to softmax ⍺_i for normalization?",1711186517,comment,39793250
zwaps,39797354,39793250,"1. They compare with an older sort of standard implementation of a transformer Unsure whether the results would be equally significant compared to models with gated units or multiquery etc.<p>2. The difference seems to diminish with scale. Real life transformers obviously are much larger and train on many more tokens.<p>3. A very significant part of training transformer models are the throughoutput and memory optimizations. I wonder how their model would work with such fused kernels or specialized paged KV cache schemes. Or activation checkpointing, if run locally.<p>4. Indeed they claim no memory impact, but their code shows that their experiments are conducted with a special optimized version which requires all activations to reside in a single tensor at all times. Not sure this would work with 3d parallelism on multiple nodes etc.",1711166784,comment,39793250
matteopagli,39799970,39793250,"I&#x27;m one of the authors, happy to answer questions.",1711202104,comment,39793250
EvkoGS,39807322,39799970,Is it possible to combine your approach with NATTEN? It seems that both approaches are optimizing from different directions and can be combined with significant throughput and small performance improvements?,1711289278,comment,39793250
efrank3,39796345,39793250,Can&#x27;t believe nobody thought of this yet,1711154973,comment,39793250
aoeusnth1,39795483,39793250,"&gt; Impact statement:<p>&gt; This paper presents work whose goal is to advance the field of Machine Learning. There are many potential societal consequences of our work, none which we feel must be specifically highlighted here.<p>I found this particularly charming.",1711146217,comment,39793250
polygamous_bat,39795552,39795483,"AFAIK this was the default, copy paste impact statement by ICML template.",1711146796,comment,39793250
,39796040,39795483,,1711151228,comment,39793250
wruza,39789498,39788590,"The prompt, for those interested. I find it pretty underspecified, but maybe that&#x27;s the point. For example, &quot;Business operating hours&quot; could be expanded a little, because &quot;Closed - Opens at XX&quot; is still non-processable in both cases.<p><pre><code>  You are an expert in Web Scraping, so you are capable to find the information in HTML and label them accordingly. Please return the final result in JSON.

  Data to scrape: 
  title: Name of the business
  type: The business nature like Cafe, Coffee Shop, many others
  phone: The phone number of the business
  address: Address of the business, can be a state, country or a full address
  years_in_business: Number of years since the business started
  hours: Business operating hours
  rating: Rating of the business
  reviews: Number of reviews on the business
  price: Typical spending on the business
  description: Extra information that is not mentioned yet in any of the data
  service_options: Array of shopping options from the business, for example, in store shopping, delivery and many others. It should be in format -&gt; option_name: true
  is_operating: Whether the business is operating
  
  HTML: 
  {html}</code></pre>",1711106186,comment,39788590
infecto,39789863,39789498,"This should be higher up. This whole blog post is mostly worthless because the way they are extracting data is less than optimal.<p>Lower end models do not have the attention to complete tasks like this, GPT4Turbo will generally have the capability. But to have an optimal pipeline you should really be splitting up these tasks into individual units. You extract each attribute you want independently and then combine it back together however you want. Also asking for JSON upfront is equally suboptimal in the whole process.<p>I have high confidence that I could accomplish this task using a lower end model with a high degree of accuracy.<p>Edit: I am not suggesting that an LLM is more optimal than what ever traditional parsing methods they may use, simply the way they are doing it is wrong from an LLM flow.",1711109484,comment,39788590
wruza,39790503,39789863,"Also, my (limited) experience with prompts tells that you want to invest more into the “You are” part. I’ll share my understanding, corrections are appreciated.<p>LLMs aren’t people even in a chat-roleplaying sense. They complete a “document” that can be a plot, a book, a protocol of conversation. The “AI” side in the chat isn’t an LLM itself, it’s a character (and so are you, it completes your “You: …” replies too - that’s where the driver app stops it and allows you to interfere). So everything you put in that header is very important. There are two places where you can do that: right in the chat, as in TFA, or in the “character card” (idk if GPTs have it, no GPT access for me). I found out that properly crafting a character card makes a huge difference and can resolve the whole classes of issues.<p>Idk what will work best in this case, but I’d start with describing which sort of a bot, how it deals with unclear or incomplete information, how amazing it is (yes, really), its soft&#x2F;tech skills and problem solving abilities, what other people think of it, their experience and so on. Maybe would add few examples of interactions in a free form. Then in the task message I’d tell it more and specific details about that json.<p>One more note - at least for 8x7B, the “You are” in the chat is a much weaker instruction than a character card, even if the context is still empty. I low-key <i>believe</i> that’s because it’s a second-class prompt, i.e. the chat document starts with “This is a conversation with a helpful AI bot which yada yada” in… mind, and then in that chat that AI character gets asked to turn into something else, which poisons the setting.<p>Simply asking the default AI card represents 0.1% of what’s possible and doesn’t give the best results. Prompt Engineering is real.<p><i>I have high confidence that I could accomplish this task using a lower end model with a high degree of accuracy.</i><p>Same. I think that no matter how good a model is, this prompt just isn’t a professional task statement and leaves too much to decide. It’s a task that you, as a regular human, would hate to receive.",1711114011,comment,39788590
mhuffman,39790176,39789863,Do you have an example of a more optimal prompt to share?,1711111711,comment,39788590
infecto,39790288,39790176,"The prompt does not matter as much as the workflow which is describe above. 1) Extract one attribute at a time. 2) Don&#x27;t ask for json during extraction, but on binary small attributes it might not matter as much.. 3) Combine the data later.<p>There are differences that can be marked on how different models perform against the same raw prompt but generally the workflow is what matters more. The raw text prompt will be dependent on what model you are using as there are those differences but I don&#x27;t think its a level of &quot;prompt engineering&quot; like we had a year ago.",1711112504,comment,39788590
feintruled,39789144,39788590,"Brave new world, where our machines are sometimes wrong but by gum they are quick about it.",1711102824,comment,39788590
RUnconcerned,39789223,39789144,I too am a big fan of having my computer hallucinate incorrect information.,1711103541,comment,39788590
darthrupert,39790088,39789223,Yesterday I asked my locally running gpt4all &quot;What model are you running on?&quot;<p>Answer: &quot;I&#x27;m running on Toyota Corolla&quot;<p>Which was perhaps the funniest thing I heard that day.,1711111107,comment,39788590
harryf,39789316,39789223,"&gt;&gt; print(“Hello, world!”.ai_reverse())
world, Hello!",1711104336,comment,39788590
ben_w,39789503,39789316,"First few versions of Swift kept changing how strings work because it&#x27;s not entirely obvious what most people intend from the nth element of a string.<p>Used to be easy, when it was ASCII.<p>Reverse the bytes of utf-8 and it won&#x27;t always be valid uft-8.<p>Reverse the code-points, and the Canadian flag gets replaced with the Ascension Island flag.",1711106221,comment,39788590
samus,39790601,39789316,"Character-level operations are difficult for LLMs. Because of tokenization they don&#x27;t really &quot;perceive&quot; strings as a list of characters. There are LLMs that ingest bytes, but they are intended to process binary data.",1711114554,comment,39788590
RUnconcerned,39789127,39788590,"Finally, something more offensive than parsing HTML with regular expressions: parsing HTML with LLMs.",1711102691,comment,39788590
AlphaAndOmega0,39789147,39789127,I for one am glad I can offload all the regex to LLMs. Powerful? Yes. Human readable for beginners? No.,1711102859,comment,39788590
cornedor,39789171,39789147,"Why tough? To me, it seems more prone to issues (hallucinations, prompt injections etc). It is also slower and more expensive at the same time. I also think it is harder to implement properly, and you need to add way more tests in order to be confident it works.",1711103065,comment,39788590
RUnconcerned,39789211,39789147,"Personally when I am parsing structured data I prefer to use parsers that won&#x27;t hallucinate data but that&#x27;s just me.<p>Also, don&#x27;t parse HTML with regular expressions.",1711103394,comment,39788590
rybosome,39789813,39789211,"Generally I agree with your point, but there is some value in a parser that doesn’t have to be updated when the underlying HTML changes.<p>Whether or not this benefit outweighs the significant problems (cost, speed, accuracy and determinism) is up to the use case. For most use cases I can think of, the speed and accuracy of an actual parser would be preferable.<p>However, in situations where one is parsing highly dynamic HTML (eg if each business type had slightly different output, or you are scraping a site which updates the structure frequently and breaks your hand written parser) then this could be worth the accuracy loss.",1711109023,comment,39788590
samus,39791028,39789813,You could employ an LLM to give you updated queries when the format changes. This is something where they should shine. And you get something that you can audit and exhaustively test.,1711117356,comment,39788590
okamiueru,39789175,39789147,Deterministic? No.,1711103090,comment,39788590
retrac98,39789107,39788590,"There are so many applications for LLMs where having a perfect score is much more important than speed, because getting it wrong is so expensive, damaging, or time consuming to resolve for an organisation.",1711102505,comment,39788590
nathan_compton,39789176,39789107,"If you need a perfect score, don&#x27;t use LLMs. This seems obvious to me, even given the state of the art LLMs. I am a heavy user of GPT4 and I wouldn&#x27;t bet $1000 bucks on it being 100% reliable for any non-trivial task.",1711103091,comment,39788590
retrac98,39789186,39789176,"They&#x27;ll get better. Humans are far from perfect, and I have no doubt that LLMs will eventually outperform them for non-trivial tasks consistently.",1711103229,comment,39788590
Jensson,39793024,39789186,"&gt; Humans are far from perfect<p>Humans running multishot with mixture of experts is close to perfect. You can&#x27;t compare a multishot mixture of expert AI to a single human, humans doesn&#x27;t work in isolation.",1711129409,comment,39788590
nathan_compton,39789228,39789186,"Maybe so, but at this stage I wouldn&#x27;t be betting a business model on it.",1711103562,comment,39788590
Socnic,39790571,39789228,Businesses do bet on imperfect and even criminal models all the time (way before LLMs existed)... they call it cost of doing business when they get it wrong or get caught.,1711114409,comment,39788590
littlestymaar,39789381,39789186,Machine learning models will get better for sure. We don&#x27;t know if LLM are the end game though and it&#x27;s not sure if this particular technique is what we&#x27;ll need to reach the next level.,1711105026,comment,39788590
somewhereoutth,39789373,39789186,"Or they might not get better. It could be that we are at a local optimum for that sort of thing, and major improvements will have to wait (perhaps for a very long time) for radical new technologies.",1711104908,comment,39788590
luma,39789556,39789373,"Maybe, but it certainly hasn’t been the arc of the past few years.  I don’t know how anyone could look at this and assume that it’s likely to slow down.",1711106651,comment,39788590
samus,39789199,39789186,They already have superhuman image classification performance.,1711103321,comment,39788590
pooper,39789238,39789199,"I remember talking to a radiologist who said he was sure something like this was coming like ten years ago where instead of a radiologist looking at scans manually, a machine would go through a lot of images and flag some for manual review.<p>We haven&#x27;t even gotten there yet, have we?",1711103685,comment,39788590
osrec,39789274,39789238,"Yes, we absolutely are there: <a href=""https:&#x2F;&#x2F;youtu.be&#x2F;D3oRN5JNMWs?feature=shared"" rel=""nofollow"">https:&#x2F;&#x2F;youtu.be&#x2F;D3oRN5JNMWs?feature=shared</a><p>My professor (Sir Michael Brady) at university 14 years ago set up a company to do this very thing, and he already had reliable models back before 2010. I believe their company was called Oxford Imaging or something similar.",1711104049,comment,39788590
wruza,39789388,39789274,"Yep, everyone seems to forget that ML was available before 2021. Had a conversation recently with my former colleague who learned about some plastic packaging company which used &quot;AI&quot; to predict client orders and inform them about scheduling implications. When I told him that you don&#x27;t need Transformers and 30GB models for that, he was quasi-confused, cause he kinda knew it but the hype just overtook his knowledge.",1711105085,comment,39788590
anon373839,39789852,39789388,"In ML courses, you’re taught to try simpler methods and models before turning to more complex ones. I think that’s something that hasn’t made it into the mainstream yet.<p>A lot of people seem to be using GPT-4 for tasks like text classification and NER, and they’d be much better off fine-tuning a BERT model instead. In vision, too, transformers are great but a lot of times, a CNN is all you really need.",1711109394,comment,39788590
dagw,39789273,39789238,"<i>We haven&#x27;t even gotten there yet, have we?</i><p>Yes and no. Countless teams have solved exactly this problems at universities and research groups across the world. Technically it&#x27;s pretty much a solved problem. The hard part is getting the systems out of the labs and certified as an actual product and convincing hospitals and doctors to actually use them.",1711104025,comment,39788590
matheusd,39789269,39789238,"Maybe it&#x27;s a liability issue, not a competency issue.",1711103993,comment,39788590
jojobas,39789242,39789199,Until a single pixel makes a cat a dog or something like that.,1711103737,comment,39788590
samus,39790533,39789242,"Changing a single pixel is usually not enough to confuse convolutional neuronal networks. Even so, human supervision will probably always be quite important.",1711114206,comment,39788590
spaniard89277,39789168,39789107,"I&#x27;ve tried to apply it to parsing HTML as this article into a pretty long pipeline. I&#x27;m using DeepInfra with Mistral 8x7B and I&#x27;m still unsure if I&#x27;m going to use for production.<p>The problem I&#x27;m finding is that the time I wanted to save mantaining selectors and the like is time that I&#x27;m spending writing wrapper code and dealing with the mistakes it makes. Some are OK and can deal with them, others are pretty annoying because It&#x27;s difficult to deal with them in a deterministic manner.<p>I&#x27;ve also tried with GPT-4 but it&#x27;s way more expensive, and despite what this guy got, it also makes mistakes.<p>I don&#x27;t really care about inference speed, but I do care about price and correctness.",1711103018,comment,39788590
ogogmad,39789232,39789168,"Might be a silly question, but if you want determinism in this, why don&#x27;t you get the LLM to write the deterministic code, and use that instead? Interesting experiment, though!<p>In fact, what about a hybrid of what you&#x27;re doing now? Initially, you use an LLM to generate examples. And then from those examples, you use that same LLM to write deterministic code?",1711103622,comment,39788590
Eisenstein,39789771,39789168,"Have you tried swapping Mistral 8x7B with either command-r 34B, Qwen 1.5 70B, or miqu 70B? Those are all superior in my experience, though suited for slightly different tasks, so experimentation is needed.",1711108687,comment,39788590
samus,39790866,39789168,"Parsing HTML and tagsoup is IMHO not the right application for LLMs since these are ultimately structured formats. LLM are for NLP tasks, like extracting meaning out of unstructured and ambiguous text. The computational cost of an LLM chewing through even moderately-sized document can be more efficiently spent on sophisticated parser technologies that have been around for decades, which can also to a degree deal with ambiguous and irregular grammars. LLMs should be able to help you write those.",1711116204,comment,39788590
malux85,39789117,39789107,Yeah I agree - just an hour ago I was dealing with an LLM that was missing a &quot;not&quot; thus inverting the meaning of a rather important simulation parameter!,1711102625,comment,39788590
worldsayshi,39789217,39789107,It makes much more sense to me to have the LLM infer the correct query for extracting data on the page. Much faster and reliable and it wouldn&#x27;t really be a problem to have a human in the loop every now and then.,1711103446,comment,39788590
onion2k,39789716,39789107,"All the places I see AI being applicable to my work don&#x27;t require a perfect score, and a threshold is actually much more useful, especially where multiple factors come together to make evaluation to a single value hard.",1711108229,comment,39788590
bberrry,39789155,39789107,If you have speed you can generate multiple answers and have another model pick the best one.,1711102890,comment,39788590
Drakim,39789182,39789155,"If I ask an LLM a very complex and specific question 500 times, if it just doesn&#x27;t know the facts you&#x27;ll still get the wrong answer 500 times.<p>That&#x27;s understandable. The real problem is when the AI lies&#x2F;hallucinates another answer with confidence instead of saying &quot;I don&#x27;t know&quot;.",1711103171,comment,39788590
simion314,39789311,39789182,"The problem is asking for facts, LLM are not a database so they know stuff but it is compressed so expect wrong facts, wrong names, dates, wrong anything.<p>We will need an LLM as a front end then it will generate a query to fetch the facts from the internet or a database , then maybe   format the facts for your consumption.",1711104293,comment,39788590
samus,39791011,39789311,"This is called Retrieval Augmented Generation (RAG). The LLM driver recognizes a query, it gets send to a vector database or to an external system (could be another LLM...) and the answer is placed in the context. It&#x27;s a common strategy to work around their limited context length, but it tends to be brittle. Look for survey papers.",1711117211,comment,39788590
ch_sm,39789595,39789311,"That‘s exactly it. It‘s ok for LLMs to not know everything, because they _should_ have a means to look up information. What are some projects where this obvious approach is implemented&#x2F;tried?",1711106992,comment,39788590
Jensson,39789715,39789595,"But then you need an LLM that can separate between grammar and facts. Current LLMs doesn&#x27;t know the difference, that is the main source to these issues, these models treat facts like grammar and that worked well enough to excite people but probably wont get us to a good state.",1711108214,comment,39788590
,39791003,39789595,,1711117171,comment,39788590
m348e912,39789383,39789182,"The weird problem is with LLM hallucinations is that it usually will acknowledge its mistake and correct itself if you call it out. My question is why can&#x27;t LLMs included a sub-routine to check itself before answering.
Simply asking itself something like &quot;this answer may not be correct, are you sure you&#x27;re right?&quot;",1711105056,comment,39788590
Shrezzing,39789565,39789383,"&gt;The weird problem is with LLM hallucinations is that it usually will acknowledge its mistake and correct itself if you call it out.<p>From what I&#x27;ve tested, all of the current models will see a prompt like &quot;are you sure that&#x27;s correct&quot; and respond &quot;no, I was incorrect [here&#x27;s some other answer]&quot;, irrespective of the accuracy of the original statement.",1711106724,comment,39788590
greenavocado,39789772,39789383,In my experience the corrections can be additional hallucinations one after another after pointing out inaccuracies even multiple times in a row.,1711108695,comment,39788590
Eisenstein,39789916,39789383,"&gt; My question is why can&#x27;t LLMs included a sub-routine to check itself before answering.<p>Because LLMs don&#x27;t work in a way for that to be possible if you operate them on their own.<p>Here is the debug output of my local instance of Mistral-Instruct 8x7B. The prompt from me was &#x27;What is poop spelled backwards?&#x27;. It answered &#x27;puoP&#x27;. Let&#x27;s see how it got there starting with it processing my prompt into tokens:<p><pre><code>   &#x27;What (3195)&#x27;, &#x27; is (349)&#x27;, &#x27; po (1627)&#x27;, &#x27;op (410)&#x27;, &#x27; sp (668)&#x27;, &#x27;elled (6099)&#x27;, &#x27; backwards (24324)&#x27;, &#x27;? (28804)&#x27;, &#x27;\n (13)&#x27;, &#x27;### (27332)&#x27;, &#x27; Response (12107)&#x27;, &#x27;: (28747)&#x27;, &#x27;\n (13)&#x27;,
</code></pre>
It tokenized &#x27;poop&#x27; as two tokens: &#x27;po&#x27;, number 1627, and &#x27;op&#x27;, number 410.<p>Next it comes up with its response:<p><pre><code>   Generating (1 &#x2F; 512 tokens) [(pu 4.43%) (The 66.62%) (po 11.96%) (p 4.99%)]
   Generating (2 &#x2F; 512 tokens) [(o 89.90%) (op 10.10%)]
   Generating (3 &#x2F; 512 tokens) [(P 100.00%)]
   Generating (4 &#x2F; 512 tokens) [( 100.00%)]
</code></pre>
It picked &#x27;pu&#x27; even though it was only a ~4% chance of being correct, then instead of picking &#x27;op&#x27; it picked &#x27;o&#x27;. The last token was a 100% probability of being &#x27;P&#x27;.<p><pre><code>   Output: puoP
</code></pre>
At no time did it write &#x27;puoP&#x27; as a complete word nor does it know what &#x27;puoP&#x27; is. It has no way of evaluating whether that is the right answer or not. You would need a different process to do that.",1711109877,comment,39788590
ZitchDog,39789474,39789383,"The problem is that if you call it out, it will frequently change its answer, even if it was correct. LLMs currently lack chutzpa.",1711106007,comment,39788590
samus,39790963,39789474,They definitely stand their ground if they were aligned to do so.,1711116888,comment,39788590
Drakim,39791230,39790963,But then they stand their ground when wrong too.,1711118621,comment,39788590
Jensson,39789516,39789383,"That is a common bullshitting strategy, talk a lot of bullshit, and then backtrack and acknowledge you were wrong when people push back. That way they will think you know way more than you do. Many people will see thought that, but most will just think you are a humble expert who can acknowledge when you are wrong instead of you always acknowledging you are wrong even when you aren&#x27;t.<p>People have a really hard time catching such bullshitting from humans, which is why free form interviews doesn&#x27;t work.",1711106307,comment,39788590
asimovfan,39789447,39789383,Its because theres no entity that is actually acknowledging anything. Its generating an answer to your prompt. You can gaslight it into anything being wrong or correct.,1711105767,comment,39788590
samus,39790933,39789383,"They simply don&#x27;t work that way. You are asking it for an answer, it will give you one since all it can do is extrapolate from its training data.<p>Good prompting and certain adjustment to the text generation parameters might help prevent hallucinations, but it&#x27;s not an exact science since it depends on how it was trained. Also, an LLMs training data frankly said contains a lot of bulls*t.",1711116733,comment,39788590
helsinkiandrew,39789248,39789182,"&gt; If I ask an LLM a very complex and specific question 500 times, if it just doesn&#x27;t know the facts you&#x27;ll still get the wrong answer 500 times.<p>Think the commenter meant use another model&#x2F;LLM which could give a different answer, then let them vote on the result.  Like &quot;old fashioned AI&quot; did with ensemble learning.",1711103786,comment,39788590
,39789231,39789182,,1711103587,comment,39788590
infecto,39789938,39788590,This test is interesting from a general high level metric&#x2F;test but overall the way they are extracting data using a LLM is suboptimal so I don&#x27;t think the takeaway means much. You could extract this type of data using a low-end model like 8x7B with a high degree of accuracy.,1711109988,comment,39788590
samus,39791038,39789938,The better way would be to ask it to generate a program that uses CSS selectors to parse the HTML.,1711117448,comment,39788590
emporas,39790271,39788590,"Mixtral works very well with json output in my personal experience. Gpt family are excellent of course, and i would bet Claude and Gemini are pretty good. Mixtral however is the smallest of the models and the most efficient.<p>Especially running on Groq&#x27;s infrastructure it&#x27;s blazing fast. Some examples i ran on Groq&#x27;s API, the query was completed in 70ms. Groq has released API libraries for Python and Javascript, i wrote a simple Rust example here, of how to use the API [1].<p>Groq&#x27;s API documents how long it takes to generate the tokens for each request. 70ms for a page of document, are well over 100 times faster than GPT, and the fastest of every other capable model. Accounting for internet&#x27;s latency and some queue that might exist, then the user receives the request in a second, but how fast would this model run locally? Fast enough to generate natural language tokens, generate a synthetic voice, listen again and decode the next request the user might talk to it, all in real time.<p>With a technology like that, why not talk to internet services with just APIs and no web interface at all? Just functions exposed on the internet, take json as an input, validate it, and send the json back to the user? Or every other interface and button around. Why pressing buttons for every electric appliance, and not just talk to the machine using a json schema? Why should users on an internet forum, every time a comment is added, have to press the add comment button, instead of just talking and saying &quot;post it&quot;? Pretty annoying actually.<p>[1] <a href=""https:&#x2F;&#x2F;github.com&#x2F;pramatias&#x2F;groq_test"">https:&#x2F;&#x2F;github.com&#x2F;pramatias&#x2F;groq_test</a>",1711112358,comment,39788590
imaurer,39792780,39788590,"Groq will soon support function calling. At that point, you would want to describe your data specification and use function calling to do extraction. Tools such as Pydantic and Instructor are good starting points.<p>I am collecting these approaches and tools here:
<a href=""https:&#x2F;&#x2F;github.com&#x2F;imaurer&#x2F;awesome-llm-json"">https:&#x2F;&#x2F;github.com&#x2F;imaurer&#x2F;awesome-llm-json</a>",1711127569,comment,39788590
bambax,39789395,39788590,"Interesting post, but the prompt is missing? How do the LLMs generate the keys? It&#x27;s likely the mistakes could be corrected with a better prompt or a post check?<p>Also, Google SERP page is deterministic (always has the same structure for the same kind of queries), so it would probably be much more effective to use AI to write a parser, and then refine it and use that?",1711105159,comment,39788590
tosh,39789215,39788590,"I initially thought the blog post is about scraping using screenshots and multi-modal llms.<p>Scraping is quite complex by now (front-end JS, deep and irregular nesting, obfuscated html, …).",1711103426,comment,39788590
crowdyriver,39789735,39788590,There&#x27;s lots of comments here about how stupid is to parse html using llms.<p>Have you ever had to scrape multiple sites with variadic html?,1711108393,comment,39788590
samus,39791094,39789735,"The example here has HTML with a somewhat fixed format. It would indeed have been better to have samples with different format and aiming for a low error rate.<p>If you are scraping a limited amount of sites, you could for each site ask the LLM for parsing code from some samples, review that, and move on.",1711117790,comment,39788590
malux85,39789080,39788590,"Sorry to be nit-picky but thats the essence of these benchmarks - Mistral putting &quot;N&#x2F;A&quot; for not available is weird - N&#x2F;A is not applicable, in every use I have ever seen, and they DONT mean the same thing. I would expect null for not available and N&#x2F;A for not applicable<p>Impressive inference speed difference though",1711102215,comment,39788590
mewpmewp2,39789123,39789080,I have always known N&#x2F;A as not available.,1711102662,comment,39788590
malux85,39789138,39789123,"Curious, where are you from? If I Google N&#x2F;A every single hit on the first page is explaining it means &quot;Not applicable&quot;<p>are you from a non-english country? Maybe its cultural?",1711102789,comment,39788590
selcuka,39789148,39789138,"The first entry on Google is Wikipedia [1] for me:<p>&gt; N&#x2F;A (or sometimes n&#x2F;a or N.A.) is a common abbreviation in tables and lists for the phrase not applicable, not available, not assessed, or no answer.<p>[1] <a href=""https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;N&#x2F;A"" rel=""nofollow"">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;N&#x2F;A</a>",1711102861,comment,39788590
malux85,39789162,39789148,"Thats interesting, wikipedia is not on the first page for me, my first hit is Cambridge dict: (and then a bunch of other dicts) - Im flying right now but IP geolocation puts me in the US<p>Meaning of n&#x2F;a in English
written abbreviation for not applicable: used on a form to show that you are not giving the information asked for because the question is not intended for you or your situation: If a question does not apply to you, please put N&#x2F;A in the box provided. COMMERCE.<p>TIL",1711102975,comment,39788590
Jensson,39790066,39789162,"In a data table &quot;not available&quot; is usually the right word for it, like if you have a list of national statistics then some of the values wont be available due to political reasons etc. But all of those means basically the same thing to the end user, this value isn&#x27;t there.",1711110937,comment,39788590
mewpmewp2,39795150,39789138,"I&#x27;m from North Europe, so not a native English speaker, but still it seems like based on my experience in life it seems as the first idea is that it&#x27;s Not Available.<p>If I was to code something and for whatever reason some data wasn&#x27;t available I would use N&#x2F;A.<p>&quot;Not applicable&quot; doesn&#x27;t feel right to me about N&#x2F;A.<p>For instance if there is a table of comparison and for whatever reason there is data missing for some entity, while there should be, I would use N&#x2F;A. So not applicable feels wrong for me for that reason alone.<p>This all is coming from intuition though.",1711143719,comment,39788590
throwaway11460,39789178,39789080,It means all of these.,1711103121,comment,39788590
huqedato,39789206,39788590,Can somebody explain why this Grok is more performant than Microsoft infrastructure ? LPU better than TPU&#x2F;GPU ?,1711103370,comment,39788590
kkielhofner,39789643,39789206,"LLM performance is about parallelism but also memory bandwidth.<p>Groq delivers this kind of speed by networking many, many chips together with high bandwidth interconnect. Each chip has only 230mb of SRAM[0].<p>From the linked reference:<p>&quot;In the case of the Mixtral model, Groq had to connect 8 racks of 9 servers each with 8 chips per server. That’s a total of 576 chips to build up the inference unit and serve the Mixtral model.&quot;<p>That&#x27;s eight racks with ~132GB of memory for the model. A single H100 has 80GB and can serve Mixtral without issue (albeit at lower performance).<p>If you consider the requirements for actual real-world inference serving workloads you need to serve multiple models, multiple versions of models, LoRA adapters, sentence embeddings models (for RAG), etc the economics and physical footprint alone get very challenging.<p>It&#x27;s an interesting approach and clearly very, very fast but I&#x27;m curious to see how they do in the market:<p>1) This analysis uses cloud GPU costs for Nvidia pricing. Cloud providers make significant margin on their GPU instances. If you look at qty 1 retail Nvidia DGX, Lambda Hyperplane, etc and compare it to cloud GPU pricing (inference needs to run 24x7) break even on hardware vs cloud is less than seven months depending on what your costs are for hosting the hardware.<p>2) Nvidia has incredibly high margins.<p>3) CUDA.<p>There are some special cases where tokens per second and time to first token are incredibly important (as the article states - real time agents, etc) but overall I think actual real-world production use or deployment of Groq is a pretty challenging proposition.<p>[0] - <a href=""https:&#x2F;&#x2F;www.semianalysis.com&#x2F;p&#x2F;groq-inference-tokenomics-speed-but"" rel=""nofollow"">https:&#x2F;&#x2F;www.semianalysis.com&#x2F;p&#x2F;groq-inference-tokenomics-spe...</a>",1711107435,comment,39788590
tosh,39789220,39789206,The Mistral Mixed Expert model has way fewer parameters active during inference and Groq has special purpose hardware (and probably less concurrent demand).,1711103518,comment,39788590
kkielhofner,39789675,39789220,&gt; probably less concurrent demand<p>This is a significant understatement. ChatGPT has an estimated 100m monthly active users.<p>Groq gets featured on HN from time to time but is otherwise almost completely unknown. According to their stats they have done something like 15m requests total since launch. ChatGPT likely does this in hours (or less).,1711107799,comment,39788590
naiv,39789244,39789206,"It&#x27;s a totally different approach for interference<p>In short:<p>Groq - Ai Chip
Microsoft etc. - Nvidia Gpu",1711103754,comment,39788590
ttrrooppeerr,39789116,39788590,A bit off-topic but maybe not? Any words on GPT-5? Is that coming? Or is OpenAI just focusing on the Sora model?,1711102622,comment,39788590
YetAnotherNick,39789153,39789116,There&#x27;s no reason for OpenAI to release the model. They have close to 100% market anyways and releasing GPT-5 likely won&#x27;t increase the total market as it is a incremental leap. And it&#x27;s a open secret that most other models used GPT-4 synthetic data for training to come close to it.<p>They would likely wait till any model performs better than GPT 4 for the same price,1711102886,comment,39788590
whiplash451,39789418,39789153,"The same reasoning would have applied for GPT-3.5.  In the <i>hindsight</i>, you can say that it was obviously a good idea to build and ship GPT4.  But hindsight is 20&#x2F;20.",1711105377,comment,39788590
YetAnotherNick,39790642,39789418,"There are few differences. Firstly, GPT-3.5 wasn&#x27;t ahead of Palm etc. from Google which was published at the same time as GPT-4.<p>Secondly, GPT-4 increased overall AI market. According to all the sources, interviews and leaks, GPT-5 won&#x27;t be a big leap over GPT-4 as the model size and training data won&#x27;t be significantly larger. I doubt GPT-5 would do that. (I could be wrong in my assumption though that GPT-5 would just be a incremental gain).",1711114763,comment,39788590
chilmers,39789424,39789153,By any chance did you used to work in leadership at Nokia or Research in Motion? :-D,1711105503,comment,39788590
YetAnotherNick,39790657,39789424,Nokia wasn&#x27;t that ahead in technology and Motion wasn&#x27;t that ahead in market. GPT-4 is ahead in both.,1711114866,comment,39788590
lewhoo,39789342,39789153,There is reason to release new models if said models would be capable of grabbing a significant portion of job market currently occupied by humans.,1711104622,comment,39788590
tosh,39789259,39789153,"100%?<p>Claude 3 Opus is in the capability ballpark of GPT-4, GPT-3.5 has alternatives that are cheaper (Claude 3 Haiku) or cheaper and work offline (Qwen 1.5, Mixtral, …).",1711103897,comment,39788590
ZitchDog,39789529,39789259,"100% market share.<p>A competitor will likely need to be 10x better than ChatGPT in order to get significant market share, not just marginally better in certain scenarios.",1711106417,comment,39788590
Kostic,39790490,39789259,"Is Claude 3 Opus generating more profits and taking considerable amount of customers from OpenAI? I&#x27;m not seeing that yet. Granted, I&#x27;m in Europe (outside of EU) so I can&#x27;t pay for Opus but I guess that kinda confirms my statement. GPT4 is still a good product and there are no market pressures to release GPT5.",1711113920,comment,39788590
burrish,39789163,39789116,I hear it should be dropped this summer,1711102997,comment,39788590
cornedor,39789181,39789163,"According to Sam Altman in a podcast with Lex Fridman this week, there is no real indication that it will be dropped this year. They will release a new model, but it might not be GPT-5",1711103164,comment,39788590
burrish,39789284,39789181,"Fair enough, I got the info from this article<p><a href=""https:&#x2F;&#x2F;web.archive.org&#x2F;web&#x2F;20240319224624&#x2F;https:&#x2F;&#x2F;www.businessinsider.com&#x2F;openai-launch-better-gpt-5-chatbot-2024-3"" rel=""nofollow"">https:&#x2F;&#x2F;web.archive.org&#x2F;web&#x2F;20240319224624&#x2F;https:&#x2F;&#x2F;www.busin...</a>",1711104092,comment,39788590
whiplash451,39789413,39789181,"Which is an indication of nothing.  In which world would Sam A. drop any kind of info about such a sensitive topic? If anything, this could just be deception before a massive drop.",1711105314,comment,39788590
HarHarVeryFunny,39789758,39789413,"Could also be resetting expectations for people who&#x27;ve been expecting GPT-5 (or just GPT-4.5) sooner - been a year now since GPT-4 was released.<p>The other odd thing from Altman was saying that GPT-4 sucks.<p>I think the context for both announcements is the recent release of Anthropic&#x27;s Claude-3, which in it&#x27;s largest &quot;Opus&quot; form beats GPT-4 across the board in benchmarks.<p>I personally think OpenAI&#x2F;Altman is a bit scared that any moat&#x2F;lead they had has disappeared and they are now being out-competed by Anthropic (Claude). Remember that Anthropic as a company was only formed (by core members of the OpenAI LLM team) at the same time as GPT-3 was released, so in same time it took OpenAI to go from GPT-3 to GPT-4, Anthropic have gone from nothing -&gt; Claude-1 -&gt; Claude-2 -&gt; Claude-3 which beats GPT-4 !!<p>Anthropic have also had quite a bit of success attracting corporate business, quite a bit of which is more long-term in nature (sharing details of expected future model capabilities so that partners can target those).<p>So, I think OpenAI is running a bit scared, and I&#x27;d interpret this non-announcement of some model (4.5 or 5) &quot;coming soonish&quot; to be them just waving the flag and saying &quot;we&#x27;ll be back on top soon&quot;, which they presumably will be, briefly, when their next release(s) do come out. Altman&#x27;s odd &quot;GPT-4 sucks&quot; statement might be meant to downplay Claude-3 &quot;Opus&quot; which beats it.",1711108592,comment,39788590
DalasNoin,39789317,39789163,"My understanding from the lex podcast: they will release a lot of new models this year, but they will release intermediate models first before gpt-5",1711104336,comment,39788590
dns_snek,39789466,39788590,"For all the posturing and crypto hate on HN, we&#x27;re entering a world where it&#x27;s socially acceptable to use 1000W of computing power and 5 seconds of inference time to parse a tiny HTML fragment which would take microseconds with traditional methods - and people are cheering about it. Time for some self-reflection? That&#x27;s not very green.",1711105940,comment,39788590
delegate,39789572,39789466,"Crypto energy requirements go up as the currency gets more traction.<p>TFA shows that groq is many times faster than GPT-4.
Up to 18x groq claims. Faster means less energy.
So I think it&#x27;s just a matter of time until these things become ridiculously power efficient (eg run on phones in sub second times)",1711106855,comment,39788590
jodleif,39789612,39789572,How does faster mean less energy? Thats only true if you’re running faster on the same hardware…,1711107126,comment,39788590
delegate,39789654,39789612,"Presumably. Less time the giant chip has to draw power for computation. 
The point is that everyone&#x27;s interested in making AI power efficient, while crypto&#x27;s proof of work is a competition for more power burned hashing and throwing away the result.",1711107529,comment,39788590
wenebego,39789663,39789612,"I think they are talking about the case where, hypothetically, there is a 10x increase in speed but only 2x increase in power consumption",1711107660,comment,39788590
jodleif,39806952,39789663,I’m just pointing out that this is not a given…,1711285084,comment,39788590
drexlspivey,39789808,39789572,Bitcoin energy requirements will be cut in half in a few days..,1711108983,comment,39788590
samus,39791207,39789572,"It&#x27;s still a monstrosity compared to a traditional parser. You can even be fancy and use complex parsers that backtrack and can deal with mildly context-sensitive languages (as required for HTML, XML, and many programmin languages), and you&#x27;d still be more efficient.",1711118429,comment,39788590
shanehoban,39789517,39789466,"This is a valid point, but we are still in the early stages of AI&#x2F;LLMs, so one would expect the speed and efficiency to improve drastically (perhaps accuracy too) over the coming years.<p>At least AI &amp; LLMs have large scale practical applications as opposed to crypto (IMO).",1711106315,comment,39788590
AlchemistCamp,39789546,39789517,AI is a lot older than blockchain. There were full-fledged neural networks in the 40s and the perceptron was implemented in hardware in the 50s.,1711106576,comment,39788590
IshanMi,39789687,39789546,"It&#x27;s also interesting to think that IBM released an 8-trillion parameter model back in the 1980s [0]. Granted it was an n-gram model so it&#x27;s not exactly an apples-to-apples comparison with today&#x27;s models, but still, quite crazy to think about.<p>[0]: <a href=""https:&#x2F;&#x2F;aclanthology.org&#x2F;J92-4003.pdf"" rel=""nofollow"">https:&#x2F;&#x2F;aclanthology.org&#x2F;J92-4003.pdf</a>",1711107930,comment,39788590
lukeschantz,39789794,39789687,"Interesting to see Robert Mercer the former CEO of Renaissance Technology is one of the authors on that paper. He is a former IBMer. If his name is unfamiliar he is a reclusive character who was a major funder of Breitbart, Cambridge Analytica and the Republican candidate in the 2016 presidential election.",1711108866,comment,39788590
varjag,39789728,39789546,"I wouldn&#x27;t call the early McCulloch &amp; Pitts work quite &quot;full-fledged&quot;. Also backpropagation, essential for multi level perceptrons was not a thing until 1980s.",1711108340,comment,39788590
samus,39791233,39789728,Backprop is just applied calculus. People simply didn&#x27;t think about using it for neuronal networks yet.,1711118638,comment,39788590
varjag,39800693,39791233,It was thought of as early as in 1960s by Rosenblatt but he did not come up with a practical implementation at the time. Lotsa things look obvious in hindsight.,1711208236,comment,39788590
,39789637,39789546,,1711107383,comment,39788590
ogogmad,39789946,39789466,"You&#x27;re partially right. It&#x27;s obvious that the solution is to combine traditional programming with AI, using traditional programming wherever possible because it&#x27;s greener. Assuming you want things to turn out well in every possible future scenario, your decisions only matter if AGI isn&#x27;t right around the corner. So assume it isn&#x27;t right around the corner. Then there&#x27;s going to be some interesting combining-together of manual human intervention, traditional software, and AI. We&#x27;ll need to charge more for some uses of electricity, to incentivise turning AI into traditional software wherever possible.<p>Crypto is nearly pure waste.",1711110087,comment,39788590
CaptainFever,39790548,39789946,"&gt; We&#x27;ll need to charge more for some uses of electricity, to incentivise turning AI into traditional software wherever possible.<p>I don&#x27;t understand this. This adds bureaucracy and I don&#x27;t see why different uses need to be charged differently if they all use energy the same.<p>In other words, if energy costs X per unit, and an inefficient (AI) software takes 30 units and an efficient (traditional) software takes 10 units, then it is already cheaper to run the efficient software, and thus people are already incentivised to do so. There&#x27;s no need to charge differently. If one day AI turns out to only need 5 units, turning more efficient, then just charge them for 5X. People will gravitate towards the new, efficient AI software naturally then.",1711114288,comment,39788590
Jensson,39789563,39789466,"Websites will never be fast, will they? Even with 1000x more compute than now they will just perform everything in LLM calls and stuff are just as slow as now.",1711106719,comment,39788590
qup,39789535,39789466,It would take microseconds after a complete program was written by a human?<p>It no longer requires an expert human,1711106442,comment,39788590
josho,39789901,39789535,And if this use case hit any kind of scale. We’d just have an llm generate a parser and be back to microseconds.<p>This was just a blog to generate traffic on the site. Not to showcase some new use case for an llm.,1711109780,comment,39788590
samlinnfer,39789679,39789466,"Any amount of energy spent useful work is vastly superior than whatever “POW” crypto burn does.<p>&gt;For all the posturing and forest fire hate on HN, it’s now socially acceptable to run a toy steam engine to power a model car? Not very green of you.",1711107866,comment,39788590
CaptainFever,39790423,39789679,"It&#x27;s almost a fallacy at this point to declare something bad simply because of the existence of carbon emissions, without first comparing the benefits of what is being produced, and the alternative tradeoffs.<p>To be fair to GP, they did compare it to alternatives (dumb HTML parsing), but failed to consider versatile HTML parsing or other uses for Groq LLM.",1711113521,comment,39788590
samus,39791242,39789679,"While you are not wrong, crypto is not what this is being compared with.",1711118713,comment,39788590
londons_explore,39789508,39789466,"While energy remains cheap and human minds remain expensive, it always makes sense to use AI to reduce human effort.<p>If one cares about the environment, a carbon cap&#x2F;tax is what you should campaign for.   Then carbon-based energy sources will be curtailled, energy costs will go up, and AI like this will be encouraged to become more energy efficient or other methods used instead.",1711106251,comment,39788590
osigurdson,39789913,39789508,It is a nice idea in principle but ends up being a political tool and a tariff on goods and services of your own country. A global and corruption free carbon tax might work but that is impossible to achieve.,1711109859,comment,39788590
londons_explore,39790752,39789913,"The only way it&#x27;s gonna work is if a bunch of countries get together, agree a carbon cap&#x2F;tax, and then tell other countries that they need to join the scheme if they want to trade goods with the group.<p>One way to combat corruption is to ask an international panel of experts to assess how many extra emissions came from non-official sources in each country and reduce next years cap by that amount.   Then countries have an incentive to stamp out corruption.",1711115374,comment,39788590
osigurdson,39799910,39790752,"I don&#x27;t know. Corruption gets easier with increased centralization. I think a far better approach is to innovate our way out of it. If carbon free energy sources are less expensive then the problem will solve itself essentially. A global carbon tax will enviably extract some portion of global GDP from corruption. That money would likely be better spent in other ways.<p>Basically, carbon tax is the accountant&#x27;s solution, innovation is the engineer&#x27;s.",1711201619,comment,39788590
londons_explore,39802018,39799910,"carbon-free will take a really long time to be cheaper.<p>As soon as demand for oil starts to drop, so will oil prices, and I suspect they could go down by a factor of 10 or more and oil-rich nations would still think it worthwhile to exploit at least some reserves.",1711218218,comment,39788590
infecto,39789807,39789466,Because crypto has very little real world use.<p>There is a lot of business value happening in the AI space and its only going to get better.,1711108982,comment,39788590
skc,39789492,39789466,One is actually useful day to day though.,1711106156,comment,39788590
rafaelero,39789623,39789466,"What a ridiculous complaint. Energy efficiency won&#x27;t remain static, and even if it were, it&#x27;s not up to you to decide how to best leverage the available electricity.",1711107214,comment,39788590
lm28469,39789706,39789623,&gt; it&#x27;s not up to you to decide<p>Unless you live in a dictatorship it&#x27;s definitely up to us to decide... Otherwise you leave your voice to the top 0.0001% business owners and expect them to work for your good and not for their own interests<p>Also read about the rebound effect. Planes are twice as efficient as they were 100 years ago yet they pollute infinitely more as a whole.<p>There is nothing ridiculous about the comment you&#x27;re replying to,1711108029,comment,39788590
infecto,39789826,39789706,Yes you are right and the future is dependent on innovation and using more electricity with a large percentage of it coming form renewable sources. I don&#x27;t want to go live on the farm myself.,1711109132,comment,39788590
rafaelero,39789866,39789706,"Ok, then let&#x27;s start by getting away with all the wasteful animal farming.",1711109513,comment,39788590
satisfice,39789485,39789466,AND it&#x27;s not even reliable.,1711106097,comment,39788590
,39789893,39789466,,1711109732,comment,39788590
,39789902,39788590,,1711109786,comment,39788590
jshreder,39819663,39805484,"This looks great -- I&#x27;ve been using <a href=""https:&#x2F;&#x2F;github.com&#x2F;ibigio&#x2F;shell-ai"">https:&#x2F;&#x2F;github.com&#x2F;ibigio&#x2F;shell-ai</a> (aliased to `q` ) but this looks even more apt for my use case. I use TypingMind for any real conversation with LLMs, but for quick answers in terminal, these kinds of tools are super useful.<p>I love the `ask` and `rask` shortcuts!<p>Would love support for Claude APIs :)",1711391223,comment,39805484
mehmet_mhy,39805960,39805484,"This looks awesome. I like how clean it looks. I made something similar called Cha (<a href=""https:&#x2F;&#x2F;github.com&#x2F;MehmetMHY&#x2F;cha"">https:&#x2F;&#x2F;github.com&#x2F;MehmetMHY&#x2F;cha</a>) that supports image generation, answer search, and web scrapping.",1711271645,comment,39805484
baalimago,39806137,39805960,"Very cool! The way to swap between models and &#x27;live configure&#x27; is neat, also the ascii picture previews.<p>I think the idea of a cli text&#x2F;photo generator is so simple I think that anyone who is technically adept enough to appreciate it are also able to write a version of their own within a short amount of time.",1711274683,comment,39805484
