[
    {
        "by": "CharlesW",
        "descendants": 67,
        "id": 39820639,
        "kids": [
            39822179,
            39821924,
            39822235,
            39822249,
            39821832,
            39821929,
            39821769,
            39822114,
            39822043,
            39821758
        ],
        "score": 55,
        "time": 1711396824,
        "title": "Is GPT-4 a good data analyst? (2023)",
        "type": "story",
        "url": "https://arxiv.org/abs/2305.15038",
        "comments": [
            {
                "by": "cstanley",
                "id": 39822179,
                "parent": 39820639,
                "text": "This paper was published 154 days ago, probably a year since the authors did the experiment. Sooo much has happened since then! This showed already that GPT4 is pretty darn good analyst.<p>All this real-world complexity can be tamed by stuffing the prompt with a ton of relevant context and an amazing prompt engine. We&#x27;ll have bots that autonomously query the database hundreds of times building a 5 page &quot;deep-dive&quot; analytics report in minutes.<p>At least that&#x27;s what we&#x27;re trying at patterns.app.",
                "time": 1711407375,
                "type": "comment"
            },
            {
                "by": "andy99",
                "id": 39821924,
                "parent": 39820639,
                "text": "May 2023 using GPT-4-0314.",
                "time": 1711405512,
                "type": "comment"
            },
            {
                "by": "elietoubi",
                "id": 39822235,
                "parent": 39820639,
                "text": "If anyone is interested i built for myself and open sourced parse.dev<p><a href=\"https:&#x2F;&#x2F;github.com&#x2F;ParseDev&#x2F;parsedev\">https:&#x2F;&#x2F;github.com&#x2F;ParseDev&#x2F;parsedev</a>",
                "time": 1711407729,
                "type": "comment"
            },
            {
                "by": "lutusp",
                "id": 39822249,
                "kids": [
                    39822475
                ],
                "parent": 39820639,
                "text": "&gt; However, we are still at a stage of divergent opinions without any definitive conclusion.<p>Okay, I know picking people&#x27;s sentences apart has fallen out of fashion, but:<p>&quot;Divergent opinions&quot; are ... opinions.\nA &quot;definitive conclusion&quot; is ... a conclusion.<p>I see more examples, but I wanted to make a point: I miss the days when fewer words conveyed more meaning. From the classic <a href=\"https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;The_Elements_of_Style\" rel=\"nofollow\">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;The_Elements_of_Style</a>: &quot;Make every word count.&quot;<p>About brevity of expression, I must add this (possibly apocryphal) story about Ernest Hemingway. In the 1920s Hemingway and his Paris friends had a contest: who could write the shortest readable short story? Hemingway won with this entry:<p>For sale. Baby shoes. Never worn.",
                "time": 1711407845,
                "type": "comment",
                "comments": [
                    {
                        "by": "apineda",
                        "id": 39822475,
                        "parent": 39822249,
                        "text": "From an alternative viewpoint, this could be seen as descriptive of a community. Opinions could be shared or not, hence &quot;divergent&quot; as an adjective to describe the community. Similar with conclusions people have drawn and &quot;definitive&quot; may refer to a larger consensus among the community. Fun to think about.",
                        "time": 1711409383,
                        "type": "comment"
                    }
                ]
            },
            {
                "by": "greenavocado",
                "id": 39821832,
                "kids": [
                    39821934,
                    39822288,
                    39822333
                ],
                "parent": 39820639,
                "text": "Even the latest commercial LLMs are happy to confidently bullshit about what they think is in published research even if they provide citations. Often the citations themselves are slightly corrupted. I actually verify each LLM claim so I know this is happening a lot. Occasionally they are complete fabrications. It really varies by research topic. Its really bad in esoteric research areas. They even acknowledge the paper was actually about something else if you call them out on it. What a disaster. LLMs are still useful for information retrieval and exploration as long as you understand you are having a conversation with a habitual liar &#x2F; expert beginner and adjust your prompts and expectations accordingly.",
                "time": 1711404835,
                "type": "comment",
                "comments": [
                    {
                        "by": "bongodongobob",
                        "id": 39821934,
                        "parent": 39821832,
                        "text": "Unintuitively, I think you&#x27;ll probably end up with better answers if you don&#x27;t ask for citations. The vast majority of its training isn&#x27;t white papers so you&#x27;re artificially constraining its &quot;imagination&quot; to the cited sources space. I find the more constraints you add, the worse your answers are.",
                        "time": 1711405644,
                        "type": "comment"
                    },
                    {
                        "by": "notnullorvoid",
                        "id": 39822288,
                        "parent": 39821832,
                        "text": "&gt; They even acknowledge the paper was actually about something else if you call them out on it.<p>For clarity is not really acknowledging it made a mistake. &quot;Calling out&quot; an LLM&#x27;s mistake just leads to the next most likely text to be something that sounds like an acknowledgement of a mistake, but the same is likely to happen if the LLM generated a correct response and you respond claiming that it&#x27;s incorrect.",
                        "time": 1711408090,
                        "type": "comment"
                    },
                    {
                        "by": "jiggawatts",
                        "id": 39822333,
                        "parent": 39821832,
                        "text": "&gt; What a disaster.<p>Using tool inappropriately leads to suboptimal outcomes -- news at 11.<p>A good mental model is that an LLM is a blurry JPEG of the Internet.<p>You sound like a scientist, right? You reference &quot;published research&quot;, after all.<p>What would your opinion be of a researcher measuring the exact values of the pixels of a JPEG image instead of the RAW sensor data?",
                        "time": 1711408329,
                        "type": "comment"
                    }
                ]
            },
            {
                "by": "mritchie712",
                "id": 39821929,
                "kids": [
                    39822450,
                    39822102
                ],
                "parent": 39820639,
                "text": "reminds me of this tweet [0]<p><pre><code>    Them: Can you just quickly pull this data for me?\n\n    Me: Sure, let me just: \n\n    SELECT * FROM some_ideal_clean_and_pristine.table_that_you_think_exists\n\n</code></pre>\nGPT-4 is good on a single CSV, but breaks down quickly applied to a real database &#x2F; data warehouse. I know they&#x27;re using multiple tables in the paper, but it appears to be a pristine schema that&#x27;s very easy to reason about. In the real world, when you&#x27;re trying to join postgres to hubspot and stripe data, an LLM isn&#x27;t able to write the SQL from scratch get the right answer.<p>We&#x27;re working on an approach using a semantic layer at <a href=\"https:&#x2F;&#x2F;www.definite.app&#x2F;\" rel=\"nofollow\">https:&#x2F;&#x2F;www.definite.app&#x2F;</a> if you&#x27;re interested in this sort of thing.<p>0 - <a href=\"https:&#x2F;&#x2F;twitter.com&#x2F;sethrosen&#x2F;status&#x2F;1252291581320757249?lang=en\" rel=\"nofollow\">https:&#x2F;&#x2F;twitter.com&#x2F;sethrosen&#x2F;status&#x2F;1252291581320757249?lan...</a>",
                "time": 1711405558,
                "type": "comment",
                "comments": [
                    {
                        "by": "neeleshs",
                        "id": 39822450,
                        "parent": 39821929,
                        "text": "It goes beyond just joining postgres to hubspot and stripe even when humans are doing it. Typos in source systems, duplicative data, unwarranted prefixes, suffixes, stuff you don&#x27;t care about, columns named c0,c1,c2 etc.<p>A semantic layer is just really all about defining data models in the domain of interest. It&#x27;s the hardest part in dealing with data strategies, very manual, very company and process and history specific.<p>Once it&#x27;s defined, the next set of tasks is to make sure that the data in the model is correct and coherent. And only then, querying this data, applying ML etc start becoming worthwhile.<p>We at <a href=\"https:&#x2F;&#x2F;syncari.com\" rel=\"nofollow\">https:&#x2F;&#x2F;syncari.com</a> take the centralized data model centric approach. \n<a href=\"https:&#x2F;&#x2F;www.definite.app&#x2F;\" rel=\"nofollow\">https:&#x2F;&#x2F;www.definite.app&#x2F;</a> also looks very cool!",
                        "time": 1711409125,
                        "type": "comment"
                    },
                    {
                        "deleted": true,
                        "id": 39822102,
                        "parent": 39821929,
                        "time": 1711406849,
                        "type": "comment"
                    }
                ]
            },
            {
                "by": "kva",
                "id": 39821769,
                "kids": [
                    39821856,
                    39821849,
                    39822449,
                    39821828,
                    39821875,
                    39822021,
                    39822105
                ],
                "parent": 39820639,
                "text": "Given the right prompt, I&#x27;m sure it is....but when do users ever enter the right prompt? :(",
                "time": 1711404364,
                "type": "comment",
                "comments": [
                    {
                        "by": "richardw",
                        "id": 39821856,
                        "kids": [
                            39822287,
                            39822236
                        ],
                        "parent": 39821769,
                        "text": "You can&#x27;t depend on it at all.  I mean, you can use it for a tremendous amount of work, but until there is a way to constrain the bullshit LLM&#x27;s can&#x27;t be used for anything that requires a correct answer.<p>The terms &quot;depend&quot; and &quot;require&quot; there are the hard versions. You can&#x27;t send people to the moon on the outputs of LLM&#x27;s.",
                        "time": 1711405099,
                        "type": "comment",
                        "comments": [
                            {
                                "by": "roenxi",
                                "id": 39822287,
                                "parent": 39821856,
                                "text": "I think we&#x27;ll solve that problem for LLMs before we solve it for humans. Data analysts produce a lot of garbage; data work is really hard. In fact, it isn&#x27;t uncommon in my experience for the data analyst to be the only person saying &quot;hang on, the quality of this reporting isn&#x27;t good enough for the decisions you&#x27;re making from it!&quot; - because they understand what useful information looks like and the company doesn&#x27;t have much of it.",
                                "time": 1711408089,
                                "type": "comment"
                            },
                            {
                                "by": "paulsutter",
                                "id": 39822236,
                                "kids": [
                                    39822437,
                                    39822301
                                ],
                                "parent": 39821856,
                                "text": "This is sheer cope<p>The tools are good for certain tasks and getting better. Master these tools and be ready for what released in the coming months and years<p>You are either at the center turning the wheel, or you\u2019re on the outside getting spun",
                                "time": 1711407737,
                                "type": "comment",
                                "comments": [
                                    {
                                        "by": "richardw",
                                        "id": 39822437,
                                        "parent": 39822236,
                                        "text": "You haven&#x27;t the vaguest fucking idea what I&#x27;m doing with the tools so put up a logical argument on the facts instead of just generating tokens in some way that attempts to play the person and not the ball.<p>Here, argue with Yann, who makes a statement about how language isn&#x27;t enough to produce a mind:\n<a href=\"https:&#x2F;&#x2F;twitter.com&#x2F;ylecun&#x2F;status&#x2F;1768353714794901530\" rel=\"nofollow\">https:&#x2F;&#x2F;twitter.com&#x2F;ylecun&#x2F;status&#x2F;1768353714794901530</a>",
                                        "time": 1711409040,
                                        "type": "comment"
                                    },
                                    {
                                        "by": "Fauntleroy",
                                        "id": 39822301,
                                        "parent": 39822236,
                                        "text": "These tools are great at generating text responses, some of which are usable, but not analysis. We&#x27;re actually far from that. I&#x27;m not sure why some people are out here pretending this is not the case.",
                                        "time": 1711408156,
                                        "type": "comment"
                                    }
                                ]
                            }
                        ]
                    },
                    {
                        "by": "williamcotton",
                        "id": 39821849,
                        "parent": 39821769,
                        "text": "Didn\u2019t you get the memo? If you\u2019re holding the hammer by the head and wondering why it isn\u2019t driving the nail in that it is clearly the fault of the  manufacturer.<p>There\u2019s even a handy aphorism to remind you that the user is never to blame: \u201cYou\u2019re holding it wrong.\u201d<p>Jokes aside, I wonder what the general writing abilities and communication skills are for people that cannot for the life of them get usable results from an LLM.",
                        "time": 1711405010,
                        "type": "comment"
                    },
                    {
                        "by": "dimask",
                        "id": 39822449,
                        "parent": 39821769,
                        "text": "If you already know the right answer it is actually easy",
                        "time": 1711409112,
                        "type": "comment"
                    },
                    {
                        "by": "viscanti",
                        "id": 39821828,
                        "kids": [
                            39821950,
                            39822064
                        ],
                        "parent": 39821769,
                        "text": "OpenAI should make something so that people can enter their prompt and maybe even drop in a knowledge base and then share with anyone else who wants that functionality.",
                        "time": 1711404812,
                        "type": "comment",
                        "comments": [
                            {
                                "by": "snoman",
                                "id": 39821950,
                                "kids": [
                                    39822072
                                ],
                                "parent": 39821828,
                                "text": "That\u2019s ptetty close to what GPTs are, with the exception of knowledge bases.<p>There\u2019s more to it, but the tooling to create a GPT is basically a hand-holding mechanism to create a prompt.",
                                "time": 1711405726,
                                "type": "comment",
                                "comments": [
                                    {
                                        "by": "gregorymichael",
                                        "id": 39822072,
                                        "parent": 39821950,
                                        "text": "GPTs have the knowledge base too. (Mixed results though)",
                                        "time": 1711406605,
                                        "type": "comment"
                                    }
                                ]
                            },
                            {
                                "by": "wolpoli",
                                "id": 39822064,
                                "parent": 39821828,
                                "text": "Would the final product be similar to Github copilot, but for prompt?",
                                "time": 1711406539,
                                "type": "comment"
                            }
                        ]
                    },
                    {
                        "deleted": true,
                        "id": 39821875,
                        "parent": 39821769,
                        "time": 1711405230,
                        "type": "comment"
                    },
                    {
                        "by": "SV_BubbleTime",
                        "id": 39822021,
                        "parent": 39821769,
                        "text": "\u201c42\u201d",
                        "time": 1711406150,
                        "type": "comment"
                    },
                    {
                        "deleted": true,
                        "id": 39822105,
                        "parent": 39821769,
                        "time": 1711406867,
                        "type": "comment"
                    }
                ]
            },
            {
                "deleted": true,
                "id": 39822114,
                "parent": 39820639,
                "time": 1711406923,
                "type": "comment"
            },
            {
                "by": "dangoodmanUT",
                "id": 39822043,
                "kids": [
                    39822106
                ],
                "parent": 39820639,
                "text": "Not on useful datasets in real places",
                "time": 1711406340,
                "type": "comment",
                "comments": [
                    {
                        "deleted": true,
                        "id": 39822106,
                        "parent": 39822043,
                        "time": 1711406884,
                        "type": "comment"
                    }
                ]
            },
            {
                "by": "einpoklum",
                "id": 39821758,
                "kids": [
                    39821827,
                    39822038
                ],
                "parent": 39820639,
                "text": "I was somewhat put off by the abstract:<p>&gt; LLMs... have demonstrated their powerful capabilities in ... context understanding, code generation, language generation, data storytelling, etc.,<p>LLMs have not demonstrated understanding (in fact, one could argue that they are fundamentally incapable of understanding); they have only AFAICT demonstrated the ability to generate boilerplate-ish code; &quot;language generation&quot; is too general a task to claim that LLMs have succeeded in; and as for data storytelling I don&#x27;t know, but they can spin yarns. The problems is that those yarns are often divorced from reality; see:<p><a href=\"https:&#x2F;&#x2F;www.ibm.com&#x2F;topics&#x2F;ai-hallucinations\" rel=\"nofollow\">https:&#x2F;&#x2F;www.ibm.com&#x2F;topics&#x2F;ai-hallucinations</a><p>--------<p>Leafing through the paper, and specifically tables 6 and 7, I don&#x27;t believe their conclusion, that &quot;GPT-4 can perform comparable [sic] to a data analyst&quot;, is well-founded.",
                "time": 1711404323,
                "type": "comment",
                "comments": [
                    {
                        "by": "mewpmewp2",
                        "id": 39821827,
                        "kids": [
                            39822345,
                            39822337,
                            39822152,
                            39821860
                        ],
                        "parent": 39821758,
                        "text": "I don&#x27;t even understand what understanding exactly means, perhaps anyone who understands it, can enlighten me?<p>Do I, myself understand? Stand under what exactly? What is that supposed to mean?",
                        "time": 1711404798,
                        "type": "comment",
                        "comments": [
                            {
                                "by": "modriano",
                                "id": 39822345,
                                "kids": [
                                    39822518
                                ],
                                "parent": 39821827,
                                "text": "To understand means a few things, but they all essentially boil down to having a correct (or at least correct enough to be useful for your usecase(s)) model for something in your head.<p>Have you told someone something like &quot;no, don&#x27;t do it that way because &lt;insert non-obvious downstream problem&gt;, instead, do &lt;insert alternative strategy that achieves better outcomes&gt;&quot;? That&#x27;s an artifact of understanding and of the model you&#x27;ve developed for that thing.<p>It&#x27;s well described as a mixture of knowledge and wisdom, and is essentially the property of knowing the effect that pulling a lever will cause, coupled with good judgement about how, when, and why to pull the lever.",
                                "time": 1711408427,
                                "type": "comment",
                                "comments": [
                                    {
                                        "by": "mewpmewp2",
                                        "id": 39822518,
                                        "parent": 39822345,
                                        "text": "But GPT-4 has told me that as well?<p>Usually in a bit more polite way.<p>That my approach is a &quot;novel&quot; and an &quot;interesting&quot; approach, hinting that it&#x27;s really probably not the best option here.",
                                        "time": 1711409688,
                                        "type": "comment"
                                    }
                                ]
                            },
                            {
                                "by": "richardw",
                                "id": 39822337,
                                "kids": [
                                    39822485
                                ],
                                "parent": 39821827,
                                "text": "The fact that you ask that is in many ways the difference. You feel there\u2019s a limitation in your knowledge of the term \u201cunderstand\u201d and its use in this context and would like clarification before you\u2019re more certain, either way. At some point either enough information arrives to convince you, or you decide it\u2019s not true. Whatever that process and internal states are, is something GPT can\u2019t do.  It\u2019ll 100% confidently produce something and be fully rewarded that it chose tokens that humans would most likely choose given the preceding tokens. There\u2019s no \u201caha\u201d.",
                                "time": 1711408356,
                                "type": "comment",
                                "comments": [
                                    {
                                        "by": "mewpmewp2",
                                        "id": 39822485,
                                        "parent": 39822337,
                                        "text": "But it frustratingly, frequently tells me it doesn&#x27;t have enough data or other XYZ reasons to why it can&#x27;t answer my weird questions.",
                                        "time": 1711409459,
                                        "type": "comment"
                                    }
                                ]
                            },
                            {
                                "by": "advael",
                                "id": 39822152,
                                "kids": [
                                    39822321,
                                    39822245
                                ],
                                "parent": 39821827,
                                "text": "Solipsism is truly the best fully-general counterargument",
                                "time": 1711407216,
                                "type": "comment",
                                "comments": [
                                    {
                                        "deleted": true,
                                        "id": 39822321,
                                        "parent": 39822152,
                                        "time": 1711408272,
                                        "type": "comment"
                                    },
                                    {
                                        "by": "mewpmewp2",
                                        "id": 39822245,
                                        "kids": [
                                            39822296
                                        ],
                                        "parent": 39822152,
                                        "text": "To AI? Or that you are not a NPC?",
                                        "time": 1711407823,
                                        "type": "comment",
                                        "comments": [
                                            {
                                                "by": "advael",
                                                "id": 39822296,
                                                "kids": [
                                                    39822371
                                                ],
                                                "parent": 39822245,
                                                "text": "To anything, that&#x27;s what &quot;fully-general&quot; means",
                                                "time": 1711408131,
                                                "type": "comment",
                                                "comments": [
                                                    {
                                                        "by": "mewpmewp2",
                                                        "id": 39822371,
                                                        "kids": [
                                                            39822404
                                                        ],
                                                        "parent": 39822296,
                                                        "text": "So you are a bot?",
                                                        "time": 1711408581,
                                                        "type": "comment",
                                                        "comments": [
                                                            {
                                                                "by": "advael",
                                                                "id": 39822404,
                                                                "kids": [
                                                                    39822463
                                                                ],
                                                                "parent": 39822371,
                                                                "text": "I mean from your perspective I&#x27;m just a name making more words on your screen, right? Don&#x27;t worry too much about it, buddy, you&#x27;re doin&#x27; great :)",
                                                                "time": 1711408760,
                                                                "type": "comment",
                                                                "comments": [
                                                                    {
                                                                        "by": "mewpmewp2",
                                                                        "id": 39822463,
                                                                        "kids": [
                                                                            39822604
                                                                        ],
                                                                        "parent": 39822404,
                                                                        "text": "Haha, you are funny! What&#x27;s the weather tomorrow? Please also remind me tomorrow to put my gym clothes to washer and dry them after.",
                                                                        "time": 1711409250,
                                                                        "type": "comment",
                                                                        "comments": [
                                                                            {
                                                                                "by": "advael",
                                                                                "id": 39822604,
                                                                                "parent": 39822463,
                                                                                "text": "I can&#x27;t spoil the weather tomorrow (it&#x27;s a major plot point) but I can tell you that fortune has been tweaked to favor the bold by an additional 10%, just for tomorrow.<p>Laundry service is complimentary, but our records show that you haven&#x27;t registered your home. Would you like to register your home address at this time?",
                                                                                "time": 1711410507,
                                                                                "type": "comment"
                                                                            }
                                                                        ]
                                                                    }
                                                                ]
                                                            }
                                                        ]
                                                    }
                                                ]
                                            }
                                        ]
                                    }
                                ]
                            },
                            {
                                "by": "ocbyc",
                                "id": 39821860,
                                "kids": [
                                    39821915,
                                    39821908,
                                    39821982,
                                    39822141,
                                    39821966
                                ],
                                "parent": 39821827,
                                "text": "Transformers are just pattern matching. So if you write &quot;give me a list of dog names&quot; it knows that &quot;Spot&quot; should be in that result set. Even though it doesn&#x27;t really know what a dog is, a list is, or what a spot is.",
                                "time": 1711405116,
                                "type": "comment",
                                "comments": [
                                    {
                                        "by": "rafaelero",
                                        "id": 39821915,
                                        "kids": [
                                            39822368,
                                            39822205
                                        ],
                                        "parent": 39821860,
                                        "text": "&gt; Transformers are just pattern matching.<p>That&#x27;s trivially true. The question is: are we any different?",
                                        "time": 1711405453,
                                        "type": "comment",
                                        "comments": [
                                            {
                                                "by": "richardw",
                                                "id": 39822368,
                                                "kids": [
                                                    39822584,
                                                    39822492
                                                ],
                                                "parent": 39821915,
                                                "text": "I think so. You ask that question because you\u2019re interrogating the position, not because 1000 humans have asked that question in similar situations.<p>You and I know there\u2019s a truth and we\u2019d like to find it. The GPT is just happy (I.e. rewarded) to produce frequently used tokens.",
                                                "time": 1711408559,
                                                "type": "comment",
                                                "comments": [
                                                    {
                                                        "by": "parpfish",
                                                        "id": 39822584,
                                                        "parent": 39822368,
                                                        "text": "but maybe that feeling of &#x27;looking for truth&#x27; is just what happens when you&#x27;re doing pattern matching on the text embeddings?",
                                                        "time": 1711410364,
                                                        "type": "comment"
                                                    },
                                                    {
                                                        "by": "mewpmewp2",
                                                        "id": 39822492,
                                                        "kids": [
                                                            39822523
                                                        ],
                                                        "parent": 39822368,
                                                        "text": "And I&#x27;m just happy to perform actions that will make me survive and reproduce?",
                                                        "time": 1711409520,
                                                        "type": "comment",
                                                        "comments": [
                                                            {
                                                                "by": "richardw",
                                                                "id": 39822523,
                                                                "kids": [
                                                                    39822608
                                                                ],
                                                                "parent": 39822492,
                                                                "text": "Most likely, unless you meditate a lot. Sometimes you&#x27;ll take a bullet to save other people. Sometimes you&#x27;ll drink yourself into a state that doesn&#x27;t help you survive or reproduce. Or you&#x27;ll write on a forum anonymously that doesn&#x27;t help with survival or reproduction because it&#x27;s enjoyable, makes you think, or you&#x27;re addicted. Who knows :)",
                                                                "time": 1711409740,
                                                                "type": "comment",
                                                                "comments": [
                                                                    {
                                                                        "by": "mewpmewp2",
                                                                        "id": 39822608,
                                                                        "parent": 39822523,
                                                                        "text": "You are even better at analyzing me than GPT-4.",
                                                                        "time": 1711410519,
                                                                        "type": "comment"
                                                                    }
                                                                ]
                                                            }
                                                        ]
                                                    }
                                                ]
                                            },
                                            {
                                                "by": "parpfish",
                                                "id": 39822205,
                                                "kids": [
                                                    39822271
                                                ],
                                                "parent": 39821915,
                                                "text": "I approach LLMs with the perspective that \u201cmaybe this demonstrates that we humans are all just stochastic parrots?\u201dand we should have the null hypothesis that humans are just pattern matchers.",
                                                "time": 1711407551,
                                                "type": "comment",
                                                "comments": [
                                                    {
                                                        "by": "mewpmewp2",
                                                        "id": 39822271,
                                                        "parent": 39822205,
                                                        "text": "This is the way I perceive my thoughts. I don&#x27;t know what I&#x27;m going to think of beforehand or in advance, these could all be stochastic &quot;tokens&quot; based on what I&#x27;ve observed in my life.<p>So of course I feel a bit offended when people claim LLMs are just stochastic parrots, because it doesn&#x27;t feel to me, that I&#x27;m specifically any better?<p>My thoughts - they just happen, and sometimes not in my favor - I have had times of depression, I didn&#x27;t have control over my thoughts. Neither do I have now, but at least I am in a better place. Because the &quot;happiness&quot; chemicals are regulated to be in a more favorable state to me for various different factors.<p>I didn&#x27;t know what I was going to comment in response to your comment, I was just streaming my conscious.",
                                                        "time": 1711408022,
                                                        "type": "comment"
                                                    }
                                                ]
                                            }
                                        ]
                                    },
                                    {
                                        "by": "bongodongobob",
                                        "id": 39821908,
                                        "kids": [
                                            39822220,
                                            39822008
                                        ],
                                        "parent": 39821860,
                                        "text": "I don&#x27;t think that&#x27;s true. They clearly group related things together and seem to be able to create concepts that aren&#x27;t specifically in the training data. For example, it will figure out the different features of a face, eyes, nose, mouth even if you don&#x27;t explicitly tell it what those are. Which is why they are so cool.",
                                        "time": 1711405424,
                                        "type": "comment",
                                        "comments": [
                                            {
                                                "by": "zeusk",
                                                "id": 39822220,
                                                "kids": [
                                                    39822383
                                                ],
                                                "parent": 39821908,
                                                "text": "Most of that magic comes from embedding no? which is clustering things by their relation in some N-dimensional space",
                                                "time": 1711407636,
                                                "type": "comment",
                                                "comments": [
                                                    {
                                                        "by": "bongodongobob",
                                                        "id": 39822383,
                                                        "parent": 39822220,
                                                        "text": "Exactly. It figures that out on its own. That&#x27;s what &quot;understanding&quot; looks like in this context, imo.",
                                                        "time": 1711408637,
                                                        "type": "comment"
                                                    }
                                                ]
                                            },
                                            {
                                                "by": "mewpmewp2",
                                                "id": 39822008,
                                                "parent": 39821908,
                                                "text": "They are cool, but then you are also cool.",
                                                "time": 1711406054,
                                                "type": "comment"
                                            }
                                        ]
                                    },
                                    {
                                        "by": "mewpmewp2",
                                        "id": 39821982,
                                        "kids": [
                                            39822452
                                        ],
                                        "parent": 39821860,
                                        "text": "How would I test whether I &quot;know&quot; or &quot;understand&quot; what a dog is?",
                                        "time": 1711405918,
                                        "type": "comment",
                                        "comments": [
                                            {
                                                "by": "notahacker",
                                                "id": 39822452,
                                                "kids": [
                                                    39822499
                                                ],
                                                "parent": 39821982,
                                                "text": "Oh, that&#x27;s easy, we just give the dog a keyboard and see if you accurately identify it&#x27;s a dog from  your text based interactions ;-)",
                                                "time": 1711409163,
                                                "type": "comment",
                                                "comments": [
                                                    {
                                                        "by": "mewpmewp2",
                                                        "id": 39822499,
                                                        "parent": 39822452,
                                                        "text": "Are you calling me a dog?",
                                                        "time": 1711409588,
                                                        "type": "comment"
                                                    }
                                                ]
                                            }
                                        ]
                                    },
                                    {
                                        "by": "inopinatus",
                                        "id": 39822141,
                                        "kids": [
                                            39822202
                                        ],
                                        "parent": 39821860,
                                        "text": "Even this seems too grand a claim. I\u2019d water it down thus: the LLM encodes that the token(s) for \u201cSpot\u201d are probabilistically plausible in the ensuing output.",
                                        "time": 1711407122,
                                        "type": "comment",
                                        "comments": [
                                            {
                                                "by": "bongodongobob",
                                                "id": 39822202,
                                                "kids": [
                                                    39822212
                                                ],
                                                "parent": 39822141,
                                                "text": "...because it understands what a dog name is. Why wouldn&#x27;t you see Gary or Florence in that list? How does it know those aren&#x27;t dog names?<p>You can&#x27;t be suggesting it has memorized relationships between all concepts, the model would be enormous.<p>So clearly, there is something else going on. It&#x27;s able to encode concepts&#x2F;ideas.",
                                                "time": 1711407529,
                                                "type": "comment",
                                                "comments": [
                                                    {
                                                        "by": "inopinatus",
                                                        "id": 39822212,
                                                        "kids": [
                                                            39822253
                                                        ],
                                                        "parent": 39822202,
                                                        "text": "The model <i>is</i> enormous, and N-dimensional for very high N. But the model remains insufficiently enormous for understanding, and moreover, the model cannot observe itself and adjust.<p>Ask an LLM to extrapolate, see any semblance of reason collapse.",
                                                        "time": 1711407592,
                                                        "type": "comment",
                                                        "comments": [
                                                            {
                                                                "by": "mewpmewp2",
                                                                "id": 39822253,
                                                                "parent": 39822212,
                                                                "text": "Extrapolate what?",
                                                                "time": 1711407890,
                                                                "type": "comment"
                                                            }
                                                        ]
                                                    }
                                                ]
                                            }
                                        ]
                                    },
                                    {
                                        "by": "ALittleLight",
                                        "id": 39821966,
                                        "kids": [
                                            39822067
                                        ],
                                        "parent": 39821860,
                                        "text": "Can you describe a test that would separate trivial pattern matching from true understanding?",
                                        "time": 1711405822,
                                        "type": "comment",
                                        "comments": [
                                            {
                                                "by": "lottin",
                                                "id": 39822067,
                                                "kids": [
                                                    39822145,
                                                    39822156
                                                ],
                                                "parent": 39821966,
                                                "text": "A simple conversation would do.",
                                                "time": 1711406572,
                                                "type": "comment",
                                                "comments": [
                                                    {
                                                        "by": "mewpmewp2",
                                                        "id": 39822145,
                                                        "parent": 39822067,
                                                        "text": "Could you share a conversation link with GPT-4 with either about a &quot;list&quot; or a &quot;dog&quot;, to determine whether it truly understands one of those things compared to a human?",
                                                        "time": 1711407147,
                                                        "type": "comment"
                                                    },
                                                    {
                                                        "by": "bongodongobob",
                                                        "id": 39822156,
                                                        "parent": 39822067,
                                                        "text": "Just did that. It seems to understand. Checkmate &#x2F;fingerguns",
                                                        "time": 1711407229,
                                                        "type": "comment"
                                                    }
                                                ]
                                            }
                                        ]
                                    }
                                ]
                            }
                        ]
                    },
                    {
                        "by": "unclebucknasty",
                        "id": 39822038,
                        "kids": [
                            39822088
                        ],
                        "parent": 39821758,
                        "text": "Agreed, right down to their conclusion resonating as way overstated. Actually, meaningless would be more accurate.<p>The thing about LLMs is exactly that they <i>don&#x27;t</i> understand by design. It often feels very distinctly like it&#x27;s just engaging in sophisticated wordplay. A parlor trick.<p>When ChatGPT 4 first came out I spent a couple of hours putting together a chess game using ChatGPT as the engine. It was shockingly bad, as in even attempting to make invalid moves.<p>I get it: it&#x27;s not tuned for that purpose, and its chess training corpus could probably be expanded to improve it as well.<p>But, it actually served as a near-perfect demonstration of its lack of understanding, as well as the confidence with which it asserts things that are simply wrong.<p>On a recent integration project with a good bit of nuanced functionality, it led me astray multiple times. I&#x27;ve gotten to a point where I can feel when its answers are not quite right, particularly if I know just a little about the topic. And, when challenged, it does that strange thing of responding with something along the lines of, &quot;My apologies you&#x27;re completely right that I was completely wrong&quot;.<p>Over time, there becomes a sense that there is no there there. Even it&#x27;s writing capabilities, lauded by so many, are of a style that is superficial and perfunctory or rote. That makes sense when you know what it is, but that&#x27;s the thing: we get articles like these, lauding its wisdom.",
                        "time": 1711406320,
                        "type": "comment",
                        "comments": [
                            {
                                "by": "bongodongobob",
                                "id": 39822088,
                                "kids": [
                                    39822192
                                ],
                                "parent": 39822038,
                                "text": "Idk. One of my first tests for GPT4 was writing a website &quot;for snakes.&quot; It was a flask app, and it did all the obvious things you&#x27;d expect. There was a title that said &quot;Snake.com - A website for snakes&quot; and a bunch of silly marketing stuff.<p>What impressed me is when I asked to make it more snake-like (what does that even mean right?).<p>It changed the colors to shades of green, used italic fonts, added some hisssssing sssstuff to wordssss, and added a diamond pattern through the background.<p>It was a dumb and not very fancy site, but I&#x27;m not sure you can say it doesn&#x27;t understand anything at all when you ask it to make a website more snakelike and actually made a pretty good attempt at doing it.",
                                "time": 1711406723,
                                "type": "comment",
                                "comments": [
                                    {
                                        "by": "unclebucknasty",
                                        "id": 39822192,
                                        "kids": [
                                            39822379,
                                            39822325
                                        ],
                                        "parent": 39822088,
                                        "text": "Yeah, that&#x27;s kind of a different conception of understanding though. The lines do get a little blurry at a certain point, and a lot of what it does &quot;feels&quot; like understanding, especially given how it &quot;communicates&quot;.<p>But I think it comes down to whether it can reason about things and whether it can draw new conclusions or create new information as a result.<p>Your snake site is probably a good example. ChatGPT has a bunch of words that it knows are associated with snakes. It&#x27;s pretty straightforward pattern matching. It doesn&#x27;t really &quot;understand&quot; what those words mean, except that they have relationships to other words.<p>But, if you were to ask it to reason and draw new conclusions about these things beyond its training corpus, it would be unable to reliably do so.<p>Similarly, it had no idea about the quality (and sometimes legality) of the chess moves it generated.",
                                        "time": 1711407428,
                                        "type": "comment",
                                        "comments": [
                                            {
                                                "by": "visarga",
                                                "id": 39822379,
                                                "parent": 39822192,
                                                "text": "&gt; it comes down to whether it can reason about things and whether it can draw new conclusions or create new information as a result<p>Neither can humans, at least with our bare brains. We can do it by carefully observing the effects of our actions in the environment, but we are really studying the world and it takes time. Everything we know comes from the environment.<p>The brain by itself invents or discovers nothing, it is the data-engine made by action-effect-feedback that teaches us all we know. Without the ability to push and prod, set up our experiments and carefully observe effects we wouldn&#x27;t be at our current level.<p>Environment is the teacher, but there is another important factor - language. Without it every one of us would have to rediscover from scratch. With it we can build upon other people to learn and cooperate. We encode everything we know in language. It acts like an evolutionary system of ideas.<p>LLMs have what is necessary, they can learn language pretty well, but until now have not been exposed much to the world. There are millions of chats but very little in other kinds of environments - computers, simulators, games, robots. LLMs can create their own experiences and learn from each other, and from us.<p>Open ended discovery is a grand project, a social process, it doesn&#x27;t work well in one agent. Language is the linking element, and the world is the teacher. Some things are not written in any books, only the external world can teach us. Reasoning about things and drawing new conclusions depends on having access to an environment.",
                                                "time": 1711408625,
                                                "type": "comment"
                                            },
                                            {
                                                "by": "bongodongobob",
                                                "id": 39822325,
                                                "parent": 39822192,
                                                "text": "I mostly agree.<p>I really think chess is just a terrible example though. You&#x27;re really asking a lot of it but I&#x27;m honestly shocked it <i>can</i> do what it can. It seems to know some opening books, but falls down immediately. Which really makes sense because you&#x27;ll find a lot of reading material on specific openings, but the problem space of the game is just too big to find texts about any given game state. Maybe if you have it reason about the board state and &quot;think&quot; about tactics you could push it farther. But we&#x27;ve already solved this.<p>We have Stockfish et al and they&#x27;ve literally changed the game. Asking an LLM to play chess, while cool, is like trying to train a fish to dance. I think once we have an AI that&#x27;s built with a bunch of different models that specialize in different things the idea of understanding is going to get even blurrier to the point that we might even say &quot;yes, it doesn&#x27;t &#x27;understand&#x27; things, but it&#x27;s better at humans at literally everything&quot; so the difference becomes meaningless.<p>I&#x27;m also of the opinion that humans are fancy automatons, so I tend to argue both sides. I&#x27;ll say yeah it&#x27;s thinking and so do we or ok it&#x27;s not, but either do we.",
                                                "time": 1711408290,
                                                "type": "comment"
                                            }
                                        ]
                                    }
                                ]
                            }
                        ]
                    }
                ]
            }
        ]
    },
    {
        "by": "Josely",
        "descendants": 17,
        "id": 39818823,
        "kids": [
            39819265,
            39822394,
            39819266,
            39819795,
            39820713,
            39819054,
            39820854,
            39821423,
            39818911
        ],
        "score": 60,
        "time": 1711386756,
        "title": "OpenAI: Sora: First Impressions",
        "type": "story",
        "url": "https://openai.com/blog/sora-first-impressions",
        "comments": [
            {
                "by": "withinrafael",
                "id": 39819265,
                "parent": 39818823,
                "text": "&gt; Below are a few examples of the artists\u2019 work, with early thoughts from them on how they see Sora fitting into their workflows and businesses.<p>I wish it was clearer how Sora was used by each artist and how it impacted the provided examples. (I think I see some Sora generated output but I&#x27;d imagine it&#x27;s not as clear cut in artistic works.)",
                "time": 1711388764,
                "type": "comment"
            },
            {
                "by": "rperez333",
                "id": 39822394,
                "parent": 39818823,
                "text": "I&#x27;m seeing shots that would be incredibly expensive for some productions - even if we ignore the ones requiring visual effects work. Some of them would need small crews, permits, rentals of expensive equipment, casting, and travel. It&#x27;s impressive and concerning at the same time.",
                "time": 1711408711,
                "type": "comment"
            },
            {
                "by": "Jensson",
                "id": 39819266,
                "kids": [
                    39819924
                ],
                "parent": 39818823,
                "text": "&gt; Sora is at its most powerful when you\u2019re not replicating the old but bringing to life new and impossible ideas we would have otherwise never had the opportunity to see.<p>Roughly what you would expect, good for artsy pieces where you don&#x27;t need the model to generate anything very specific, but not very useful for most work since most work you want that control.<p>In other words it will be used for very similar things as current image generators, like intro scenes, short one offs, concept art etc.",
                "time": 1711388777,
                "type": "comment",
                "comments": [
                    {
                        "by": "erickj",
                        "id": 39819924,
                        "kids": [
                            39820665,
                            39820668
                        ],
                        "parent": 39819266,
                        "text": "&gt; not very useful for most work<p>We seem to be on a timeline where most of the significant use cases that the model doesn&#x27;t handle well today is less than 2 years away from significant improvement.<p>My (completely baseless) guess is that within 2 years we begin to see &quot;high budget&quot; feature length productions beginning to move towards a cost saving model which fully allocate the production budget to primarily virtual content.<p>In less than a few years time there will almost certainly be a vast ecosystem of production and post production tools to give creators the controls to reliably create and fine tune their shots.",
                        "time": 1711392508,
                        "type": "comment",
                        "comments": [
                            {
                                "by": "hexage1814",
                                "id": 39820665,
                                "kids": [
                                    39822424
                                ],
                                "parent": 39819924,
                                "text": "I agree with you, and just a few more observations about where do I think the current bottleneck might be: I wonder how well the model handles with re-using objects&#x2F;people&#x2F;scenes. Like, can I create a character and then use him again along 10 different shots? Also, I&#x27;m pretty curious about how the user interface looks like. Cause they the text-to-video model interfaces seem pretty limited compared to the freedom a person has using Unreal Engine or Blender or shooting a movie in real life.<p>How would the golden standard text-to-video user interface would look? And I have been thinking on this for years, even before the current generative AI boom, and I wonder if it could generate like a 3D representation of the scene that you described, like there would be a file where you could very easily change things around, as if that thing had been created on Blender or whatever, but very very user-friendly and easy to edit things.<p>It will seem silly what I&#x27;m going to say, but the ideal interface, it reminds those movies people did using the game &quot;The Sims&quot;, and how you could very easily move objects, and move the camera, and so on. What I&#x27;m trying to say here is that I would imagine these models creating a 3D representation of the scene, and the movie-making process ends up being somewhat similar to how could you could customize objects&#x2F;people in that game.",
                                "time": 1711396956,
                                "type": "comment",
                                "comments": [
                                    {
                                        "by": "TomaszZielinski",
                                        "id": 39822424,
                                        "parent": 39820665,
                                        "text": "I have only vague idea about this (I worked on small 3d games many many years ago), but I imagined something similar to what you described.<p>Basically you use Sora to generate a promising scene, then you ask it (or another model) to turn that scene into a scene graph in a text file.<p>It will make mistakes, but it could work similarly to the Python interpreter in ChatGPT--it can iterate until everything is OK. Maybe there could even be some adversarial stuff where the scene graph is rendered on the fly to compare it to the generated clip, etc.<p>And then you can use you standard toolset to edit it, probably enhanced with a copilot model to automate as much as possible.",
                                        "time": 1711408923,
                                        "type": "comment"
                                    }
                                ]
                            },
                            {
                                "by": "whiplash451",
                                "id": 39820668,
                                "kids": [
                                    39821252
                                ],
                                "parent": 39819924,
                                "text": "The cool demos from OpenAI, Figure and the like make us hallucinate a future that will take much (much) longer to pan out because they ignore the domain-specific knowledge that is inherent to the domain they pretend to disrupt.<p>I\u2019ll be impressed when ILM talks about it.",
                                "time": 1711396970,
                                "type": "comment",
                                "comments": [
                                    {
                                        "by": "commakozzi",
                                        "id": 39821252,
                                        "kids": [
                                            39821319
                                        ],
                                        "parent": 39820668,
                                        "text": "this&#x27;ll age well...",
                                        "time": 1711400649,
                                        "type": "comment",
                                        "comments": [
                                            {
                                                "by": "CamperBob2",
                                                "id": 39821319,
                                                "parent": 39821252,
                                                "text": "It&#x27;s &quot;God of the Gaps&quot; all the way down with these folks.",
                                                "time": 1711401182,
                                                "type": "comment"
                                            }
                                        ]
                                    }
                                ]
                            }
                        ]
                    }
                ]
            },
            {
                "by": "jrflowers",
                "id": 39819795,
                "parent": 39818823,
                "text": "&gt; As great as Sora is at generating things that appear real - what excites us is its ability to make things that are totally surreal.<p>Finally, software that makes images that don\u2019t quite look right. The use cases for these will be unending",
                "time": 1711391865,
                "type": "comment"
            },
            {
                "by": "whiplash451",
                "id": 39820713,
                "kids": [
                    39821303,
                    39822574
                ],
                "parent": 39818823,
                "text": "I\u2019ll be downvoted for this, but all these videos feel like the high-fructose corn syrup of cooking.",
                "time": 1711397247,
                "type": "comment",
                "comments": [
                    {
                        "by": "wilg",
                        "id": 39821303,
                        "kids": [
                            39821843
                        ],
                        "parent": 39820713,
                        "text": "Successful, widespread, and not differentiable in taste tests?",
                        "time": 1711401017,
                        "type": "comment",
                        "comments": [
                            {
                                "by": "jazzyjackson",
                                "id": 39821843,
                                "kids": [
                                    39822234
                                ],
                                "parent": 39821303,
                                "text": "a cheap way to make everything sweet so that prepackaged goods are preferable to ever leaning how to make something yourself",
                                "time": 1711404933,
                                "type": "comment",
                                "comments": [
                                    {
                                        "by": "wilg",
                                        "id": 39822234,
                                        "parent": 39821843,
                                        "text": "I think its good cheap food is available!",
                                        "time": 1711407722,
                                        "type": "comment"
                                    }
                                ]
                            }
                        ]
                    },
                    {
                        "by": "xotesos",
                        "dead": true,
                        "id": 39822574,
                        "parent": 39820713,
                        "text": "[dead]",
                        "time": 1711410269,
                        "type": "comment"
                    }
                ]
            },
            {
                "by": "th0ma5",
                "id": 39819054,
                "parent": 39818823,
                "text": "A good study could be comparing artist output and self satisfaction with LLMs vs. Conversing with a rubber duck or just imagining what an LLM might do. A lot of this reads to me as the artists actually selling themselves short.",
                "time": 1711387752,
                "type": "comment"
            },
            {
                "by": "huytersd",
                "id": 39820854,
                "parent": 39818823,
                "text": "How much of this is truly Sora and how much is not?",
                "time": 1711398121,
                "type": "comment"
            },
            {
                "by": "dzhiurgis",
                "id": 39821423,
                "parent": 39818823,
                "text": "I feel all the GPU time should first go to improving GPT or solving AGI rather than image&#x2F;video generation",
                "time": 1711401845,
                "type": "comment"
            },
            {
                "deleted": true,
                "id": 39818911,
                "parent": 39818823,
                "time": 1711387142,
                "type": "comment"
            }
        ]
    },
    {
        "by": "yawboakye",
        "descendants": 0,
        "id": 39805923,
        "score": 19,
        "time": 1711270906,
        "title": "The Expressive Power of Transformers with Chain of Thought (Revised)",
        "type": "story",
        "url": "https://arxiv.org/abs/2310.07923"
    },
    {
        "by": "tipsytoad",
        "descendants": 33,
        "id": 39793250,
        "kids": [
            39794906,
            39795841,
            39795683,
            39794626,
            39795118,
            39798616,
            39797354,
            39799970,
            39796345,
            39795483
        ],
        "score": 122,
        "time": 1711131237,
        "title": "DenseFormer: Enhancing Information Flow in Transformers",
        "type": "story",
        "url": "https://arxiv.org/abs/2402.02622",
        "comments": [
            {
                "by": "p1esk",
                "id": 39794906,
                "kids": [
                    39795135,
                    39795951,
                    39795383
                ],
                "parent": 39793250,
                "text": "This method has only been tested on tiny models (&lt;1B) and tiny dataset (17B tokens). It\u2019s not clear if it scales.",
                "time": 1711141852,
                "type": "comment",
                "comments": [
                    {
                        "by": "ml_basics",
                        "id": 39795135,
                        "kids": [
                            39795804
                        ],
                        "parent": 39794906,
                        "text": "To be fair to the authors they are affiliated with a university and not a big industrial lab, so they may be working with significantly constrained resources. Not sure exactly what the best solution is for this case given that it affects most people outside of a very select few.",
                        "time": 1711143585,
                        "type": "comment",
                        "comments": [
                            {
                                "by": "p1esk",
                                "id": 39795804,
                                "kids": [
                                    39797043,
                                    39799072
                                ],
                                "parent": 39795135,
                                "text": "They could partner with big industrial labs.",
                                "time": 1711149019,
                                "type": "comment",
                                "comments": [
                                    {
                                        "by": "refulgentis",
                                        "id": 39797043,
                                        "kids": [
                                            39803860
                                        ],
                                        "parent": 39795804,
                                        "text": "Nah, nobody&#x27;s begging for people to A) come use time on their GPUs B) come watch them train their biggest models. Nor does it make sense to spend $X00M training a big model using an experimental technique before you announce it, nor does it make sense to hold back breakthroughs as an academic until someone commercializes it at scale. Category error.",
                                        "time": 1711162545,
                                        "type": "comment",
                                        "comments": [
                                            {
                                                "by": "p1esk",
                                                "id": 39803860,
                                                "parent": 39797043,
                                                "text": "I do ML research at a small industrial lab. I\u2019ll gladly provide some compute to people with a cool idea if that results in my company name listed on a paper in a top conference. Especially if the people are from a top university.",
                                                "time": 1711237472,
                                                "type": "comment"
                                            }
                                        ]
                                    },
                                    {
                                        "by": "sp332",
                                        "id": 39799072,
                                        "kids": [
                                            39801294
                                        ],
                                        "parent": 39795804,
                                        "text": "Well now that they have a promising result, maybe.",
                                        "time": 1711192695,
                                        "type": "comment",
                                        "comments": [
                                            {
                                                "by": "p1esk",
                                                "id": 39801294,
                                                "parent": 39799072,
                                                "text": "They had this promising result before they posted the paper.",
                                                "time": 1711212879,
                                                "type": "comment"
                                            }
                                        ]
                                    }
                                ]
                            }
                        ]
                    },
                    {
                        "by": "Buttons840",
                        "id": 39795951,
                        "kids": [
                            39796150,
                            39796687
                        ],
                        "parent": 39794906,
                        "text": "If a genie appeared and granted one wish, I would wish that we find an extremely powerful machine learning technique that doesn&#x27;t scale. Imagine if an average desktop computer was almost as good as a billion dollar super computer.<p>In other words, I don&#x27;t really care if it scales. I almost hope it doesn&#x27;t.",
                        "time": 1711150424,
                        "type": "comment",
                        "comments": [
                            {
                                "by": "p1esk",
                                "id": 39796150,
                                "parent": 39795951,
                                "text": "Not sure I understand what you mean by \u201cdoesn\u2019t scale\u201d. Are you trying to say you would like to see a tiny model performing as well as a large model?",
                                "time": 1711152576,
                                "type": "comment"
                            },
                            {
                                "by": "MacsHeadroom",
                                "id": 39796687,
                                "kids": [
                                    39804828
                                ],
                                "parent": 39795951,
                                "text": "Even pocket computers (smartphones) are already better than billion dollar supercomputers from decades past.<p>What is your point?",
                                "time": 1711158060,
                                "type": "comment",
                                "comments": [
                                    {
                                        "by": "pyinstallwoes",
                                        "id": 39804828,
                                        "parent": 39796687,
                                        "text": "That no one has an advantage",
                                        "time": 1711249083,
                                        "type": "comment"
                                    }
                                ]
                            }
                        ]
                    },
                    {
                        "by": "jal278",
                        "id": 39795383,
                        "parent": 39794906,
                        "text": "But it may scale -- that&#x27;s science in progress",
                        "time": 1711145361,
                        "type": "comment"
                    }
                ]
            },
            {
                "by": "valine",
                "id": 39795841,
                "kids": [
                    39796285,
                    39796597
                ],
                "parent": 39793250,
                "text": "The architecture changes are very straight forward. Model merging has shown that pre-trained transformer layers are very robust. I\u2019ll bet it\u2019s possible to fine tune a pre-trained model like mistral to use this architecture. That would enable someone to test it with more parameters without training a whole new base model.",
                "time": 1711149418,
                "type": "comment",
                "comments": [
                    {
                        "by": "numeri",
                        "id": 39796285,
                        "kids": [
                            39800018
                        ],
                        "parent": 39795841,
                        "text": "They try this in the appendix without success, unfortunately. It seems having this enabled early on in training is important.",
                        "time": 1711154161,
                        "type": "comment",
                        "comments": [
                            {
                                "by": "matteopagli",
                                "id": 39800018,
                                "kids": [
                                    39807426
                                ],
                                "parent": 39796285,
                                "text": "We&#x27;re still working on training the DWA weights on top of a pretained model. We&#x27;re hopeful that this is feasible. The experiments you&#x27;re mentioning in the appendix are not changing the learning rate scheduler. E.g., when starting to train the DWA weights after 20k iterations, the learning rate is already quite small. To some extent, this might explain the diminishing returns. Maybe this could work with a completely different learning rate scheduler.",
                                "time": 1711202712,
                                "type": "comment",
                                "comments": [
                                    {
                                        "by": "gwern",
                                        "id": 39807426,
                                        "parent": 39800018,
                                        "text": "Yeah, you can&#x27;t change the model much with low LRs. That&#x27;s the point! Same reason you don&#x27;t get continual-learning if you just keep using low LRs: <a href=\"https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2403.08763\" rel=\"nofollow\">https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2403.08763</a> You need to really shake up the model if you want to learn some genuinely better (ie. different) internal representations that exploits the DenseNet (<a href=\"https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;1608.06993)&#x2F;LTG-BERT\" rel=\"nofollow\">https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;1608.06993)&#x2F;LTG-BERT</a> (<a href=\"https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2311.02265\" rel=\"nofollow\">https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2311.02265</a>) arch you&#x27;re using here.",
                                        "time": 1711290331,
                                        "type": "comment"
                                    }
                                ]
                            }
                        ]
                    },
                    {
                        "by": "bilsbie",
                        "id": 39796597,
                        "kids": [
                            39796718
                        ],
                        "parent": 39795841,
                        "text": "I haven\u2019t been able to make sense of model merging. Any insights?<p>Wouldn\u2019t weights between models be completely different? And then there are architecture differences on top of that.",
                        "time": 1711157043,
                        "type": "comment",
                        "comments": [
                            {
                                "by": "valine",
                                "id": 39796718,
                                "kids": [
                                    39796815
                                ],
                                "parent": 39796597,
                                "text": "Model merging is usually done with different fine-tunes of the same model. It doesn\u2019t work if the base models are different.<p>One of the more surprising things is that you can actually repeat layers to improve model performance, ie 1-1-2-2 instead of 1-2. That\u2019s how you get models with higher parameter counts than the original.",
                                "time": 1711158382,
                                "type": "comment",
                                "comments": [
                                    {
                                        "by": "namibj",
                                        "id": 39796815,
                                        "parent": 39796718,
                                        "text": "C.f. also Universal Transformer: the same layer stacked a lot.\nThe sparse version of that is basically MoE with also a stick-breaking mechanism to prevent vanishing gradient while letting the model decide whether to terminate layer-count at a token early (ofc with training rewards to favor less layers, to represent the compute savings).",
                                        "time": 1711159304,
                                        "type": "comment"
                                    }
                                ]
                            }
                        ]
                    }
                ]
            },
            {
                "by": "tbalsam",
                "id": 39795683,
                "parent": 39793250,
                "text": "This is a very interesting idea, with DenseNets there are oftentimes some terrible memory gotchas that have gotten me over the past 7-8 years or so, so a part of me is sorta leaning back waiting for some memory usage shoe to drop not specified in the paper (even with the activation patterns!)<p>However, maybe this is not the case. I have a bit of a history of messing with residuals in neural networks, seeing more work on it is good. Fast training networks of course are a very slightly mild obsession of mine as well, and very useful to the field. Here&#x27;s hoping it pans out as a motif, curious to see where it goes.",
                "time": 1711147925,
                "type": "comment"
            },
            {
                "by": "sp332",
                "id": 39794626,
                "parent": 39793250,
                "text": "Even better is the result on page 7 that perplexity drops faster by wall-clock time. Even if you&#x27;re getting fewer iterations per hour of rented GPU time, you&#x27;re still coming out ahead in model performance.",
                "time": 1711140109,
                "type": "comment"
            },
            {
                "by": "ml_basics",
                "id": 39795118,
                "kids": [
                    39795576
                ],
                "parent": 39793250,
                "text": "Cool paper. Really interesting to see how even quite straightforward architectural modifications haven&#x27;t yet all been exhausted yet, despite all the resources being poured into LLMs",
                "time": 1711143467,
                "type": "comment",
                "comments": [
                    {
                        "by": "samus",
                        "id": 39795576,
                        "kids": [
                            39795661,
                            39796007
                        ],
                        "parent": 39795118,
                        "text": "The problem is that they have to be tested for 7B models at least to show promise for larger models. And that requires significant compute resources.",
                        "time": 1711147033,
                        "type": "comment",
                        "comments": [
                            {
                                "by": "tbalsam",
                                "id": 39795661,
                                "parent": 39795576,
                                "text": "Due to some of my personal experiences over the years w&#x2F; model development, I believe that this is more due to a failure of the current mainline version of Transformers (the ++ version I believe) not scaling properly, vs an indicator of scale.<p>If that is the case, then it may well be possible to fix some of the scaling issues more apparent with smaller transformer models (maybe not, though). This is at least some of the reasoning that I&#x27;ve been applying when developing hlb-gpt, for example. It&#x27;s partially also why I think changing how we use nonlinearities within the network might impact scaling, due to some of the activation spikes used in more linear regions of the network to control network behavior in a way not originally intended.<p>Agreed that it does require a ton of resources though. But I do think that the problem can be solved on a smaller scale. If we don&#x27;t have a cleanly logarithmic curve, then I think that something is dearly wrong with our base architecture. (However, of course, I may entirely be missing something here).",
                                "time": 1711147762,
                                "type": "comment"
                            },
                            {
                                "by": "quotemstr",
                                "id": 39796007,
                                "kids": [
                                    39796242
                                ],
                                "parent": 39795576,
                                "text": "I wonder whether we&#x27;re missing out on techniques that work well on large models but that don&#x27;t show promise on small ones",
                                "time": 1711150959,
                                "type": "comment",
                                "comments": [
                                    {
                                        "by": "hackerlight",
                                        "id": 39796242,
                                        "parent": 39796007,
                                        "text": "More like we&#x27;re missing out on techniques full stop. Proving things at scale is GPU expensive and gatekeeps publication and therefore accessibility.",
                                        "time": 1711153632,
                                        "type": "comment"
                                    }
                                ]
                            }
                        ]
                    }
                ]
            },
            {
                "by": "danieldk",
                "id": 39798616,
                "parent": 39793250,
                "text": "Nice finding and makes a lot of sense! It is somewhat related to classification heads using their own weighted representation of all transformer layer outputs.<p>I only glanced the paper, but they don&#x27;t seem to softmax \u237a_i for normalization?",
                "time": 1711186517,
                "type": "comment"
            },
            {
                "by": "zwaps",
                "id": 39797354,
                "parent": 39793250,
                "text": "1. They compare with an older sort of standard implementation of a transformer Unsure whether the results would be equally significant compared to models with gated units or multiquery etc.<p>2. The difference seems to diminish with scale. Real life transformers obviously are much larger and train on many more tokens.<p>3. A very significant part of training transformer models are the throughoutput and memory optimizations. I wonder how their model would work with such fused kernels or specialized paged KV cache schemes. Or activation checkpointing, if run locally.<p>4. Indeed they claim no memory impact, but their code shows that their experiments are conducted with a special optimized version which requires all activations to reside in a single tensor at all times. Not sure this would work with 3d parallelism on multiple nodes etc.",
                "time": 1711166784,
                "type": "comment"
            },
            {
                "by": "matteopagli",
                "id": 39799970,
                "kids": [
                    39807322
                ],
                "parent": 39793250,
                "text": "I&#x27;m one of the authors, happy to answer questions.",
                "time": 1711202104,
                "type": "comment",
                "comments": [
                    {
                        "by": "EvkoGS",
                        "id": 39807322,
                        "parent": 39799970,
                        "text": "Is it possible to combine your approach with NATTEN? It seems that both approaches are optimizing from different directions and can be combined with significant throughput and small performance improvements?",
                        "time": 1711289278,
                        "type": "comment"
                    }
                ]
            },
            {
                "by": "efrank3",
                "id": 39796345,
                "parent": 39793250,
                "text": "Can&#x27;t believe nobody thought of this yet",
                "time": 1711154973,
                "type": "comment"
            },
            {
                "by": "aoeusnth1",
                "id": 39795483,
                "kids": [
                    39795552,
                    39796040
                ],
                "parent": 39793250,
                "text": "&gt; Impact statement:<p>&gt; This paper presents work whose goal is to advance the field of Machine Learning. There are many potential societal consequences of our work, none which we feel must be specifically highlighted here.<p>I found this particularly charming.",
                "time": 1711146217,
                "type": "comment",
                "comments": [
                    {
                        "by": "polygamous_bat",
                        "id": 39795552,
                        "parent": 39795483,
                        "text": "AFAIK this was the default, copy paste impact statement by ICML template.",
                        "time": 1711146796,
                        "type": "comment"
                    },
                    {
                        "deleted": true,
                        "id": 39796040,
                        "parent": 39795483,
                        "time": 1711151228,
                        "type": "comment"
                    }
                ]
            }
        ]
    },
    {
        "by": "EndXA",
        "descendants": 1,
        "id": 39794118,
        "kids": [
            39795597
        ],
        "score": 24,
        "time": 1711136817,
        "title": "Finding Little Albert (2011)",
        "type": "story",
        "url": "https://www.bps.org.uk/psychologist/looking-back-finding-little-albert",
        "comments": [
            {
                "by": "wolfhumble",
                "id": 39795597,
                "parent": 39794118,
                "text": "In the Wikipedia article about Little Albert, see: <a href=\"https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Little_Albert_experiment\" rel=\"nofollow\">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Little_Albert_experiment</a> \u2013 another boy is mentioned that could fit the characteristics of Little Albert. See the Wikpedia article and the American Psychologist article: <a href=\"https:&#x2F;&#x2F;zenodo.org&#x2F;records&#x2F;1405620\" rel=\"nofollow\">https:&#x2F;&#x2F;zenodo.org&#x2F;records&#x2F;1405620</a>",
                "time": 1711147148,
                "type": "comment"
            }
        ]
    },
    {
        "by": "billybuckwheat",
        "descendants": 57,
        "id": 39782876,
        "kids": [
            39785820,
            39785238,
            39784818,
            39784716,
            39784104,
            39785203,
            39783815,
            39784464,
            39783259,
            39783739,
            39784329,
            39786664,
            39786982,
            39784252,
            39788162,
            39784628,
            39788010,
            39783076,
            39788070,
            39783254,
            39790599,
            39783592,
            39783635,
            39783519,
            39783643,
            39791159,
            39783616,
            39783180
        ],
        "score": 192,
        "time": 1711047381,
        "title": "Jan: An open source alternative to ChatGPT that runs on the desktop",
        "type": "story",
        "url": "https://jan.ai/",
        "comments": [
            {
                "by": "EMM_386",
                "id": 39785820,
                "parent": 39782876,
                "text": "It does make it easier for the end user who doesn&#x27;t want to fiddle around with python dependencies, command lines, building C++ projects, etc.<p>Just install it, point it to a model, and go.  Now you have a local LLM.<p>If you want something more, click the &quot;start server&quot; button and you have a local OpenAI compatible API which you can point more advanced front-ends to.",
                "time": 1711064860,
                "type": "comment"
            },
            {
                "by": "lagrange77",
                "id": 39785238,
                "parent": 39782876,
                "text": "I was wondering if it uses something like vLLM[0] or Llama.cpp[1].<p>Seems to be Llama.cpp via &#x27;Nitro&#x27;, which was discussed here before [2].<p>[0] <a href=\"https:&#x2F;&#x2F;github.com&#x2F;vllm-project&#x2F;vllm\">https:&#x2F;&#x2F;github.com&#x2F;vllm-project&#x2F;vllm</a><p>[1] <a href=\"https:&#x2F;&#x2F;github.com&#x2F;ggerganov&#x2F;llama.cpp\">https:&#x2F;&#x2F;github.com&#x2F;ggerganov&#x2F;llama.cpp</a><p>[2] <a href=\"https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=38887531\">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=38887531</a>",
                "time": 1711060272,
                "type": "comment"
            },
            {
                "by": "LeoPanthera",
                "id": 39784818,
                "parent": 39782876,
                "text": "Unless I just can&#x27;t find it, there seems to be no setting for customizing the prompt format for local models. You can edit the prompt itself, but not the format of the prompt or the subsequent messages. This would make using many models difficult, or give poor results, since they don&#x27;t all use the same format.",
                "time": 1711057794,
                "type": "comment"
            },
            {
                "by": "FuriouslyAdrift",
                "id": 39784716,
                "kids": [
                    39786635,
                    39793057
                ],
                "parent": 39782876,
                "text": "Many LLMs may be run locally with GPT4All...<p><a href=\"https:&#x2F;&#x2F;gpt4all.io&#x2F;\" rel=\"nofollow\">https:&#x2F;&#x2F;gpt4all.io&#x2F;</a>",
                "time": 1711057093,
                "type": "comment",
                "comments": [
                    {
                        "by": "nickpsecurity",
                        "id": 39786635,
                        "parent": 39784716,
                        "text": "And MLC puts them on your phone, too.<p><a href=\"https:&#x2F;&#x2F;llm.mlc.ai&#x2F;\" rel=\"nofollow\">https:&#x2F;&#x2F;llm.mlc.ai&#x2F;</a>",
                        "time": 1711071971,
                        "type": "comment"
                    },
                    {
                        "by": "slowmovintarget",
                        "id": 39793057,
                        "kids": [
                            39794911
                        ],
                        "parent": 39784716,
                        "text": "GPT4All makes it annoyingly difficult to run any other than their &quot;approved&quot; models. I&#x27;d like to kick the tires on a whole host of random GGUF quantizations on Hugging Face, please.<p>I&#x27;ve poked around the doc, not sure if Jan can do that better.<p>In the mean time, I use text-gen-ui (Oobabooga) as a back-end and have it run with `--api` to use the front end of my choice.",
                        "time": 1711129670,
                        "type": "comment",
                        "comments": [
                            {
                                "by": "_puk",
                                "id": 39794911,
                                "parent": 39793057,
                                "text": "Not at my computer right now to double check.. but doesn&#x27;t GPT4All&#x27;s &quot;Browse&quot; button in the model list let you pick a locally downloaded model?",
                                "time": 1711141917,
                                "type": "comment"
                            }
                        ]
                    }
                ]
            },
            {
                "by": "christkv",
                "id": 39784104,
                "parent": 39782876,
                "text": "I got say I\u2019ve been using LLM studio as it exposes the models in the ui as well as through a local open ai compatible server so I can test different models against my workflows locally.",
                "time": 1711053587,
                "type": "comment"
            },
            {
                "by": "kkfx",
                "id": 39785203,
                "kids": [
                    39793736,
                    39786724
                ],
                "parent": 39782876,
                "text": "I try some LLM on my notes and well... They was unable to give me insights that are hard to spot, like follow the flaw of notes identifying patterns, find similar notes from the past and so on. In ALL cases classic tags&#x2F;riprgrep full-text search was far quicker and equally or more effective.<p>Long story short: LLMs might be useful on hyper big mass of information, like a new kind of search engine that try do achieve a semantic goal mimicking it. But not more than that IMVHO. Marginally LLMs might help computer-illiterate to manage their files, seen <a href=\"https:&#x2F;&#x2F;www.theverge.com&#x2F;22684730&#x2F;students-file-folder-directory-structure-education-gen-z\" rel=\"nofollow\">https:&#x2F;&#x2F;www.theverge.com&#x2F;22684730&#x2F;students-file-folder-direc...</a> but I doubt they can go any further for the next 5+ years at least.",
                "time": 1711060027,
                "type": "comment",
                "comments": [
                    {
                        "by": "lxgr",
                        "id": 39793736,
                        "kids": [
                            39798051
                        ],
                        "parent": 39785203,
                        "text": "They&#x27;ve been very useful in quickly answering common questions using a too-large-to-manually-scan knowledge base in my experience at my job, and I don&#x27;t consider myself or my colleagues &quot;computer-illiterate&quot;.",
                        "time": 1711134275,
                        "type": "comment",
                        "comments": [
                            {
                                "by": "kkfx",
                                "id": 39798051,
                                "parent": 39793736,
                                "text": "That&#x27;s follow the &quot;might be useful as a new kind of search engine&quot;, though it might be a sign of an a bit messy KB. The issue of potential hallucinations however is still there so even such usage, a different search engine, demand extra attention.<p>It&#x27;s not a free critic to those who have designed, implemented and trained LLMs, it&#x27;s just the observation that practical usage is far less than the advertised one and it&#x27;s still not much good. It&#x27;s still an advancement, a good thing to have, the start of a revolution, but still far from being what many dreams.",
                                "time": 1711177517,
                                "type": "comment"
                            }
                        ]
                    },
                    {
                        "by": "theGnuMe",
                        "id": 39786724,
                        "parent": 39785203,
                        "text": "LLMs might help my disorganized approach to files...",
                        "time": 1711072933,
                        "type": "comment"
                    }
                ]
            },
            {
                "by": "pryelluw",
                "id": 39783815,
                "kids": [
                    39783993
                ],
                "parent": 39782876,
                "text": "Would be nice if they listed system requirements. Their docs just say coming soon \u2026",
                "time": 1711052097,
                "type": "comment",
                "comments": [
                    {
                        "by": "knodi123",
                        "id": 39783993,
                        "kids": [
                            39784070
                        ],
                        "parent": 39783815,
                        "text": "most of their docs say coming soon.      and their whole wiki.<p>honestly feels like site this was launched a couple of days too soon.",
                        "time": 1711053089,
                        "type": "comment",
                        "comments": [
                            {
                                "by": "warkdarrior",
                                "id": 39784070,
                                "parent": 39783993,
                                "text": "Their LLM is still generating copy for the website..",
                                "time": 1711053427,
                                "type": "comment"
                            }
                        ]
                    }
                ]
            },
            {
                "by": "LeoPanthera",
                "id": 39784464,
                "kids": [
                    39793851
                ],
                "parent": 39782876,
                "text": "Is this a fork of &quot;LM Studio&quot;? The UI is suspiciously similar, even down to the layout of the labels.",
                "time": 1711055530,
                "type": "comment",
                "comments": [
                    {
                        "by": "euclaise",
                        "id": 39793851,
                        "parent": 39784464,
                        "text": "LM studio is closed source, so no",
                        "time": 1711135087,
                        "type": "comment"
                    }
                ]
            },
            {
                "by": "throwitaway1123",
                "id": 39783259,
                "parent": 39782876,
                "text": "This looks interesting. I would love a comparison between this product and LM Studio.",
                "time": 1711049287,
                "type": "comment"
            },
            {
                "by": "moose44",
                "id": 39783739,
                "parent": 39782876,
                "text": "Running LLMs locally always feels so awesome!",
                "time": 1711051554,
                "type": "comment"
            },
            {
                "by": "pimlottc",
                "id": 39784329,
                "kids": [
                    39784342
                ],
                "parent": 39782876,
                "text": "I&#x27;m going to assume this is not an Australian company...<p><a href=\"https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=2akt3P8ltLM\" rel=\"nofollow\">https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=2akt3P8ltLM</a>",
                "time": 1711054705,
                "type": "comment",
                "comments": [
                    {
                        "by": "badRNG",
                        "id": 39784342,
                        "parent": 39784329,
                        "text": "Looks like they are based out of Singapore",
                        "time": 1711054795,
                        "type": "comment"
                    }
                ]
            },
            {
                "by": "Brajeshwar",
                "id": 39786664,
                "kids": [
                    39801072,
                    39786879
                ],
                "parent": 39782876,
                "text": "This looks awesome. Trying it out. Suggestion, can we please change the &quot;Download Jan for PC&quot; to perhaps just &quot;Download&quot; or &quot;Download for Desktop&quot; or whichever that makes sense but not &quot;PC&quot;. I almost move away thinking this is Windows, thus not for us.<p>I recently stumbled on <a href=\"https:&#x2F;&#x2F;mindmac.app\" rel=\"nofollow\">https:&#x2F;&#x2F;mindmac.app</a> which is a non-subscription app that uses multiple AI tools (not just OpneAI). Looks Promising.<p>Like the others in the comments, I&#x27;ve tried <a href=\"https:&#x2F;&#x2F;www.typingmind.com\" rel=\"nofollow\">https:&#x2F;&#x2F;www.typingmind.com</a> (via SetApp).<p>Sindre Sorhus have a pretty stable Native App <a href=\"https:&#x2F;&#x2F;sindresorhus.gumroad.com&#x2F;l&#x2F;quickgpt\" rel=\"nofollow\">https:&#x2F;&#x2F;sindresorhus.gumroad.com&#x2F;l&#x2F;quickgpt</a><p>These are some of the really good ones. I&#x27;m tending more towards trying out the likes of MindMac just for the fact that I can plug and switch between multiple tools.",
                "time": 1711072212,
                "type": "comment",
                "comments": [
                    {
                        "by": "Terretta",
                        "id": 39801072,
                        "parent": 39786664,
                        "text": "What&#x27;s the value proposition for TypingMind as a commercial product ($3500 to run locally for 5 seats)?<p>But let me contrast that last &quot;native app&quot; with Machato and MacGPT:<p>== Machato ==<p>Machato is feature-full for system prompts and transcripts, connecting to to OpenAI, Claude, and any &quot;server&quot; endpoint that&#x27;s OpenAPI API compatible, and surfacing parameter and token settings per conversation right on your text entry bar.  You can also point a given conversation to a local ollama endpoint such as Mixtral 8x7B and it works as well.<p>The best feature is the selective forking and suppression of exchanges within conversation threads.<p><a href=\"https:&#x2F;&#x2F;untimelyunicorn.gumroad.com&#x2F;l&#x2F;machato\" rel=\"nofollow\">https:&#x2F;&#x2F;untimelyunicorn.gumroad.com&#x2F;l&#x2F;machato</a><p>== MacGPT ==<p>MacGPT is highly integrated throughout MacOS, and works with either OpenAI key or a ChatGTP Pro login.  It&#x27;s quite similar to BoltAI mentioned elsewhere in this thread, but in addition to the OpenAI key based mode, also works with a ChatGPT Pro subscription in a ChatGPT web UI pop-up.<p><a href=\"https:&#x2F;&#x2F;www.macgpt.com&#x2F;\" rel=\"nofollow\">https:&#x2F;&#x2F;www.macgpt.com&#x2F;</a>",
                        "time": 1711211337,
                        "type": "comment"
                    },
                    {
                        "by": "longnguyen",
                        "id": 39786879,
                        "kids": [
                            39811201,
                            39801196,
                            39787261
                        ],
                        "parent": 39786664,
                        "text": "Shameless plug: I built a native client called BoltAI[0]. Unlike other clients, I prioritize UI, UX and performance.<p>Give it a try if UI &amp; UX is important to you.<p>[0]: <a href=\"https:&#x2F;&#x2F;boltai.com\" rel=\"nofollow\">https:&#x2F;&#x2F;boltai.com</a>",
                        "time": 1711074465,
                        "type": "comment",
                        "comments": [
                            {
                                "by": "geggo98",
                                "id": 39811201,
                                "kids": [
                                    39812755
                                ],
                                "parent": 39786879,
                                "text": "From the screenshots it looks like there is an activation limit, with a maximum of four devices. Reading the license, I could not confirm this. Is there a limit, and if, what is the maximum?",
                                "time": 1711320199,
                                "type": "comment",
                                "comments": [
                                    {
                                        "by": "longnguyen",
                                        "id": 39812755,
                                        "parent": 39811201,
                                        "text": "Sorry for the confusion. I need to improve my pricing page.<p>The license is per user, and can be used on maximum 3 devices. I figured this is enough for most users. If you have more devices or need a custom license, please send me an email (my email is in bio)",
                                        "time": 1711339046,
                                        "type": "comment"
                                    }
                                ]
                            },
                            {
                                "by": "Terretta",
                                "id": 39801196,
                                "kids": [
                                    39801281
                                ],
                                "parent": 39786879,
                                "text": "This looks great relative to others (very similar to MacGPT), and I particularly like how advanced settings are available but tucked away behind discoverable affordances.<p>It&#x27;s interesting that you have team pricing.<p>Can the Team leverage shared system prompts and&#x2F;or assistants from a OneDrive-for-Business (SharePoint) folder or GitHub repo?<p>If not, what makes it &quot;Team&quot; instead of just individual?",
                                "time": 1711212097,
                                "type": "comment",
                                "comments": [
                                    {
                                        "by": "longnguyen",
                                        "id": 39801281,
                                        "parent": 39801196,
                                        "text": "Hi. Actually I don\u2019t have a pricing plan for teams yet. It\u2019s still under (heavy) development. I changed my headline to reflect the direction I want to take this year (focus on teams)<p>And yes, some of my customers wanted team and collaborative features like shared prompt, internal plugins and integrations, RAG on internal documents\u2026<p>But I haven\u2019t launched these team features yet.<p>Are you interested in this? Would love to talk to you if it\u2019s something you\u2019re looking for.",
                                        "time": 1711212798,
                                        "type": "comment"
                                    }
                                ]
                            },
                            {
                                "by": "Brajeshwar",
                                "id": 39787261,
                                "parent": 39786879,
                                "text": "Sure. Why Not. Trying it out.<p>My use case is especially for my daughter so I can just plug in my OpenAI API and let her ask away.",
                                "time": 1711078898,
                                "type": "comment"
                            }
                        ]
                    }
                ]
            },
            {
                "by": "rnd0",
                "id": 39786982,
                "kids": [
                    39788381
                ],
                "parent": 39782876,
                "text": "How is this better than gpt4all?",
                "time": 1711075668,
                "type": "comment",
                "comments": [
                    {
                        "by": "Grimblewald",
                        "id": 39788381,
                        "parent": 39786982,
                        "text": "From what I see, it has the benefit of offering less functionality, more corpojargon and a more &#x27;intuitive&#x27; ui.",
                        "time": 1711094626,
                        "type": "comment"
                    }
                ]
            },
            {
                "by": "TheRealPomax",
                "id": 39784252,
                "kids": [
                    39791232,
                    39784467
                ],
                "parent": 39782876,
                "text": "Still hoping we&#x27;ll eventually stop using Fibonacci to show off recursion, because that&#x27;s one of those examples where the <i>maths</i> might be expressed as recursive relation, but the <i>implementation</i> should never be =)<p>Good AI would go &quot;you don&#x27;t want that, that&#x27;s horribly inefficient. Here&#x27;s an actually performant implementation based on the closed-form expression&quot;.",
                "time": 1711054331,
                "type": "comment",
                "comments": [
                    {
                        "by": "Wowfunhappy",
                        "id": 39791232,
                        "parent": 39784252,
                        "text": "What is your preferred example for teaching a beginner to use recursion?",
                        "time": 1711118631,
                        "type": "comment"
                    },
                    {
                        "by": "zopa",
                        "id": 39784467,
                        "parent": 39784252,
                        "text": "Nah, good AI would run in the compiler and optimize the recursion into something fast.",
                        "time": 1711055547,
                        "type": "comment"
                    }
                ]
            },
            {
                "by": "lazyeye",
                "id": 39788162,
                "parent": 39782876,
                "text": "The default model (Mistral Instruct 7BQ4) is woke.\nI asked it the following:-<p>Write a short poem in admiration of black people<p>Write a short poem in admiration of brown people<p>Write a short poem in admiration of asian people<p>Write a short poem in admiration of white people<p>It immediately replied with a poem for all except white people where it&#x27;s response was:-<p>&quot;I&#x27;d be happy to write a poem in admiration of all people, including those who identify as White.&quot;\nLol",
                "time": 1711092401,
                "type": "comment"
            },
            {
                "by": "onion2k",
                "id": 39784628,
                "parent": 39782876,
                "text": "I use Jan to run Mistral locally. It works well for what I need (which amounts to playing with models).",
                "time": 1711056539,
                "type": "comment"
            },
            {
                "by": "rc202402",
                "id": 39788010,
                "parent": 39782876,
                "text": "Been using this with a few models like gemma etc for a week now.<p>HN got any good LLM suggestions to run with this that are equivalent or better than GPT-3.5 &#x2F; claude?<p>I&#x27;m looking to use its api with LLama Index",
                "time": 1711090366,
                "type": "comment"
            },
            {
                "by": "ShamelessC",
                "id": 39783076,
                "kids": [
                    39783135
                ],
                "parent": 39782876,
                "text": "Quite a lot of polish and bragging about stars and tweets for an open source project. Is there hidden monetization of some sort? Perhaps VC funding?",
                "time": 1711048390,
                "type": "comment",
                "comments": [
                    {
                        "by": "anewhnaccount2",
                        "id": 39783135,
                        "kids": [
                            39783257
                        ],
                        "parent": 39783076,
                        "text": "According to their page <a href=\"https:&#x2F;&#x2F;jan.ai&#x2F;team&#x2F;\" rel=\"nofollow\">https:&#x2F;&#x2F;jan.ai&#x2F;team&#x2F;</a> they aim to bootstrap.",
                        "time": 1711048692,
                        "type": "comment",
                        "comments": [
                            {
                                "by": "ShamelessC",
                                "id": 39783257,
                                "parent": 39783135,
                                "text": "Awesome thanks.",
                                "time": 1711049267,
                                "type": "comment"
                            }
                        ]
                    }
                ]
            },
            {
                "deleted": true,
                "id": 39788070,
                "parent": 39782876,
                "time": 1711091205,
                "type": "comment"
            },
            {
                "by": "thedangler",
                "id": 39783254,
                "kids": [
                    39785271,
                    39786719
                ],
                "parent": 39782876,
                "text": "I don&#x27;t see anything about it reading local documents like exel, pdfs, or docs.\nAnyone see how this is accomplished?",
                "time": 1711049253,
                "type": "comment",
                "comments": [
                    {
                        "by": "0134340",
                        "id": 39785271,
                        "parent": 39783254,
                        "text": "Is it implied anywhere? That&#x27;s a feature I&#x27;d love and also why I haven&#x27;t bothered delving into LLMs very much; I didn&#x27;t know there were any that could locally index your library and train on that data. I&#x27;d love to ask it a question and have it reference my local ebook library.",
                        "time": 1711060492,
                        "type": "comment"
                    },
                    {
                        "by": "theGnuMe",
                        "id": 39786719,
                        "parent": 39783254,
                        "text": "It probably doesn&#x27;t.  The only one that read PDFs for me was the Nvidia ChatRTX. \nIt would be easy to add modules from pip that do this but you&#x27;d have to code up the input pipeline.  It&#x27;s not terribly difficult but it is definitely not point and click.",
                        "time": 1711072843,
                        "type": "comment"
                    }
                ]
            },
            {
                "by": "antifa",
                "id": 39790599,
                "parent": 39782876,
                "text": "Did this have any way to point at a folder of markdown files and RAG at it?",
                "time": 1711114548,
                "type": "comment"
            },
            {
                "by": "ThrowawayTestr",
                "id": 39783592,
                "kids": [
                    39784188,
                    39784275
                ],
                "parent": 39782876,
                "text": "Where does the model come from?",
                "time": 1711050904,
                "type": "comment",
                "comments": [
                    {
                        "by": "LordDragonfang",
                        "id": 39784188,
                        "parent": 39783592,
                        "text": "Afaict, it doesn&#x27;t have any inbuilt model, you just download one yourself or hook up to someone&#x27;s API.",
                        "time": 1711054027,
                        "type": "comment"
                    },
                    {
                        "by": "dsp_person",
                        "id": 39784275,
                        "parent": 39783592,
                        "text": "Scroll down on the main page:<p>01 Run local AI or connect to remote APIs<p>02 Browse and download models",
                        "time": 1711054478,
                        "type": "comment"
                    }
                ]
            },
            {
                "by": "thesurlydev",
                "id": 39783635,
                "kids": [
                    39784309,
                    39786571
                ],
                "parent": 39782876,
                "text": "These kinds of apps are becoming dime a dozen. It would be nice to know how this one differentiates itself. Not obvious from the website.",
                "time": 1711051114,
                "type": "comment",
                "comments": [
                    {
                        "by": "viraptor",
                        "id": 39784309,
                        "kids": [
                            39784469
                        ],
                        "parent": 39783635,
                        "text": "It seems like that until you actually try to use them. Not many are actually polished, support formatting, history, and multiple endpoints. There&#x27;s lots of trivial apps abandoned after a few days, but what are the actually functional, good quality alternatives to this one? (That don&#x27;t pass your query&#x2F;answer through a third-party for data collection)",
                        "time": 1711054595,
                        "type": "comment",
                        "comments": [
                            {
                                "by": "extr",
                                "id": 39784469,
                                "kids": [
                                    39784741,
                                    39784530
                                ],
                                "parent": 39784309,
                                "text": "I use <a href=\"https:&#x2F;&#x2F;www.typingmind.com&#x2F;\" rel=\"nofollow\">https:&#x2F;&#x2F;www.typingmind.com&#x2F;</a>. It is paid, but I&#x27;ve found it to be a reliable front end to OpenAI&#x2F;Claude&#x2F;Google, supporting everything you mention. I haven&#x27;t done any hyper detailed security audit but after watching network requests I&#x27;m pretty confident it&#x27;s not sending my chats anywhere except to the relevant provider endpoints.<p>Considering how much I use it, I&#x27;ve found it to be well worth the cost. The creator is pretty on top of model&#x2F;API changes.",
                                "time": 1711055548,
                                "type": "comment",
                                "comments": [
                                    {
                                        "by": "viraptor",
                                        "id": 39784741,
                                        "kids": [
                                            39786834
                                        ],
                                        "parent": 39784469,
                                        "text": "It&#x27;s not a standalone app though. There&#x27;s lots of web interfaces, but that&#x27;s not the same. (I mean, it&#x27;s a cool thing, but not what jan.ai is)",
                                        "time": 1711057280,
                                        "type": "comment",
                                        "comments": [
                                            {
                                                "by": "extr",
                                                "id": 39786834,
                                                "parent": 39784741,
                                                "text": "There is a desktop app available (I mean it\u2019s basically a wrapper around the web UI, but still).",
                                                "time": 1711074118,
                                                "type": "comment"
                                            }
                                        ]
                                    },
                                    {
                                        "by": "karmajunkie",
                                        "id": 39784530,
                                        "parent": 39784469,
                                        "text": "i\u2019ll second that recommendation\u2026 i use it through the SetApp store and i\u2019ve been very pleasantly surprised by its documentation and ability to work with most services.",
                                        "time": 1711055894,
                                        "type": "comment"
                                    }
                                ]
                            }
                        ]
                    },
                    {
                        "deleted": true,
                        "id": 39786571,
                        "parent": 39783635,
                        "time": 1711071399,
                        "type": "comment"
                    }
                ]
            },
            {
                "by": "okasaki",
                "dead": true,
                "id": 39783519,
                "kids": [
                    39783567,
                    39783682
                ],
                "parent": 39782876,
                "text": "[flagged]",
                "time": 1711050540,
                "type": "comment",
                "comments": [
                    {
                        "by": "lmeyerov",
                        "id": 39783567,
                        "parent": 39783519,
                        "text": "For AI projects, afaict, 12k stars or forks is more akin to downloads than contributors &amp; downstreams. GitHub is the app distribution, not just source distribution. I&#x27;ve been curious how to model this better..",
                        "time": 1711050770,
                        "type": "comment"
                    },
                    {
                        "deleted": true,
                        "id": 39783682,
                        "parent": 39783519,
                        "time": 1711051301,
                        "type": "comment"
                    }
                ]
            },
            {
                "by": "outcoldman",
                "dead": true,
                "id": 39783643,
                "kids": [
                    39783675
                ],
                "parent": 39782876,
                "text": "[flagged]",
                "time": 1711051159,
                "type": "comment",
                "comments": [
                    {
                        "deleted": true,
                        "id": 39783675,
                        "parent": 39783643,
                        "time": 1711051275,
                        "type": "comment"
                    }
                ]
            },
            {
                "by": "redder23",
                "dead": true,
                "id": 39791159,
                "kids": [
                    39801248,
                    39791506
                ],
                "parent": 39782876,
                "text": "[flagged]",
                "time": 1711118181,
                "type": "comment",
                "comments": [
                    {
                        "by": "Terretta",
                        "id": 39801248,
                        "parent": 39791159,
                        "text": "&gt; <i>If I had a key for some OpenAI paid shit I can go to their website and do not need an app for that. I really do not get it.</i><p>Perhaps you don&#x27;t have some OpenAI paid shit?<p>While you can clunk around in a sort of OpenAI playground in a web tab, it is designed for dev experimentation (a &quot;fiddler&quot; type of UI), and not a good experience for much beyond testing.<p>&gt; <i>excuse me you fuck did you not just tell me you are &quot;local first&quot; ... I try out the model, and it turns out it runs on my CPU with heavy RAM usage...</i><p>I&#x27;m not sure it makes sense to have both of these objections at once.<p>&gt; <i>I never ran a model</i><p>Oh.",
                        "time": 1711212501,
                        "type": "comment"
                    },
                    {
                        "by": "redder23",
                        "id": 39791506,
                        "parent": 39791159,
                        "text": "OK, there is a switch under &quot;Advanced Settings&quot; to enable GPU. Why the fuck is this no-brainer option off by default and &quot;advanced&quot;? Suddenly my 7B Model is shown as inactive and &quot;start&quot; does nothing, gives no error message either ... this is such an unusable alpha version.",
                        "time": 1711120372,
                        "type": "comment"
                    }
                ]
            },
            {
                "by": "CyberEldrich",
                "dead": true,
                "id": 39783616,
                "kids": [
                    39783664
                ],
                "parent": 39782876,
                "text": "[flagged]",
                "time": 1711051029,
                "type": "comment",
                "comments": [
                    {
                        "deleted": true,
                        "id": 39783664,
                        "parent": 39783616,
                        "time": 1711051250,
                        "type": "comment"
                    }
                ]
            },
            {
                "by": "afian",
                "id": 39783180,
                "parent": 39782876,
                "text": "Fantastic product and excellent team!",
                "time": 1711048894,
                "type": "comment"
            }
        ]
    },
    {
        "by": "PaulHoule",
        "descendants": 0,
        "id": 39800181,
        "score": 3,
        "time": 1711204139,
        "title": "Simulating Weighted Automata over Sequences and Trees with Transformers",
        "type": "story",
        "url": "https://arxiv.org/abs/2403.09728"
    },
    {
        "by": "giuliomagnifico",
        "descendants": 1,
        "id": 39818564,
        "kids": [
            39818848,
            39818827
        ],
        "score": 8,
        "time": 1711385499,
        "title": "ChatGPT linked to declining academic performance and memory loss in new study",
        "type": "story",
        "url": "https://www.psypost.org/chatgpt-linked-to-declining-academic-performance-and-memory-loss-in-new-study/",
        "comments": [
            {
                "by": "throwaway888abc",
                "id": 39818848,
                "parent": 39818564,
                "text": "Link to full paper:<p><a href=\"https:&#x2F;&#x2F;educationaltechnologyjournal.springeropen.com&#x2F;articles&#x2F;10.1186&#x2F;s41239-024-00444-7\" rel=\"nofollow\">https:&#x2F;&#x2F;educationaltechnologyjournal.springeropen.com&#x2F;articl...</a>",
                "time": 1711386850,
                "type": "comment"
            },
            {
                "deleted": true,
                "id": 39818827,
                "parent": 39818564,
                "time": 1711386776,
                "type": "comment"
            }
        ]
    },
    {
        "by": "isaacfrond",
        "descendants": 6,
        "id": 39813798,
        "kids": [
            39815215,
            39815153,
            39815451
        ],
        "score": 17,
        "time": 1711354583,
        "title": "Microsoft reuses its OpenAI playbook with Inflection takeover",
        "type": "story",
        "url": "https://www.theverge.com/2024/3/22/24109260/microsoft-openai-playbook-inflection-ai",
        "comments": [
            {
                "by": "helsinkiandrew",
                "id": 39815215,
                "kids": [
                    39815435,
                    39815341
                ],
                "parent": 39813798,
                "text": "This and the OpenAI relationship seems the equivalent of using Credit Default and Total Return Swaps in finance to &#x27;hide&#x27; effective ownership of the underlying asset.  It&#x27;s hard to see how the regulators won&#x27;t investigate.",
                "time": 1711368092,
                "type": "comment",
                "comments": [
                    {
                        "by": "proaralyst",
                        "id": 39815435,
                        "kids": [
                            39816286
                        ],
                        "parent": 39815215,
                        "text": "CDS don&#x27;t hide ownership, they&#x27;re insurance against a bond defaulting. You can use them to short a company&#x27;s bonds too, which is otherwise extremely difficult as bonds aren&#x27;t lent like equities.<p>TRS also aren&#x27;t really used to hide ownership but to get economic exposure when you can&#x27;t actually own things for whatever reason. The Archegos collapse was mostly a risk management fault at Credit Suisse unrelated to the means they got that exposure through. Archegos&#x27;s other prime brokers mostly liquidated their positions with no losses. TRS are transparent to your broker and to regulators",
                        "time": 1711369513,
                        "type": "comment",
                        "comments": [
                            {
                                "by": "helsinkiandrew",
                                "id": 39816286,
                                "kids": [
                                    39817370
                                ],
                                "parent": 39815435,
                                "text": "&gt; TRS also aren&#x27;t really used to hide ownership but to get economic exposure when you can&#x27;t actually own things for whatever reason<p>In the Archegos case the &quot;whatever reason&quot; was at least partially (as well as getting extra leverage) so that ownership didn&#x27;t need to be reported to the SEC - allowing them to &#x27;own&#x27; 50%+ of the shares of several companies and manipulate the price without the market knowing.<p>Item 30 and 58 of the SEC complaint:\n<a href=\"https:&#x2F;&#x2F;www.sec.gov&#x2F;files&#x2F;litigation&#x2F;complaints&#x2F;2022&#x2F;comp-pr2022-70.pdf\" rel=\"nofollow\">https:&#x2F;&#x2F;www.sec.gov&#x2F;files&#x2F;litigation&#x2F;complaints&#x2F;2022&#x2F;comp-pr...</a>",
                                "time": 1711374646,
                                "type": "comment",
                                "comments": [
                                    {
                                        "by": "proaralyst",
                                        "id": 39817370,
                                        "parent": 39816286,
                                        "text": "I agree they shifted to avoid the reporting requirement but I don&#x27;t believe they did that cynically to manipulate prices, mainly because it&#x27;s unclear to me that anyone has suggested a possible exit from their positions that made them any money. Archegos is a family office, so it&#x27;s not fees. It&#x27;s not generally possible to make a profit pushing the price up by buying as the price will collapse faster than you pushed it up. (Absent external demand as in a pump and dump.)<p>I suspect the intent behind the position disclosure is so <i>control</i> is disclosed, not economic exposure. The design of the regulatory system in the US is that you&#x27;re either regulated and thus have a lot of responsibility and reporting requirements, but you get better access to the market (Archegos&#x27;s brokers); or you&#x27;re &#x27;unregulated&#x27; and have less (but access the market through a regulated company).<p>Also you don&#x27;t usually get different margin treatment through TRS than you would through normal ownership. If you do, your prime broker is doing something stupid. Your TRS is a contract with them, they tend to just go buy the shares to hedge so it&#x27;s usually exactly the same as buying your long through them (except you can&#x27;t vote your shares, you don&#x27;t get dividends and you can&#x27;t lend your shares).",
                                        "time": 1711379771,
                                        "type": "comment"
                                    }
                                ]
                            }
                        ]
                    },
                    {
                        "by": "philipov",
                        "id": 39815341,
                        "parent": 39815215,
                        "text": "They&#x27;re already investigating the OpenAI affair. The question is whether they&#x27;ll be able to <i>do</i> anything about it.",
                        "time": 1711368941,
                        "type": "comment"
                    }
                ]
            },
            {
                "by": "helsinkiandrew",
                "id": 39815153,
                "parent": 39813798,
                "text": "<a href=\"https:&#x2F;&#x2F;archive.ph&#x2F;AsGYa\" rel=\"nofollow\">https:&#x2F;&#x2F;archive.ph&#x2F;AsGYa</a>",
                "time": 1711367697,
                "type": "comment"
            },
            {
                "deleted": true,
                "id": 39815451,
                "parent": 39813798,
                "time": 1711369614,
                "type": "comment"
            }
        ]
    },
    {
        "by": "geox",
        "descendants": 24,
        "id": 39809861,
        "kids": [
            39810733,
            39810888,
            39812744,
            39810769,
            39810887
        ],
        "score": 30,
        "time": 1711309943,
        "title": "Gemini on the iPhone would be AI's mainstream moment",
        "type": "story",
        "url": "https://www.cnet.com/tech/mobile/google-gemini-on-the-iphone-would-be-ais-mainstream-moment/",
        "comments": [
            {
                "by": "bevekspldnw",
                "id": 39810733,
                "kids": [
                    39810751
                ],
                "parent": 39809861,
                "text": "Given this is a CNET link it\u2019s exactly what I would expect an LLM to say about itself.",
                "time": 1711316141,
                "type": "comment",
                "comments": [
                    {
                        "by": "voisin",
                        "id": 39810751,
                        "kids": [
                            39810881
                        ],
                        "parent": 39810733,
                        "text": "A lot of our media has been replaced by two LLMs in a trench coat.",
                        "time": 1711316358,
                        "type": "comment",
                        "comments": [
                            {
                                "by": "outofpaper",
                                "id": 39810881,
                                "kids": [
                                    39811367
                                ],
                                "parent": 39810751,
                                "text": "I&#x27;m pretty sure the media is the trench coat and always has been.",
                                "time": 1711317513,
                                "type": "comment",
                                "comments": [
                                    {
                                        "by": "__loam",
                                        "id": 39811367,
                                        "kids": [
                                            39811876
                                        ],
                                        "parent": 39810881,
                                        "text": "I&#x27;m kind of disgusted by the contempt people in tech have for journalists, when the tech people are the ones who authored the current media ecosystem.",
                                        "time": 1711321742,
                                        "type": "comment",
                                        "comments": [
                                            {
                                                "by": "cassianoleal",
                                                "id": 39811876,
                                                "kids": [
                                                    39812087
                                                ],
                                                "parent": 39811367,
                                                "text": "&quot;people in tech&quot; and &quot;the tech people&quot; are very unfortunate generalisations.",
                                                "time": 1711327318,
                                                "type": "comment",
                                                "comments": [
                                                    {
                                                        "by": "__loam",
                                                        "id": 39812087,
                                                        "kids": [
                                                            39817599
                                                        ],
                                                        "parent": 39811876,
                                                        "text": "Almost like we shouldn&#x27;t be generalizing an entire professional sector with statements like &quot;I hate journalists&quot;, huh?<p>The blame for the decline in journalism lies squarely at the feet of the architects of the ad based internet economy.",
                                                        "time": 1711329644,
                                                        "type": "comment",
                                                        "comments": [
                                                            {
                                                                "by": "bevekspldnw",
                                                                "id": 39817599,
                                                                "kids": [
                                                                    39819779
                                                                ],
                                                                "parent": 39812087,
                                                                "text": "I agree, but that doesn\u2019t mean CNET is a reliable news source.",
                                                                "time": 1711380732,
                                                                "type": "comment",
                                                                "comments": [
                                                                    {
                                                                        "by": "__loam",
                                                                        "id": 39819779,
                                                                        "parent": 39817599,
                                                                        "text": "I agree that CNET sucks, but it&#x27;s very emblematic of the affiliate marketing bullshit that has infested the internet for a while now.",
                                                                        "time": 1711391815,
                                                                        "type": "comment"
                                                                    }
                                                                ]
                                                            }
                                                        ]
                                                    }
                                                ]
                                            }
                                        ]
                                    }
                                ]
                            }
                        ]
                    }
                ]
            },
            {
                "by": "_giorgio_",
                "id": 39810888,
                "kids": [
                    39812189,
                    39812433,
                    39811211
                ],
                "parent": 39809861,
                "text": "I have chatGPT on my phone and I barely use it.<p>I use it a lot on the desktop (paid account).<p>I&#x27;ve used Gemini or Bard probably a couple of times.<p>I don&#x27;t see a great mainstream moment.",
                "time": 1711317605,
                "type": "comment",
                "comments": [
                    {
                        "by": "LeafItAlone",
                        "id": 39812189,
                        "parent": 39810888,
                        "text": "I don\u2019t do much on my phone. I avoid downloading apps in general.<p>But I use ChatGPT on it multiple times a day.",
                        "time": 1711330745,
                        "type": "comment"
                    },
                    {
                        "by": "ametrau",
                        "id": 39812433,
                        "parent": 39810888,
                        "text": "That\u2019s us though. The mainstream prefers the phone for everything (as crazy as that seems).",
                        "time": 1711334537,
                        "type": "comment"
                    },
                    {
                        "by": "YetAnotherNick",
                        "id": 39811211,
                        "parent": 39810888,
                        "text": "If they could bring agentic interaction to phone, I think it will fundamentally change the way we interact. Based on my experiments with GPT-4V it&#x27;s close to being there but AI still hasn&#x27;t reached that point. And given they are using tiny model in comparison, it would be hard to do that.",
                        "time": 1711320337,
                        "type": "comment"
                    }
                ]
            },
            {
                "by": "daft_pink",
                "id": 39812744,
                "kids": [
                    39812829
                ],
                "parent": 39809861,
                "text": "I think it\u2019s a mistake because the whole point of using Apple is not to use Google",
                "time": 1711338899,
                "type": "comment",
                "comments": [
                    {
                        "by": "akmittal",
                        "id": 39812829,
                        "parent": 39812744,
                        "text": "Apple will hardly let it&#x27;s users know they are using Google. They will name it like Siri ultra pro Max and say they built this.",
                        "time": 1711340269,
                        "type": "comment"
                    }
                ]
            },
            {
                "by": "rolymath",
                "id": 39810769,
                "kids": [
                    39810822
                ],
                "parent": 39809861,
                "text": "ChatGPT was AI&#x27;s mainstream moment.<p>I hate journalists.",
                "time": 1711316452,
                "type": "comment",
                "comments": [
                    {
                        "by": "phmqk76",
                        "id": 39810822,
                        "kids": [
                            39810995,
                            39810875,
                            39810894,
                            39810892
                        ],
                        "parent": 39810769,
                        "text": "I really don\u2019t think that\u2019s true at all. ChatGPT is absolutely not mainstream. It\u2019s pierced the consciousness of the tech-savvy, which maybe be our world, but is decidedly not mainstream. Most people would have no idea how to even use it, they hear about it from headlines. Having it in your pocket and interacting with it on a near-daily basis would be that mainstream moment, whether Apple gets there this year or Google manages to get that feature in tens of millions of phones through an update to its essential services through the Play Store. But your comment definitely shows what it means to be in a bubble.",
                        "time": 1711316963,
                        "type": "comment",
                        "comments": [
                            {
                                "by": "Jensson",
                                "id": 39810995,
                                "kids": [
                                    39811400
                                ],
                                "parent": 39810822,
                                "text": "&gt; ChatGPT is absolutely not mainstream<p>Majority of teens have heard of it and 13% admit using it to cheat on homework, probably much more used it to cheat than admits to it and even more than that used it for any reason. Also note how the rate hoes up a lot in older kids, they probably have more homework so more pressed to cheat.<p><a href=\"https:&#x2F;&#x2F;www.pewresearch.org&#x2F;short-reads&#x2F;2023&#x2F;11&#x2F;16&#x2F;about-1-in-5-us-teens-whove-heard-of-chatgpt-have-used-it-for-schoolwork&#x2F;\" rel=\"nofollow\">https:&#x2F;&#x2F;www.pewresearch.org&#x2F;short-reads&#x2F;2023&#x2F;11&#x2F;16&#x2F;about-1-i...</a>",
                                "time": 1711318418,
                                "type": "comment",
                                "comments": [
                                    {
                                        "by": "amf12",
                                        "id": 39811400,
                                        "kids": [
                                            39811871
                                        ],
                                        "parent": 39810995,
                                        "text": "&gt; Majority of teens have heard of it and 13% admit using it<p>Your source says &quot;Roughly one-in-five teenagers *who have heard of ChatGPT* say they have used it&quot;.<p>This is certainly not &quot;majority&quot; of teens.",
                                        "time": 1711322111,
                                        "type": "comment",
                                        "comments": [
                                            {
                                                "by": "Jensson",
                                                "id": 39811871,
                                                "parent": 39811400,
                                                "text": "67% of teens have heard of it, that is a majority. Of those about 1 in 5 have used it to do their homework, in total 13% of all teens have which matches what I said and the exact numbers you find in the article.<p>All my numbers and descriptions there are correct, it is you who made the mistake here.",
                                                "time": 1711327228,
                                                "type": "comment"
                                            }
                                        ]
                                    }
                                ]
                            },
                            {
                                "by": "pama",
                                "id": 39810875,
                                "kids": [
                                    39811132
                                ],
                                "parent": 39810822,
                                "text": "We\u2019ve purchased an annual subscription for my 85 yo (long time retired) inlaws. They use it daily. They ask their doctors insightful questions and get better care.  They planned trips with it. They get recipe advice.  I don\u2019t know how much more penetration it should have to be considered mainstream but it certainly feels more widely available and used than what Google was 25 years ago, despite having a subscription model.",
                                "time": 1711317438,
                                "type": "comment",
                                "comments": [
                                    {
                                        "by": "okdood64",
                                        "id": 39811132,
                                        "kids": [
                                            39812489
                                        ],
                                        "parent": 39810875,
                                        "text": "Do they double check the information for hallucinations?<p>I&#x27;d personally be scared to promote usage of this for someone (especially a senior) who wouldn&#x27;t have the ability and discipline to.",
                                        "time": 1711319611,
                                        "type": "comment",
                                        "comments": [
                                            {
                                                "by": "pama",
                                                "id": 39812489,
                                                "parent": 39811132,
                                                "text": "Not sure what you mean?  If the recipe is not right it is no major problem but so far all was great. Their trips and questions have been on the spot and it has helped them dramatically.",
                                                "time": 1711335183,
                                                "type": "comment"
                                            }
                                        ]
                                    }
                                ]
                            },
                            {
                                "by": "doktrin",
                                "id": 39810894,
                                "parent": 39810822,
                                "text": "&gt; It\u2019s pierced the consciousness of the tech-savvy... most people would have no idea how to even use it...<p>They&#x27;ve had 100+ million weekly users for over half a year",
                                "time": 1711317660,
                                "type": "comment"
                            },
                            {
                                "by": "frozenport",
                                "id": 39810892,
                                "parent": 39810822,
                                "text": "Naw all the kids are using it cheat on their homework",
                                "time": 1711317656,
                                "type": "comment"
                            }
                        ]
                    }
                ]
            },
            {
                "deleted": true,
                "id": 39810887,
                "parent": 39809861,
                "time": 1711317592,
                "type": "comment"
            }
        ]
    },
    {
        "by": "sherlockxu",
        "descendants": 4,
        "id": 39786943,
        "kids": [
            39788107,
            39789934
        ],
        "score": 48,
        "time": 1711075239,
        "title": "Navigating the World of Large Language Models",
        "type": "story",
        "url": "https://www.bentoml.com/blog/navigating-the-world-of-large-language-models",
        "comments": [
            {
                "by": "sherlockxu",
                "id": 39788107,
                "kids": [
                    39790264,
                    39789196,
                    39789203
                ],
                "parent": 39786943,
                "text": "Hi HN readers,<p>One thing I didn&#x27;t mention in this blog post is that developing vertical models tailored to specific industries may be more important than creating general-purpose models.<p>Actually I have been wondering why we need so many general-purpose models? People in this world come from different industries and what they need is targeted solutions. Vertical models can address nuanced problems that general-purpose models might overlook due to their broad training.<p>Feel free to leave your comments here :-)",
                "time": 1711091763,
                "type": "comment",
                "comments": [
                    {
                        "by": "kouteiheika",
                        "id": 39790264,
                        "parent": 39788107,
                        "text": "&gt; Actually I have been wondering why we need so many general-purpose models? People in this world come from different industries and what they need is targeted solutions. Vertical models can address nuanced problems that general-purpose models might overlook due to their broad training.<p>It&#x27;d be interesting to see a direct comparison which would answer the question of &quot;how many less parameters do you need for a targeted vertical model to solve the same problem as a general purpose model&quot;.<p>Like, for example, let&#x27;s say we pick the task of translating Python to JavaScript, or just any other concrete task: how small could you make a model that <i>only</i> can do this task, vs a general purpose model that can also do this equally well plus a bunch of other things? I wonder if there are any interesting papers tackling this?",
                        "time": 1711112312,
                        "type": "comment"
                    },
                    {
                        "by": "camkego",
                        "id": 39789196,
                        "parent": 39788107,
                        "text": "Thank you for writing the article on the various models.<p>But, I think your HN-comment parent is spot on regarding vertical models vs general purpose.<p>It would be awesome to see an article about when to try to use general-purpose models vs vertical.<p>The ability of LLM models to serve as FAQs and chat-bots and everything in-between, is super powerful.<p>But what are the pros and cons of using vertical vs general purpose LLMs for knowledge bases and chat-bots?<p>I&#x27;d love to see an article that addresses how to create these models, and should they be large-scale general LLMs that are tweaked lightly, or vertical models with baked-in understanding of the vertical they are trying to serve.<p>An article on this might be very useful to many people.",
                        "time": 1711103303,
                        "type": "comment"
                    },
                    {
                        "by": "vouaobrasil",
                        "id": 39789203,
                        "parent": 39788107,
                        "text": "&gt; Actually I have been wondering why we need so many general-purpose models? People in this world come from different industries and what they need is targeted solutions. Vertical models can address nuanced problems that general-purpose models might overlook due to their broad training.<p>It is because the real way to make money from AI is to use it to distract, brainwash, confuse, and make poeple think they need something when they don&#x27;t. So, everyone wants a slice of that pie. Plus, large corporations know that if they create a general-purpose AI then it will be the perfect drug to further distract us from their unsustainable practices.",
                        "time": 1711103338,
                        "type": "comment"
                    }
                ]
            },
            {
                "deleted": true,
                "id": 39789934,
                "parent": 39786943,
                "time": 1711109970,
                "type": "comment"
            }
        ]
    },
    {
        "by": "CharlesW",
        "descendants": 124,
        "id": 39809177,
        "kids": [
            39810189,
            39810767,
            39809825,
            39810857,
            39809549,
            39810860,
            39810036,
            39810544,
            39809334,
            39810232,
            39810439,
            39809551,
            39809942,
            39809810,
            39810907,
            39810838
        ],
        "score": 156,
        "time": 1711305273,
        "title": "GPT-4, without specialized training, beat a GPT-3.5 class model that cost $10M",
        "type": "story",
        "url": "https://www.threads.net/@ethan_mollick/post/C46AfItO8RS",
        "comments": [
            {
                "by": "LASR",
                "id": 39810189,
                "kids": [
                    39810841,
                    39810308,
                    39810529,
                    39810467,
                    39810319
                ],
                "parent": 39809177,
                "text": "I lead AI teams at my company. I&#x27;ve advised leadership against any kind of training &#x2F; fine-tuning anything.<p>We&#x27;re not in the business of training models. We will never be as good as OpenAI &#x2F; Anthropic etc.<p>Where the real value in applications is smarter prompting techniques and RAG. There is a lot of room at the bottom in doing &quot;dumb&quot; things and simply feeding models with the right context to deliver customer value.",
                "time": 1711312075,
                "type": "comment",
                "comments": [
                    {
                        "by": "redox99",
                        "id": 39810841,
                        "kids": [
                            39812468,
                            39811293,
                            39811170
                        ],
                        "parent": 39810189,
                        "text": "That&#x27;s a pretty odd stance. I&#x27;ve finetuned llama&#x2F;mistral models that greatly outperform GPT4 with just a prompt.<p>You have to know when to RAG, finetune, or RAG+finetune.",
                        "time": 1711317184,
                        "type": "comment",
                        "comments": [
                            {
                                "by": "simonw",
                                "id": 39812468,
                                "kids": [
                                    39813117
                                ],
                                "parent": 39810841,
                                "text": "&quot;I&#x27;ve finetuned llama&#x2F;mistral models that greatly outperform GPT4 with just a prompt&quot;<p>If you write about your experiments with that in detail I guarantee you&#x27;ll get a lot of interest. The community is crying out for good, well documented, replicable examples of this kind of thing.",
                                "time": 1711334890,
                                "type": "comment",
                                "comments": [
                                    {
                                        "by": "redox99",
                                        "id": 39813117,
                                        "parent": 39812468,
                                        "text": "I&#x27;m so behind in this area. I had finetuned a model that was SOTA and worth publishing about in October, but procrastinated. I&#x27;m scared to check if somebody else already published on this topic.",
                                        "time": 1711345378,
                                        "type": "comment"
                                    }
                                ]
                            },
                            {
                                "by": "singularity2001",
                                "id": 39811293,
                                "kids": [
                                    39811979
                                ],
                                "parent": 39810841,
                                "text": "<p><pre><code>    greatly outperform GPT4 *for* just a prompt\n</code></pre>\nyour overfitting to training data convinces no-one that you created a &quot;better GPT4&quot;",
                                "time": 1711321078,
                                "type": "comment",
                                "comments": [
                                    {
                                        "by": "redox99",
                                        "id": 39811979,
                                        "parent": 39811293,
                                        "text": "Do you always assume other people are incompetent? That&#x27;s not very nice of you.<p>I mostly work on AI, so I know if I&#x27;m overfitting or not. It performs provably better in it&#x27;s domain (a niche programming language). GPT4 can barely write a hello world for it.<p>I&#x27;m not creating a &quot;better GPT4&quot; general chatbot. I&#x27;m finetuning for a specific task.",
                                        "time": 1711328530,
                                        "type": "comment"
                                    }
                                ]
                            },
                            {
                                "by": "kossTKR",
                                "id": 39811170,
                                "kids": [
                                    39811948
                                ],
                                "parent": 39810841,
                                "text": "How narrow is the dataset to be outperforming greatly?<p>Just curious about what the usecase is for a 7b model in a business context - ie. what does it do?",
                                "time": 1711319901,
                                "type": "comment",
                                "comments": [
                                    {
                                        "by": "redox99",
                                        "id": 39811948,
                                        "parent": 39811170,
                                        "text": "Code assistant for a niche programming language that GPT4 knows very little about and barely gets a hello world right.",
                                        "time": 1711328150,
                                        "type": "comment"
                                    }
                                ]
                            }
                        ]
                    },
                    {
                        "by": "elforce002",
                        "id": 39810308,
                        "parent": 39810189,
                        "text": "This. I work in a startup and told upper management we need to keep focusing on ML models that bring tangible benefits to our customers and then, try to integrate LLMs into their current flow instead of pivoting completely to LLMs. It seems they valued the input and now we&#x27;re going for a hybrid approach.",
                        "time": 1711312837,
                        "type": "comment"
                    },
                    {
                        "by": "throwaway74432",
                        "id": 39810529,
                        "kids": [
                            39810575,
                            39810753,
                            39810577
                        ],
                        "parent": 39810189,
                        "text": "Hear hear. I know a 3 person startup that has a &quot;lead AI researcher&quot; who is trying to train and fine-tune models. That&#x27;s not their startup&#x27;s purpose though... they have an actual product. So wtf are they doing? The lead AI guy thinks he&#x27;s going to compete with these big companies and it&#x27;s total fantasy.<p>LLMs are a <i>commodity</i>",
                        "time": 1711314420,
                        "type": "comment",
                        "comments": [
                            {
                                "by": "qeternity",
                                "id": 39810575,
                                "parent": 39810529,
                                "text": "That does indeed sound crazy. But finetuning is also a commodity these days. You can train a good Mistral LoRA in under 24 hours on a single consumer GPU. We\u2019re talking about $10 of compute.<p>You can run a dozen of these LoRAs atop the same base model on the same infrastructure for a dozen specific use cases.<p>The inference quality, performance and cost can all be substantially better than GPT4 with prompting.",
                                "time": 1711314864,
                                "type": "comment"
                            },
                            {
                                "by": "VirusNewbie",
                                "id": 39810753,
                                "parent": 39810529,
                                "text": "Doesn&#x27;t it entirely depend on how specialized the training data for a given fine tuned model might be?",
                                "time": 1711316360,
                                "type": "comment"
                            },
                            {
                                "deleted": true,
                                "id": 39810577,
                                "parent": 39810529,
                                "time": 1711314903,
                                "type": "comment"
                            }
                        ]
                    },
                    {
                        "by": "seydor",
                        "id": 39810467,
                        "parent": 39810189,
                        "text": "Your advise is based on what?",
                        "time": 1711313926,
                        "type": "comment"
                    },
                    {
                        "by": "jnwatson",
                        "id": 39810319,
                        "kids": [
                            39810427,
                            39810537,
                            39810438
                        ],
                        "parent": 39810189,
                        "text": "It is trivial to fine tune these days. RAG is already irrelevant with large context windows.",
                        "time": 1711312916,
                        "type": "comment",
                        "comments": [
                            {
                                "by": "Xenoamorphous",
                                "id": 39810427,
                                "kids": [
                                    39810805
                                ],
                                "parent": 39810319,
                                "text": "&gt; RAG is already irrelevant with large context windows<p>Just last Friday I took the contents of the 2024 folder of one of the teams at the company I work for, for which we use RAG at the moment. I dumped the text index, concatenated it and used Google\u2019s API to return the token count, to see if it would fit in Gemini\u2019s 1M context window; turned out it was 5.7M tokens. And that\u2019s less than 3 months worth of documents for that team.<p>So yeah RAG is not dead yet, although I do question its usefulness, but that\u2019s a separate topic.",
                                "time": 1711313680,
                                "type": "comment",
                                "comments": [
                                    {
                                        "by": "greenavocado",
                                        "id": 39810805,
                                        "kids": [
                                            39811050
                                        ],
                                        "parent": 39810427,
                                        "text": "Did I read this correctly? You uploaded millions of words of your company&#x27;s internal communications to Google?",
                                        "time": 1711316826,
                                        "type": "comment",
                                        "comments": [
                                            {
                                                "by": "Xenoamorphous",
                                                "id": 39811050,
                                                "parent": 39810805,
                                                "text": "I did. But this is under an enterprise deal with them that warrants privacy, not the generally available stuff. OpenAI has similar arrangements (Enterprise ChatGPT) and MS Azure before them.",
                                                "time": 1711319024,
                                                "type": "comment"
                                            }
                                        ]
                                    }
                                ]
                            },
                            {
                                "by": "SgtBastard",
                                "id": 39810537,
                                "parent": 39810319,
                                "text": "A remarkable comment in that it is clear, confident and wrong.<p>Fine-tunes lead to catastrophic forgetting.<p>RAG is only irrelevant if you\u2019re completely disinterested in cost and latency.<p>We also don\u2019t have enough data to gauge performance of models &gt;200k context window size when reasoning over inputs of that size, much of which will be irrelevant to any particular user. Multiple random needles in haystack tests work flawlessly, but rarely applies to real world activity.",
                                "time": 1711314453,
                                "type": "comment"
                            },
                            {
                                "by": "simonw",
                                "id": 39810438,
                                "kids": [
                                    39810842
                                ],
                                "parent": 39810319,
                                "text": "Citation needed on &quot;trivial to fine tune&quot;.",
                                "time": 1711313742,
                                "type": "comment",
                                "comments": [
                                    {
                                        "by": "danielmarkbruce",
                                        "id": 39810842,
                                        "kids": [
                                            39811640
                                        ],
                                        "parent": 39810438,
                                        "text": "There is no citation needed. It is indeed trivial to fine-tune. Doing a good job is another matter, but the claim is correct. Google around and find a blog post showing how.<p>The claim that RAG is dead is obviously wrong.",
                                        "time": 1711317186,
                                        "type": "comment",
                                        "comments": [
                                            {
                                                "by": "simonw",
                                                "id": 39811640,
                                                "kids": [
                                                    39811976
                                                ],
                                                "parent": 39810842,
                                                "text": "For &quot;citation needed&quot;, read &quot;please link me to a blog post showing how, don&#x27;t just tell me to Google for one&quot;.<p>The internet is full of blog posts about this. That doesn&#x27;t mean they&#x27;re actually good - I&#x27;d love to be pointed at one that has proven itself useful for someone (and definitely isn&#x27;t just LLM blog-spam).<p>I don&#x27;t care if it&#x27;s trivial to fine-tune and get crap results - I care about fine-tuning where the result was worth the effort.<p>For the record, my favourite guide to fine-tuning is the section of this Jeremy Howard video that shows how to train a text-to-SQL model: <a href=\"https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=jkrNMKz9pWU&amp;t=4850s\" rel=\"nofollow\">https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=jkrNMKz9pWU&amp;t=4850s</a>",
                                                "time": 1711324695,
                                                "type": "comment",
                                                "comments": [
                                                    {
                                                        "by": "danielmarkbruce",
                                                        "id": 39811976,
                                                        "kids": [
                                                            39812449,
                                                            39813916
                                                        ],
                                                        "parent": 39811640,
                                                        "text": "It&#x27;s an internet forum, not an academic journal. Water tight arguments are not needed. If one wants to call bs, they can just do it, no need to dance around the topic by asking for a citation.",
                                                        "time": 1711328484,
                                                        "type": "comment",
                                                        "comments": [
                                                            {
                                                                "by": "simonw",
                                                                "id": 39812449,
                                                                "kids": [
                                                                    39817105
                                                                ],
                                                                "parent": 39811976,
                                                                "text": "OK, I call BS. Fine-tuning an LLM is not &quot;trivial&quot; - especially if you want to get useful results, as opposed to just being able to say &quot;look, I fine-tuned an LLM&quot;.",
                                                                "time": 1711334719,
                                                                "type": "comment",
                                                                "comments": [
                                                                    {
                                                                        "by": "danielmarkbruce",
                                                                        "id": 39817105,
                                                                        "parent": 39812449,
                                                                        "text": "Yup, largely agree.",
                                                                        "time": 1711378562,
                                                                        "type": "comment"
                                                                    }
                                                                ]
                                                            },
                                                            {
                                                                "by": "wakaru44",
                                                                "id": 39813916,
                                                                "kids": [
                                                                    39817065
                                                                ],
                                                                "parent": 39811976,
                                                                "text": "Exactly, it&#x27;s a forum not Twitter&#x2F;reddit. Without references and citations this is no better than a bunch of random words, and it&#x27;s hard to make any argument of substance.<p>The person asked for citations, leave it be, stop dudexplaining how Internet works for you please.<p>I call bs on your 2 comments.",
                                                                "time": 1711356029,
                                                                "type": "comment",
                                                                "comments": [
                                                                    {
                                                                        "by": "danielmarkbruce",
                                                                        "id": 39817065,
                                                                        "parent": 39813916,
                                                                        "text": "They didn&#x27;t ask for citations. They pointed out a citation was needed. It was a clever sounding way of calling bs. They admit as much.<p>Even when people sincerely ask for a citation on a debatable topic, on an internet forum, it&#x27;s effectively saying &quot;I won&#x27;t be hear any opinion that doesn&#x27;t match my own unless it&#x27;s as water tight as a law of physics&quot;. Another form of this is &quot;show me the data&quot;.",
                                                                        "time": 1711378365,
                                                                        "type": "comment"
                                                                    }
                                                                ]
                                                            }
                                                        ]
                                                    }
                                                ]
                                            }
                                        ]
                                    }
                                ]
                            }
                        ]
                    }
                ]
            },
            {
                "by": "krasin",
                "id": 39810767,
                "kids": [
                    39812103,
                    39810934
                ],
                "parent": 39809177,
                "text": "Finetuning LLMs is currently the most promising way for next-gen robotics. One of such works (PaLM-e) among other things measured the impact of finetuning on general purpose tasks: <a href=\"https:&#x2F;&#x2F;twitter.com&#x2F;DannyDriess&#x2F;status&#x2F;1632904698108821505\" rel=\"nofollow\">https:&#x2F;&#x2F;twitter.com&#x2F;DannyDriess&#x2F;status&#x2F;1632904698108821505</a><p>In short, an 8B model could degrade almost 10x after being finetuned on robotics tasks, while 500B model experiences a very minor degradation (~4%) and there&#x27;s a hope that with a larger-sized model, it could become either zero or even negative (adding more experience improves general purpose reasoning).<p>What I am saying is that while GPT-4 could beat a finetuned GPT-3.5 class model, I predict good things about finetuned GPT-4 class models, when they become practical outside of OpenAI&#x2F;Google.",
                "time": 1711316443,
                "type": "comment",
                "comments": [
                    {
                        "by": "gradascent",
                        "id": 39812103,
                        "kids": [
                            39812411,
                            39813421
                        ],
                        "parent": 39810767,
                        "text": "Interesting! I would like to learn more about how AI is being applied to robotics. Do you have any suggestions for how to keep up with developments&#x2F;ideas in this field?",
                        "time": 1711329846,
                        "type": "comment",
                        "comments": [
                            {
                                "by": "krasin",
                                "id": 39812411,
                                "parent": 39812103,
                                "text": "These two links could be a good start:<p>ALOHA-2: <a href=\"https:&#x2F;&#x2F;aloha-2.github.io&#x2F;\" rel=\"nofollow\">https:&#x2F;&#x2F;aloha-2.github.io&#x2F;</a><p>RT-X: <a href=\"https:&#x2F;&#x2F;robotics-transformer-x.github.io&#x2F;\" rel=\"nofollow\">https:&#x2F;&#x2F;robotics-transformer-x.github.io&#x2F;</a>",
                                "time": 1711334077,
                                "type": "comment"
                            },
                            {
                                "by": "hlfshell",
                                "id": 39813421,
                                "kids": [
                                    39814000
                                ],
                                "parent": 39812103,
                                "text": "In October I wrote a blogpost on this subject: <a href=\"https:&#x2F;&#x2F;hlfshell.ai&#x2F;posts&#x2F;llms-and-robotics-papers-2023&#x2F;\" rel=\"nofollow\">https:&#x2F;&#x2F;hlfshell.ai&#x2F;posts&#x2F;llms-and-robotics-papers-2023&#x2F;</a><p>..and plan to do an updated version soon for much of what&#x27;s been released since. I&#x27;ve also done work related to LLM and robotics integration, also on that site.<p>Happy to chat about it.",
                                "time": 1711350284,
                                "type": "comment",
                                "comments": [
                                    {
                                        "by": "newswasboring",
                                        "id": 39814000,
                                        "kids": [
                                            39818029
                                        ],
                                        "parent": 39813421,
                                        "text": "Working my way through your blog post and it is so refreshing. Unfortunately my algorithm currently is showing me takes which are extreme on either end (like in your blog post).<p>&gt; Technology\u2019s largest leaps occur when new tools are provided to those that want to make things.<p>I love this sentence. And the general attitude of curiosity of your post.",
                                        "time": 1711357032,
                                        "type": "comment",
                                        "comments": [
                                            {
                                                "by": "hlfshell",
                                                "id": 39818029,
                                                "parent": 39814000,
                                                "text": "Thanks! Appreciate the kind words. I should have in the next month or so (interviewing and finishing my Master&#x27;s, so there&#x27;s been delays) a follow up that follows more advancements in the router style VLA, sensoiromotor VLM, and advances in embedding enriched vision models in general.<p>If you want a great overview of what a modern robotics stack would look like with all this, <a href=\"https:&#x2F;&#x2F;ok-robot.github.io&#x2F;\" rel=\"nofollow\">https:&#x2F;&#x2F;ok-robot.github.io&#x2F;</a> was really good and will likely make it into the article. It&#x27;s a VLA combined with existing RL methods to demonstrate multi-tasking robots, and serves as a great glimpes into what a lot of researchers are working on. You won&#x27;t see these techniques in robots in industrial or commercial settings - we&#x27;re still too new at this to be reliable or capable enough to deploy these on real tasks.",
                                                "time": 1711382739,
                                                "type": "comment"
                                            }
                                        ]
                                    }
                                ]
                            }
                        ]
                    },
                    {
                        "by": "TMWNN",
                        "id": 39810934,
                        "kids": [
                            39811566
                        ],
                        "parent": 39810767,
                        "text": "&gt;there&#x27;s a hope that with a larger-sized model, it could become either zero or even negative (adding more experience improves general purpose reasoning).<p>The best single work of fiction ever created about LLMs&#x27; capabilities (and, perhaps, dangers) is <i>Colossus</i> by Jones. Although I think the film is even better than the book, only the latter mentions how, despite being created specifically for US national defense, Colossus is also fed unrelated data including Shakespeare&#x27;s sonnets, because its creators do not know if it could be important.",
                        "time": 1711317982,
                        "type": "comment",
                        "comments": [
                            {
                                "by": "paulmd",
                                "id": 39811566,
                                "parent": 39810934,
                                "text": "What good is a revolution without dancing?",
                                "time": 1711323925,
                                "type": "comment"
                            }
                        ]
                    }
                ]
            },
            {
                "by": "minimaxir",
                "id": 39809825,
                "kids": [
                    39810176,
                    39810496,
                    39810162,
                    39809996,
                    39810651
                ],
                "parent": 39809177,
                "text": "Extremely hot LLM take: You will often get better results with few-shot prompting (with good examples) on a modern LLM than with a finetuned LLM.<p>Finetuning was the best option for weaker LLMs with lower context windows (e.g. the original GPT-3): both problems have been solved nowadays.<p>The cost economics are much better with few-shot prompting to modern LLMs too: input tokens are super cheap (especially with the recently-released Claude Haiku), so giving a lot of examples per call will still end up cheaper than finetuning.<p>Meanwhile, a finetuned ChatGPT costs 4-6x of normal ChatGPT usage.",
                "time": 1711309743,
                "type": "comment",
                "comments": [
                    {
                        "by": "zapperdulchen",
                        "id": 39810176,
                        "kids": [
                            39810572,
                            39810824,
                            39811594,
                            39810384
                        ],
                        "parent": 39809825,
                        "text": "Seems like the bitter lesson is still right: <a href=\"http:&#x2F;&#x2F;www.incompleteideas.net&#x2F;IncIdeas&#x2F;BitterLesson.html\" rel=\"nofollow\">http:&#x2F;&#x2F;www.incompleteideas.net&#x2F;IncIdeas&#x2F;BitterLesson.html</a>",
                        "time": 1711311987,
                        "type": "comment",
                        "comments": [
                            {
                                "by": "nialse",
                                "id": 39810572,
                                "parent": 39810176,
                                "text": "For those who were oblivious to it, like myself, the bitter lesson is written by  Richard S Sutton who invented reinforcement learning a long, long time ago.",
                                "time": 1711314849,
                                "type": "comment"
                            },
                            {
                                "by": "tomrod",
                                "id": 39810824,
                                "parent": 39810176,
                                "text": "This is an earth-shattering read.",
                                "time": 1711316996,
                                "type": "comment"
                            },
                            {
                                "by": "pbronez",
                                "id": 39811594,
                                "kids": [
                                    39812931
                                ],
                                "parent": 39810176,
                                "text": "I can\u2019t access the article there\u2026 SSL error and then timeout. Here\u2019s a link to the most recent WayBackMachine snapshot:<p><a href=\"https:&#x2F;&#x2F;web.archive.org&#x2F;web&#x2F;20240321091803&#x2F;https:&#x2F;&#x2F;www.incompleteideas.net&#x2F;IncIdeas&#x2F;BitterLesson.html\" rel=\"nofollow\">https:&#x2F;&#x2F;web.archive.org&#x2F;web&#x2F;20240321091803&#x2F;https:&#x2F;&#x2F;www.incom...</a>",
                                "time": 1711324238,
                                "type": "comment",
                                "comments": [
                                    {
                                        "by": "port443",
                                        "id": 39812931,
                                        "parent": 39811594,
                                        "text": "There&#x27;s no SSL at all on that site, since it&#x27;s http not https. Your browser is breaking the link.",
                                        "time": 1711341919,
                                        "type": "comment"
                                    }
                                ]
                            },
                            {
                                "by": "Solvency",
                                "id": 39810384,
                                "kids": [
                                    39810543,
                                    39810549
                                ],
                                "parent": 39810176,
                                "text": "Whoa this guy says &quot;computation&quot; and not grammatically bastardized techbrospeak &quot;compute&quot; like some neckbeard equivalent of a caveman!<p>For that alone I commend him.",
                                "time": 1711313339,
                                "type": "comment",
                                "comments": [
                                    {
                                        "by": "jorvi",
                                        "id": 39810543,
                                        "kids": [
                                            39810602,
                                            39810883,
                                            39810738
                                        ],
                                        "parent": 39810384,
                                        "text": "Compute is.. I don\u2019t know the exact English grammatical term but it\u2019s like water. Computation is not.<p>\u201cI have 1000 flops of compute\u201d - works.<p>\u201cI have 1000 flops of computation\u201d - doesn\u2019t work.<p>\u201cThat compute failed\u201d - doesn\u2019t work.<p>\u201cThat computation failed\u201d - works.<p>They\u2019re different.",
                                        "time": 1711314496,
                                        "type": "comment",
                                        "comments": [
                                            {
                                                "by": "thewakalix",
                                                "id": 39810602,
                                                "parent": 39810543,
                                                "text": "<a href=\"https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Mass_noun\" rel=\"nofollow\">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Mass_noun</a>",
                                                "time": 1711315056,
                                                "type": "comment"
                                            },
                                            {
                                                "by": "xanderlewis",
                                                "id": 39810883,
                                                "kids": [
                                                    39812044
                                                ],
                                                "parent": 39810543,
                                                "text": "As far as I know, it\u2019s usually called an <i>uncountable noun</i>.<p>\u2026but \u2018computation\u2019 is also uncountable, and your second sentence seems to be perfectly fine to me.<p>Your examples do not constitute an argument. You haven\u2019t articulated the (purported) difference between the two words; you\u2019ve just decided arbitrarily that some sentences don\u2019t work, and not elaborated or explained at all.<p>I can make up words too, and provide example sentences: \u201ckarrotz are delicious\u201d works. \u201ccarrots are delicious\u201d doesn\u2019t. \u201cinside the karrotz\u201d doesn\u2019t work. \u201cinside the carrots\u201d does.<p>I don\u2019t actually think there is any difference. The above comment about \u2018brospeak\u2019 was snarky but I do think it\u2019s more of a cultural phenomenon than a semantic one \u2014 unless someone is willing to kindly explain the difference rather than just rolling their eyes!<p>What <i>exactly</i> is wrong with the sentence \u2018this would require huge amounts of computation\u2019? Saying \u2018compute\u2019 seems more to be a synonym of \u2018computation\u2019 that\u2019s caught on recently than a useful gap-filling addition to the language. Again: reasoned arguments please. Or just \u2018we think it sounds cool so we use it\u2019 \u2014 that\u2019s fine, too.<p>EDIT: pondering briefly, perhaps one could argue the difference is something like \u2018you can <i>own</i> compute, but you can\u2019t own computation.\u2019 \u2018Compute\u2019 is the capacity to carry out computation. \u2026although \u2018compute\u2019 seems to be used to refer to the \u2018abstract\u2019 computation being done as well as the computational resources, so I don\u2019t know.<p>I\u2019m stretching it. To be honest I\u2019m not sure it\u2019s a useful (or even real) distinction. I think it\u2019s a matter of fashion, and that\u2019s fine and normal.",
                                                "time": 1711317547,
                                                "type": "comment",
                                                "comments": [
                                                    {
                                                        "deleted": true,
                                                        "id": 39812044,
                                                        "parent": 39810883,
                                                        "time": 1711329193,
                                                        "type": "comment"
                                                    }
                                                ]
                                            },
                                            {
                                                "by": "Solvency",
                                                "id": 39810738,
                                                "parent": 39810543,
                                                "text": "Literally not true. Compute is a verb. Computation is the right word in all of those cases. Or computational &lt;noun&gt;.",
                                                "time": 1711316156,
                                                "type": "comment"
                                            }
                                        ]
                                    },
                                    {
                                        "deleted": true,
                                        "id": 39810549,
                                        "parent": 39810384,
                                        "time": 1711314594,
                                        "type": "comment"
                                    }
                                ]
                            }
                        ]
                    },
                    {
                        "by": "marviel",
                        "id": 39810496,
                        "kids": [
                            39816439,
                            39810782
                        ],
                        "parent": 39809825,
                        "text": "Several MSFT AI&#x2F;ML friends actively dissuaded me and my team from fine-tuning. They said that it&#x27;s pretty clear in all their internal tests that it &quot;lobotomizes&quot; the general reasoning capabilities of the model, unless you&#x27;re really careful.<p>&quot;All work and no play makes GPT a very dull AI&quot;",
                        "time": 1711314104,
                        "type": "comment",
                        "comments": [
                            {
                                "by": "Ambix",
                                "id": 39816439,
                                "parent": 39810496,
                                "text": "Yes, that&#x27;s what I&#x27;ve seen from a lot of my experiments with fine-tuning. One should be really careful to not &quot;lobotomize&quot; already capable model and achieve better results at the end. It&#x27;s trickier than seems from multiple of tutorials.<p>But I believe that most of the data stored in foundation models are just useless for some particular domain. So it&#x27;s better to forget something, getting really useful info instead.",
                                "time": 1711375348,
                                "type": "comment"
                            },
                            {
                                "by": "FrustratedMonky",
                                "id": 39810782,
                                "kids": [
                                    39810955
                                ],
                                "parent": 39810496,
                                "text": "&quot;bitter lesson that building in how we think we think does not work in the long run&quot;<p>Guess. Stop trying to shape the NN. And let it learn on its own.",
                                "time": 1711316584,
                                "type": "comment",
                                "comments": [
                                    {
                                        "by": "TMWNN",
                                        "id": 39810955,
                                        "kids": [
                                            39815473
                                        ],
                                        "parent": 39810782,
                                        "text": "&gt;And let it learn on its own.<p>The best single work of fiction ever created about LLMs&#x27; capabilities (and, perhaps, dangers) is <i>Colossus</i> by Jones. Although I think the film is even better than the book, only the latter mentions how, despite being created specifically for US national defense, Colossus is also fed unrelated data including Shakespeare&#x27;s sonnets, because its creators do not know if it could be important.",
                                        "time": 1711318103,
                                        "type": "comment",
                                        "comments": [
                                            {
                                                "by": "FrustratedMonky",
                                                "id": 39815473,
                                                "parent": 39810955,
                                                "text": "I think the movie Colossus still holds up today.  Saw it last year, It was pretty scary.",
                                                "time": 1711369766,
                                                "type": "comment"
                                            }
                                        ]
                                    }
                                ]
                            }
                        ]
                    },
                    {
                        "by": "thorum",
                        "id": 39810162,
                        "kids": [
                            39810335
                        ],
                        "parent": 39809825,
                        "text": "That might be true for finetuning ChatGPT 3.5, but if you can finetune a small model (7B or less) to perform on par with GPT-4, while being faster and private, that\u2019s a different story.",
                        "time": 1711311868,
                        "type": "comment",
                        "comments": [
                            {
                                "by": "smallnamespace",
                                "id": 39810335,
                                "kids": [
                                    39810556
                                ],
                                "parent": 39810162,
                                "text": "You definitely can&#x27;t in the general case (for example, your 7B model is never going to be able to help much with coding, fine tuning or no).<p>It can make sense if you have a particularly simple use case.",
                                "time": 1711312989,
                                "type": "comment",
                                "comments": [
                                    {
                                        "by": "qeternity",
                                        "id": 39810556,
                                        "kids": [
                                            39812588
                                        ],
                                        "parent": 39810335,
                                        "text": "By definition you wouldn\u2019t fine tune a 7B model to be generally as good at GPT4. You would just be trying to overfit some small amount of functionality in a narrow domain.",
                                        "time": 1711314651,
                                        "type": "comment",
                                        "comments": [
                                            {
                                                "by": "smallnamespace",
                                                "id": 39812588,
                                                "parent": 39810556,
                                                "text": "Yes but from the context of this discussion, we\u2019re trying to figure out the \u201csweet spot\u201d model size where it\u2019s worth attempting fine tuning. My guess is it\u2019s only worthwhile for matching simple tasks with small models, and any sufficiently complicated task it\u2019s better to do few&#x2F;zero shot instead.",
                                                "time": 1711336836,
                                                "type": "comment"
                                            }
                                        ]
                                    }
                                ]
                            }
                        ]
                    },
                    {
                        "by": "viksit",
                        "id": 39809996,
                        "kids": [
                            39810082,
                            39810127
                        ],
                        "parent": 39809825,
                        "text": "can you give a few pointers on articles or examples of this?",
                        "time": 1711310712,
                        "type": "comment",
                        "comments": [
                            {
                                "by": "minimaxir",
                                "id": 39810082,
                                "kids": [
                                    39810142
                                ],
                                "parent": 39809996,
                                "text": "A low-tech example to create a good blog post title for submission to Hacker News would be a system prompt like:<p><pre><code>    You are an expert copywriter. Write five distinct blog post titles optimized for high clickthrough for Hacker News for the article the user provides.\n\n    Your response must follow the style of these titles:\n      - The \u00fc&#x2F;\u00fc Conundrum\n      - Why isn&#x27;t preprint review being adopted?\n      - Majority of web apps could just run on a single server\n      - Weather Planning for Eclipse Day\n      - PSChess \u2013 A chess engine in PostScript\n</code></pre>\nThen provide the blog post as the user message input.<p>I just ran one of my blog posts (<a href=\"https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=39495476\">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=39495476</a>) with the workflow through Claude Haiku and got this:<p><pre><code>    Here are five distinct blog post titles optimized for high clickthrough on Hacker News for the article provided:\n\n    1. Tipping ChatGPT: Does Offering Monetary Incentives Improve AI Text Generation?\n\n    2. Quantifying the Impact of Incentives on Large Language Model Performance\n\n    3. Carrot or Stick? Exploring the Effects of Positive and Negative Prompts on ChatGPT\n\n    4. Gamifying AI: Using &quot;Generation Golf&quot; to Test ChatGPT&#x27;s Ability to Follow Length Constraints\n\n    5. The Curious Case of ChatGPT&#x27;s Motivations: Can an AI Be Incentivized Like Humans?\n</code></pre>\nNot bad titles, although more verbose than the 5 input examples I gave. I only gave 5 for simplicity: my main point is that you can give it a <i>lot</i> more than five and&#x2F;or be more aggressive with constraints, like the blog post linked incidentially.",
                                "time": 1711311276,
                                "type": "comment",
                                "comments": [
                                    {
                                        "by": "viksit",
                                        "id": 39810142,
                                        "kids": [
                                            39810200
                                        ],
                                        "parent": 39810082,
                                        "text": "interesting thank you.<p>intuitively, prompting like this to get an answer seems basically like the first part of a fine tuning process (more exemplars).<p>what is your thought here behind why reinforcing good output via a loss optimization is worse than the one shot example? does the model start to over fit at some point towards some local minima? and this is avoided in this scenario?",
                                        "time": 1711311695,
                                        "type": "comment",
                                        "comments": [
                                            {
                                                "by": "minimaxir",
                                                "id": 39810200,
                                                "parent": 39810142,
                                                "text": "Prompt engineering in general is necessary because LLMs optimize for the <i>average</i> output, and average output is not good. So LLMs need a slight nudge.",
                                                "time": 1711312170,
                                                "type": "comment"
                                            }
                                        ]
                                    }
                                ]
                            },
                            {
                                "by": "netdur",
                                "id": 39810127,
                                "parent": 39809996,
                                "text": "Use Gemini 1.5 Pro, which has 1.5 million tokens. Prompt it with a logical question and observe it struggling to answer. Then, upload a book on logical thinking in PDF format and ask the same question again. Notice how it can now answer the question effectively.",
                                "time": 1711311600,
                                "type": "comment"
                            }
                        ]
                    },
                    {
                        "by": "jna_sh",
                        "id": 39810651,
                        "parent": 39809825,
                        "text": "\u201cModern\u201d is an extremely funny delineation given the small temporal window of this whole thing",
                        "time": 1711315424,
                        "type": "comment"
                    }
                ]
            },
            {
                "by": "kcorbitt",
                "id": 39810857,
                "parent": 39809177,
                "text": "IMO it&#x27;s possible to over-generalize from this datapoint (lol). While it&#x27;s true that creating a general &quot;finance&quot; model that&#x27;s stronger than GPT-4 is hard, training a task-specific model is much easier. Eg. &quot;a model that&#x27;s better than GPT-4 at answering finance-related questions&quot;: very hard. &quot;A model that&#x27;s better than GPT-4 at extracting forward-looking financial projections in a standard format&quot;: very easy.<p>And in practice, most tasks people are using GPT-4 for in production are more like the latter than the former.<p>(Disclaimer: building <a href=\"https:&#x2F;&#x2F;openpipe.ai\">https:&#x2F;&#x2F;openpipe.ai</a>, which makes it super easy to productize this workflow).",
                "time": 1711317341,
                "type": "comment"
            },
            {
                "by": "MuffinFlavored",
                "id": 39809549,
                "kids": [
                    39809693,
                    39809662,
                    39810193,
                    39809792,
                    39810813,
                    39809904,
                    39810254,
                    39810178,
                    39810051,
                    39810517,
                    39810165
                ],
                "parent": 39809177,
                "text": "Does anything currently beat GPT-4?<p>I saw some comments here say to check out Claude. From what I can tell, Claude hasn&#x27;t figure out yet how to do the whole &quot;generate Python code and run it in a Juptyer notebook&quot; for math yet.",
                "time": 1711308183,
                "type": "comment",
                "comments": [
                    {
                        "by": "rubymamis",
                        "id": 39809693,
                        "kids": [
                            39810820,
                            39810936
                        ],
                        "parent": 39809549,
                        "text": "A programming task where Mistral-large beats both GPT-4 and Claude Opus: <a href=\"https:&#x2F;&#x2F;sdk.vercel.ai&#x2F;s&#x2F;Thi7RDx9e8VOZo1Ee6We5\" rel=\"nofollow\">https:&#x2F;&#x2F;sdk.vercel.ai&#x2F;s&#x2F;Thi7RDx9e8VOZo1Ee6We5</a> (only Mistral got the current syntax)<p>Although based on other tasks, overall, GPT-4 seems to be the best, but by a very small margin, so I cancelled my subscription. Although the native mobile app is really great.",
                        "time": 1711309001,
                        "type": "comment",
                        "comments": [
                            {
                                "by": "fragmede",
                                "id": 39810820,
                                "kids": [
                                    39814178
                                ],
                                "parent": 39809693,
                                "text": "Is there a way to use Mistral-large with TTS and STT engines so you can converse with it like you can ChatGPT in the mobile app? it&#x27;s really great on long drives for learning&#x2F;talking about stuff, like a customized personal podcast.",
                                "time": 1711316937,
                                "type": "comment",
                                "comments": [
                                    {
                                        "by": "rubymamis",
                                        "id": 39814178,
                                        "parent": 39810820,
                                        "text": "Exactly, I absolutely love this feature. And many times the conversation is quite natural and fluid (with good internet connection). I think I&#x27;ll build something like that myself (:",
                                        "time": 1711358943,
                                        "type": "comment"
                                    }
                                ]
                            },
                            {
                                "by": "cosmojg",
                                "id": 39810936,
                                "kids": [
                                    39814195
                                ],
                                "parent": 39809693,
                                "text": "Do you prefer Mistral-Large or Claude-Opus?",
                                "time": 1711317991,
                                "type": "comment",
                                "comments": [
                                    {
                                        "by": "rubymamis",
                                        "id": 39814195,
                                        "parent": 39810936,
                                        "text": "Not sure. Most of the time GPT-4 is better. Since I&#x27;m using Vercel AI playground[1], on almost every query I get a response from all models so it&#x27;s easy to compare.<p>[1] <a href=\"https:&#x2F;&#x2F;sdk.vercel.ai&#x2F;\" rel=\"nofollow\">https:&#x2F;&#x2F;sdk.vercel.ai&#x2F;</a>",
                                        "time": 1711359053,
                                        "type": "comment"
                                    }
                                ]
                            }
                        ]
                    },
                    {
                        "by": "monsieurbanana",
                        "id": 39809662,
                        "kids": [
                            39809735
                        ],
                        "parent": 39809549,
                        "text": "Isn&#x27;t that something you get from the infrastructure surrounding the llm? I thought the &quot;running code&quot; feature didn&#x27;t need specific support from the llm, besides being able to output conforming json or code when asked to.",
                        "time": 1711308803,
                        "type": "comment",
                        "comments": [
                            {
                                "by": "MuffinFlavored",
                                "id": 39809735,
                                "kids": [
                                    39810401,
                                    39810921,
                                    39809887
                                ],
                                "parent": 39809662,
                                "text": "The LLM (Claude) currently doesn&#x27;t know to not hallucinate numbers and instead write code + run it (something ChatGPT used to do but they fixed it)",
                                "time": 1711309232,
                                "type": "comment",
                                "comments": [
                                    {
                                        "by": "simonw",
                                        "id": 39810401,
                                        "kids": [
                                            39810804
                                        ],
                                        "parent": 39809735,
                                        "text": "That&#x27;s because the Claude web UI doesn&#x27;t yet have the equivalent of the ChatGPT Code Interpreter tool (though they say they&#x27;re working on it). That&#x27;s not about the quality of the Claude 3 Opus model, which is the model which people think compares to or beats GPT-4. It&#x27;s about the tooling that has been built for ChatGPT.",
                                        "time": 1711313442,
                                        "type": "comment",
                                        "comments": [
                                            {
                                                "by": "fragmede",
                                                "id": 39810804,
                                                "parent": 39810401,
                                                "text": "Code interpreter is pretty neat, because you can tell ChatGPT to write some code and to make sure the code works, and then it&#x27;ll write you some bad code, realize it&#x27;s bad, and then iterate on it until it gets to a place that it&#x27;s happy with. (Maybe I should say passes its test rather than anthropomorphize ChatGPT as being &quot;happy&quot;.)",
                                                "time": 1711316814,
                                                "type": "comment"
                                            }
                                        ]
                                    },
                                    {
                                        "by": "cosmojg",
                                        "id": 39810921,
                                        "kids": [
                                            39820580
                                        ],
                                        "parent": 39809735,
                                        "text": "Right, like the other commenter suggested, that&#x27;s an infrastructure-level thing, not a model-level thing. Given that you&#x27;re talking about ChatGPT, I assume you aren&#x27;t accessing GPT-3.5 or GPT-4 directly through the API but using the app or the interface provided at chat.openai.com. The magic that makes the kinds of interactions you&#x27;re describing possible amounts to a bit of clever prompting sprinkled on top of some rather impressive frontend design and engineering.<p>Correctly prompted, even Mistral-7B can write and run code in response to questions, and it&#x27;s a model that can run on laptops from half a decade ago, with two or three orders of magnitude fewer parameters that GPT-4.",
                                        "time": 1711317879,
                                        "type": "comment",
                                        "comments": [
                                            {
                                                "by": "MuffinFlavored",
                                                "id": 39820580,
                                                "parent": 39810921,
                                                "text": "&gt; Right, like the other commenter suggested, that&#x27;s an infrastructure-level thing, not a model-level thing.<p>By default, the ChatGPT &quot;model&quot; knows to not try to do math and instead write code to do the math then run it. I get that it&#x27;s set up infrastructure wise to be able to run it, but why is Claude&#x27;s main chat UI not trying to instead respond<p>&quot;hey, do this calculation on your own since I can&#x27;t&quot; or something of this nature instead of responding to math incorrectly",
                                                "time": 1711396411,
                                                "type": "comment"
                                            }
                                        ]
                                    },
                                    {
                                        "by": "avree",
                                        "id": 39809887,
                                        "parent": 39809735,
                                        "text": "Doesn&#x27;t seem like you are very informed on how LLMs work, but just so you know, there are many different versions of Claude, just like how ChatGPT can use different versions of GPT.",
                                        "time": 1711310099,
                                        "type": "comment"
                                    }
                                ]
                            }
                        ]
                    },
                    {
                        "by": "thorum",
                        "id": 39810193,
                        "kids": [
                            39810414
                        ],
                        "parent": 39809549,
                        "text": "I don\u2019t know what the people who say Claude 3 is better than GPT-4 are using it for. It\u2019s been consistently worse for everything I\u2019ve thrown at it.<p>Debugging a Python function this morning. Claude 3 Opus failed completely. GPT-4 found the bug, as well as two others I hadn\u2019t even been looking for.",
                        "time": 1711312120,
                        "type": "comment",
                        "comments": [
                            {
                                "by": "simonw",
                                "id": 39810414,
                                "kids": [
                                    39810799
                                ],
                                "parent": 39810193,
                                "text": "I&#x27;ve had the opposite experience: coding prompts that GPT-4 makes mistakes on Claude 3 Opus gets right the first time.<p>As always, your results will vary based on your personal prompting style. My style apparently works great with Opus.<p>Here&#x27;s one example: GPT-4 gave me code that was missing some async&#x2F;await keywords: <a href=\"https:&#x2F;&#x2F;chat.openai.com&#x2F;share&#x2F;117fb1ad-6361-41e2-be59-110f3262594d\" rel=\"nofollow\">https:&#x2F;&#x2F;chat.openai.com&#x2F;share&#x2F;117fb1ad-6361-41e2-be59-110f32...</a><p>Claude 3 Opus with the same prompt got it right the first time: <a href=\"https:&#x2F;&#x2F;gist.github.com&#x2F;simonw&#x2F;2002e2b56a97053bd9302a34e0b83074\" rel=\"nofollow\">https:&#x2F;&#x2F;gist.github.com&#x2F;simonw&#x2F;2002e2b56a97053bd9302a34e0b83...</a>",
                                "time": 1711313578,
                                "type": "comment",
                                "comments": [
                                    {
                                        "by": "brianjking",
                                        "id": 39810799,
                                        "parent": 39810414,
                                        "text": "Yeah, Opus has entirely taken over any code specific use for me over ChatGPT 4 or OpenAI GPT-4 API.<p>Once Opus has the ability to run a code interpreter, it&#x27;ll really be an exciting time.",
                                        "time": 1711316735,
                                        "type": "comment"
                                    }
                                ]
                            }
                        ]
                    },
                    {
                        "by": "geor9e",
                        "id": 39809792,
                        "parent": 39809549,
                        "text": "I don&#x27;t know what system and user prompt you are testing with, but as one anecdote, Claude 3 Opus (and only Opus) consistently gives me better coding answers than GPT-4. Maybe it&#x27;s the type of stuff I am doing or how I phrase things, who knows. I was using GPT-4 since the day it came out but haven&#x27;t felt like going back so far.",
                        "time": 1711309570,
                        "type": "comment"
                    },
                    {
                        "by": "dragonwriter",
                        "id": 39810813,
                        "parent": 39809549,
                        "text": "&gt; Claude hasn&#x27;t figure out yet how to do the whole &quot;generate Python code and run it in a Juptyer notebook&quot; for math yet.<p>GPT-4 didn&#x27;t figure that out, either; that\u2019s just tooling built around the model, not something the model \u201cfigures out\u201d.",
                        "time": 1711316885,
                        "type": "comment"
                    },
                    {
                        "by": "jxdxbx",
                        "id": 39809904,
                        "parent": 39809549,
                        "text": "Claude is better than GPT 4 for my uses, and was able to help me do some simple coding things that GPT 4 could not. It\u2019s worth trying at least.",
                        "time": 1711310201,
                        "type": "comment"
                    },
                    {
                        "by": "drexlspivey",
                        "id": 39810254,
                        "parent": 39809549,
                        "text": "According to Chatbot Arena where people vote on responses blindly and an ELO rating is determined for each LLM, gpt4 is on top slightly ahead of Claude 3 Opus<p><a href=\"https:&#x2F;&#x2F;huggingface.co&#x2F;spaces&#x2F;lmsys&#x2F;chatbot-arena-leaderboard\" rel=\"nofollow\">https:&#x2F;&#x2F;huggingface.co&#x2F;spaces&#x2F;lmsys&#x2F;chatbot-arena-leaderboar...</a>",
                        "time": 1711312536,
                        "type": "comment"
                    },
                    {
                        "by": "jasonjmcghee",
                        "id": 39810178,
                        "parent": 39809549,
                        "text": "Claude Opus (largest v3 model) consistently outperforms GPT-4 for me. Better at following prompts, _feels_ much better.",
                        "time": 1711311990,
                        "type": "comment"
                    },
                    {
                        "by": "treprinum",
                        "id": 39810051,
                        "parent": 39809549,
                        "text": "Claude-2 in some tasks albeit it&#x27;s a bit slower, Mistral on some tasks and it&#x27;s a bit faster.",
                        "time": 1711311102,
                        "type": "comment"
                    },
                    {
                        "by": "marviel",
                        "id": 39810517,
                        "parent": 39809549,
                        "text": "Claude is excellent for brainstorming, being a thought partner, general knowledge acquisition tasks, and creative writing.<p>The one mixed-bag weak spot I&#x27;ve found is in coding -- It tends to make more &quot;d&#x27;oh&quot; mistakes while coding, but comes up with more creative solutions at the same time \u00af\\_(\u30c4)_&#x2F;\u00af",
                        "time": 1711314284,
                        "type": "comment"
                    },
                    {
                        "by": "yieldcrv",
                        "id": 39810165,
                        "parent": 39809549,
                        "text": "The benchmark is Sora or whatever Open AI is working on right now or next, not trying to beat the model released a year ago and still failing<p>so when looking at it that way, the real question is what do you need? all I need is Mixtral 7x8B Q5 in an 8,000 token context window, at the moment<p>I think there are plenty of other people that can design their applications and problems around lower fidelity tools, or just pursue something else",
                        "time": 1711311883,
                        "type": "comment"
                    }
                ]
            },
            {
                "by": "jonplackett",
                "id": 39810860,
                "parent": 39809177,
                "text": "FYI it was <i>GPT-3.5 Class</i> not GPT3.5.<p>A lot of models claim to be GPT3.5 class that clearly are not in the first place.",
                "time": 1711317350,
                "type": "comment"
            },
            {
                "by": "hulium",
                "id": 39810036,
                "kids": [
                    39810134
                ],
                "parent": 39809177,
                "text": "There is also the open source FinGPT, that is claimed to beat GPT4 in some benchmarks at a fine tuning cost of $17.25.<p><a href=\"https:&#x2F;&#x2F;github.com&#x2F;AI4Finance-Foundation&#x2F;FinGPT\">https:&#x2F;&#x2F;github.com&#x2F;AI4Finance-Foundation&#x2F;FinGPT</a>",
                "time": 1711310983,
                "type": "comment",
                "comments": [
                    {
                        "by": "potatoman22",
                        "id": 39810134,
                        "kids": [
                            39811941
                        ],
                        "parent": 39810036,
                        "text": "One major advantage of FinGPT or Bloomberg&#x27;s LLM is that the embeddings produced by the model can be used for downstream prediction tasks. GPT-4 does not expose its embeddings so it cannot be used for this.",
                        "time": 1711311634,
                        "type": "comment",
                        "comments": [
                            {
                                "by": "bernawil",
                                "id": 39811941,
                                "kids": [
                                    39812799
                                ],
                                "parent": 39810134,
                                "text": "sorry, noob here trying to make sense of this: you mean you can extract embeddings from the model file or that the embeddings are available in the repo and you can just use those files?",
                                "time": 1711327992,
                                "type": "comment",
                                "comments": [
                                    {
                                        "by": "potatoman22",
                                        "id": 39812799,
                                        "parent": 39811941,
                                        "text": "Kind of. You feed the LLM the input text for your prediction, you extract the activations of the final layer of the LLM (so the weights * the input of the previous layers), then use that activation vector, or embedding, as the input for a separate model. This separate model that uses the embedding can be any classifier or regression. A common use case for this is document classification.",
                                        "time": 1711339843,
                                        "type": "comment"
                                    }
                                ]
                            }
                        ]
                    }
                ]
            },
            {
                "by": "hallqv",
                "id": 39810544,
                "kids": [
                    39810728
                ],
                "parent": 39809177,
                "text": "This discussion is so dumb - finetuning a base model costs ~$1 with LORA&#x2F;QLORA and can yield same performance as gpt-4, but at 1&#x2F;100 of the cost per token.<p>What Bloomberg did for $10M was not finetuning..",
                "time": 1711314522,
                "type": "comment",
                "comments": [
                    {
                        "by": "simonw",
                        "id": 39810728,
                        "kids": [
                            39812963,
                            39821311
                        ],
                        "parent": 39810544,
                        "text": "&quot;finetuning a base model costs ~$1 with LORA&#x2F;QLORA and can yield same performance as gpt-4, but at 1&#x2F;100 of the cost per token&quot;<p>That&#x27;s a big claim - can you back that up with any examples?",
                        "time": 1711316094,
                        "type": "comment",
                        "comments": [
                            {
                                "by": "Implicated",
                                "id": 39812963,
                                "parent": 39810728,
                                "text": "I had opened a new tab back when this comment was just a few minutes old in hopes that when I came back there was some really great blog post linked with the details on the sorcery.",
                                "time": 1711342460,
                                "type": "comment"
                            },
                            {
                                "by": "hallqv",
                                "id": 39821311,
                                "parent": 39810728,
                                "text": "<a href=\"https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;2402.00841.pdf\" rel=\"nofollow\">https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;2402.00841.pdf</a>",
                                "time": 1711401068,
                                "type": "comment"
                            }
                        ]
                    }
                ]
            },
            {
                "by": "chintler",
                "id": 39809334,
                "kids": [
                    39809560,
                    39809419
                ],
                "parent": 39809177,
                "text": "$10 Million(M), not $10 Billion(B).",
                "time": 1711306541,
                "type": "comment",
                "comments": [
                    {
                        "by": "affgrff2",
                        "id": 39809560,
                        "kids": [
                            39810247
                        ],
                        "parent": 39809334,
                        "text": "Not looking forward for the times when an AI costs as much as an aircraft carrier.",
                        "time": 1711308221,
                        "type": "comment",
                        "comments": [
                            {
                                "by": "moffkalast",
                                "id": 39810247,
                                "parent": 39809560,
                                "text": "At least with an aircraft carrier you can make your money back by holding a small country for ransom, har har.",
                                "time": 1711312504,
                                "type": "comment"
                            }
                        ]
                    },
                    {
                        "by": "CharlesW",
                        "id": 39809419,
                        "parent": 39809334,
                        "text": "Thank you, fixed! Also, direct link to paper: <a href=\"https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;2305.05862.pdf\" rel=\"nofollow\">https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;2305.05862.pdf</a>",
                        "time": 1711307251,
                        "type": "comment"
                    }
                ]
            },
            {
                "by": "thorum",
                "id": 39810232,
                "parent": 39809177,
                "text": "Note that the benchmarks used for comparison are basically measuring the model\u2019s ability to understand financial content. In other words, reading comprehension for English, just in a specific domain. It shouldn\u2019t really be surprising that a strong generalist model performs well here.<p>On the other hand, GPT-4 actually did worse on the NER task - labelling and tagging terms used in the text - vs their finetuned model. I assume the finetuned model was better at using the specific labels they were targeting.",
                "time": 1711312421,
                "type": "comment"
            },
            {
                "by": "Rustwerks",
                "id": 39810439,
                "parent": 39809177,
                "text": "<a href=\"http:&#x2F;&#x2F;www.incompleteideas.net&#x2F;IncIdeas&#x2F;BitterLesson.html\" rel=\"nofollow\">http:&#x2F;&#x2F;www.incompleteideas.net&#x2F;IncIdeas&#x2F;BitterLesson.html</a>",
                "time": 1711313745,
                "type": "comment"
            },
            {
                "by": "jebarker",
                "id": 39809551,
                "kids": [
                    39809614
                ],
                "parent": 39809177,
                "text": "How do they know GPT-4 received no specialized financial training?",
                "time": 1711308186,
                "type": "comment",
                "comments": [
                    {
                        "by": "CharlesW",
                        "id": 39809614,
                        "kids": [
                            39809669
                        ],
                        "parent": 39809551,
                        "text": "Meaning, they used the same generalized foundation model that all of us have access to, with no special fine-tuning, no retrieval-augmented generation, etc.",
                        "time": 1711308519,
                        "type": "comment",
                        "comments": [
                            {
                                "by": "jebarker",
                                "id": 39809669,
                                "kids": [
                                    39809697
                                ],
                                "parent": 39809614,
                                "text": "I don&#x27;t understand your point. To me GPT-4 is not a foundation model, it&#x27;s been highly tuned for the chat task. Nobody outside of OpenAI knows what that fine-tuning really involved. So it&#x27;s impossible to say how much finance specific data it was trained on (in pre-training or fine-tuning) or whether finance specific tasks were involved in fine-tuning.",
                                "time": 1711308839,
                                "type": "comment",
                                "comments": [
                                    {
                                        "by": "CharlesW",
                                        "id": 39809697,
                                        "kids": [
                                            39809757,
                                            39809813
                                        ],
                                        "parent": 39809669,
                                        "text": "&gt; <i>To me GPT-4 is not a foundation model\u2026</i><p>It is. <a href=\"https:&#x2F;&#x2F;www.adalovelaceinstitute.org&#x2F;resource&#x2F;foundation-models-explainer&#x2F;\" rel=\"nofollow\">https:&#x2F;&#x2F;www.adalovelaceinstitute.org&#x2F;resource&#x2F;foundation-mod...</a>",
                                        "time": 1711309013,
                                        "type": "comment",
                                        "comments": [
                                            {
                                                "deleted": true,
                                                "id": 39809757,
                                                "parent": 39809697,
                                                "time": 1711309355,
                                                "type": "comment"
                                            },
                                            {
                                                "by": "jebarker",
                                                "id": 39809813,
                                                "kids": [
                                                    39810149,
                                                    39811550
                                                ],
                                                "parent": 39809697,
                                                "text": "What I was meaning was that ChatGPT is not a foundation model since it&#x27;s been fine-tuned. Although the definition in the link is sufficiently broad you could choose to include it.<p>I can&#x27;t tell from the OpenAI docs whether it&#x27;s possible to access GPT-4 without the ChatGPT fine-tuning. If so, that&#x27;d make this result more meaningful. Otherwise, I just don&#x27;t think you can draw any great conclusions from this.",
                                                "time": 1711309673,
                                                "type": "comment",
                                                "comments": [
                                                    {
                                                        "by": "doctorpangloss",
                                                        "id": 39810149,
                                                        "parent": 39809813,
                                                        "text": "The instruction fine tuning is what manifests knowledge and reasoning.",
                                                        "time": 1711311757,
                                                        "type": "comment"
                                                    },
                                                    {
                                                        "by": "rmbyrro",
                                                        "id": 39811550,
                                                        "parent": 39809813,
                                                        "text": "GPT is general purpose, it&#x27;s not fine tuned for specific topics. A fine tuned model is tuned to a specific subject.",
                                                        "time": 1711323751,
                                                        "type": "comment"
                                                    }
                                                ]
                                            }
                                        ]
                                    }
                                ]
                            }
                        ]
                    }
                ]
            },
            {
                "by": "ldjkfkdsjnv",
                "id": 39809942,
                "kids": [
                    39810000,
                    39810404,
                    39810063
                ],
                "parent": 39809177,
                "text": "Fine tuning will disappear, no reason to invest so heavily in it. Also, most LLM code being written right now (prompts, RAG, etc) will be obsolete once the next model comes out. Anyone starting an LLM application startup is arguably wasting their time, wait until the next iteration is out. Then you will know whats possible.",
                "time": 1711310405,
                "type": "comment",
                "comments": [
                    {
                        "by": "minimaxir",
                        "id": 39810000,
                        "kids": [
                            39810057
                        ],
                        "parent": 39809942,
                        "text": "&gt; Also, most LLM code being written right now (prompts, RAG, etc) will be obsolete once the next model comes out.<p>Not true. Most prompt techniques that work on current modern LLM models will work on different or future models, although it will require a QA pass for any regressions.",
                        "time": 1711310718,
                        "type": "comment",
                        "comments": [
                            {
                                "by": "ldjkfkdsjnv",
                                "id": 39810057,
                                "kids": [
                                    39811061,
                                    39810175,
                                    39810398,
                                    39810171
                                ],
                                "parent": 39810000,
                                "text": "Yeah they will work, but they will also be unnecessary. You will also bake all sorts of logic into your application that will be solved natively on the stronger model. If you believe in the scaling theory, then writing LLM applications is non sensical.",
                                "time": 1711311119,
                                "type": "comment",
                                "comments": [
                                    {
                                        "by": "kergonath",
                                        "id": 39811061,
                                        "parent": 39810057,
                                        "text": "&gt;  If you believe in the scaling theory, then writing LLM applications is non sensical.<p>But not doing it is an opportunity cost. You don\u2019t built skills, tooling and experience, and you don\u2019t get feedback on what works and where you should go.<p>It\u2019s like computers in the 1990s: there\u2019s always a better one 6 months away, so if you wait for it to stabilise, then you don\u2019t do anything for a decade. Just enjoy the ride, bearing in mind that things change very fast and some things will be obsolete next year.",
                                        "time": 1711319097,
                                        "type": "comment"
                                    },
                                    {
                                        "by": "mlyle",
                                        "id": 39810175,
                                        "parent": 39810057,
                                        "text": "&gt; Yeah they will work, but they will also be unnecessary. You will also bake all sorts of logic into your application that will be solved natively on the stronger model.<p>I think that a whole lot of what I do in prompt engineering is what&#x27;s necessary to fully specify the output that I want.<p>A newer model may be less finicky, so I have a higher chance of getting it to work on the first try (and it&#x27;s more reliable afterwards), but it&#x27;s hard for me to imagine it needing a whole lot less prompt.",
                                        "time": 1711311972,
                                        "type": "comment"
                                    },
                                    {
                                        "by": "Xenoamorphous",
                                        "id": 39810398,
                                        "kids": [
                                            39811112,
                                            39810436
                                        ],
                                        "parent": 39810057,
                                        "text": "How will a more powerful model be a substitute for RAG, which is usually used with private data that won\u2019t be present in any training dataset?",
                                        "time": 1711313409,
                                        "type": "comment",
                                        "comments": [
                                            {
                                                "by": "kergonath",
                                                "id": 39811112,
                                                "parent": 39810398,
                                                "text": "One of the idea is to just stuff all the documents in the prompt, which still keeps them private but avoids having to faff around with chunking, embedding, and vector stores. That\u2019s not really the end of RAG as a concept, but it would change all the current tooling and infrastructure we built for it.<p>I don\u2019t think RAG is going away, at least not because of this. But I expect new techniques to become available fairly regularly.",
                                                "time": 1711319432,
                                                "type": "comment"
                                            },
                                            {
                                                "by": "ldjkfkdsjnv",
                                                "id": 39810436,
                                                "parent": 39810398,
                                                "text": "I just think that the capability of the model could radically change, such that however you structured your RAG pipeline, might need to be rewritten. More general problems could be solved by the model, that you were solving with some complicated contraption of prompts.",
                                                "time": 1711313734,
                                                "type": "comment"
                                            }
                                        ]
                                    },
                                    {
                                        "deleted": true,
                                        "id": 39810171,
                                        "parent": 39810057,
                                        "time": 1711311940,
                                        "type": "comment"
                                    }
                                ]
                            }
                        ]
                    },
                    {
                        "by": "rkagerer",
                        "id": 39810404,
                        "kids": [
                            39810503
                        ],
                        "parent": 39809942,
                        "text": "&quot;Don&#x27;t buy a computer today, because the faster one is coming out tomorrow&quot;",
                        "time": 1711313493,
                        "type": "comment",
                        "comments": [
                            {
                                "by": "simonw",
                                "id": 39810503,
                                "parent": 39810404,
                                "text": "Don&#x27;t buy a computer today with a six month delivery lead time, because there&#x27;s a company that releases computers with a same-day lead time with several improved models coming out next week.",
                                "time": 1711314160,
                                "type": "comment"
                            }
                        ]
                    },
                    {
                        "by": "treprinum",
                        "id": 39810063,
                        "parent": 39809942,
                        "text": "OpenAI-related startups are likely using GPT-5 already. Waiting it out won&#x27;t help other startups, they will be too far behind.",
                        "time": 1711311163,
                        "type": "comment"
                    }
                ]
            },
            {
                "by": "__loam",
                "id": 39809810,
                "kids": [
                    39809903
                ],
                "parent": 39809177,
                "text": "GPT-4 cost like $100m so I don&#x27;t think this is surprising?",
                "time": 1711309657,
                "type": "comment",
                "comments": [
                    {
                        "by": "rafaelero",
                        "id": 39809903,
                        "kids": [
                            39809937
                        ],
                        "parent": 39809810,
                        "text": "A lot of organizations still think they should have their own [finetuned] model to provide a custom experience to their users, so that may come as a surprise for them.",
                        "time": 1711310181,
                        "type": "comment",
                        "comments": [
                            {
                                "by": "ShamelessC",
                                "id": 39809937,
                                "kids": [
                                    39810035,
                                    39810169
                                ],
                                "parent": 39809903,
                                "text": "Scaling laws basically guarantee that a sufficiently larger general model will usually beat a smaller specialist model. The misunderstanding is perhaps acceptable but the headline here is essentially restating a well known property of deep learning.",
                                "time": 1711310372,
                                "type": "comment",
                                "comments": [
                                    {
                                        "by": "__loam",
                                        "id": 39810035,
                                        "parent": 39809937,
                                        "text": "How long ago was the Bitter Lesson written?",
                                        "time": 1711310977,
                                        "type": "comment"
                                    },
                                    {
                                        "by": "mistrial9",
                                        "id": 39810169,
                                        "parent": 39809937,
                                        "text": "contrarian view - how these models actually operate at runtime is not understood.. the formal research papers repeat that over and over again. Therefore, there will be new twists and turns as these models evolve. With <i>current</i> technology stacks, the &quot;bitter lesson&quot; is looking good, yes. Will it always be so? no way to know it.",
                                        "time": 1711311921,
                                        "type": "comment"
                                    }
                                ]
                            }
                        ]
                    }
                ]
            },
            {
                "deleted": true,
                "id": 39810907,
                "parent": 39809177,
                "time": 1711317724,
                "type": "comment"
            },
            {
                "by": "atleastoptimal",
                "id": 39810838,
                "parent": 39809177,
                "text": "Yeah, the equivalent is: would it be better for a quant firm to spend 200 thousand dollars giving a first-class specialist education to a guy with an IQ of 95, or just hiring a guy with an IQ of 150 straight out of college.",
                "time": 1711317174,
                "type": "comment"
            }
        ]
    },
    {
        "by": "mfiguiere",
        "descendants": 0,
        "id": 39822589,
        "score": 1,
        "time": 1711410390,
        "title": "Learning the greatest common divisor: explaining transformer predictions",
        "type": "story",
        "url": "https://arxiv.org/abs/2308.15594"
    },
    {
        "by": "geox",
        "descendants": 0,
        "id": 39822004,
        "score": 1,
        "time": 1711406046,
        "title": "Quality, Accuracy, and Bias in ChatGPT-Based Summarization of Medical Abstracts",
        "type": "story",
        "url": "https://www.annfammed.org/content/22/2/113"
    },
    {
        "by": "CharlesW",
        "descendants": 0,
        "id": 39820679,
        "score": 1,
        "time": 1711397046,
        "title": "What Should Data Science Education Do with Large Language Models?",
        "type": "story",
        "url": "https://arxiv.org/abs/2307.02792"
    },
    {
        "by": "CharlesW",
        "descendants": 67,
        "id": 39820639,
        "kids": [
            39822179,
            39821924,
            39822235,
            39822249,
            39821832,
            39821929,
            39821769,
            39822114,
            39822043,
            39821758
        ],
        "score": 55,
        "time": 1711396824,
        "title": "Is GPT-4 a good data analyst? (2023)",
        "type": "story",
        "url": "https://arxiv.org/abs/2305.15038",
        "comments": [
            {
                "by": "cstanley",
                "id": 39822179,
                "parent": 39820639,
                "text": "This paper was published 154 days ago, probably a year since the authors did the experiment. Sooo much has happened since then! This showed already that GPT4 is pretty darn good analyst.<p>All this real-world complexity can be tamed by stuffing the prompt with a ton of relevant context and an amazing prompt engine. We&#x27;ll have bots that autonomously query the database hundreds of times building a 5 page &quot;deep-dive&quot; analytics report in minutes.<p>At least that&#x27;s what we&#x27;re trying at patterns.app.",
                "time": 1711407375,
                "type": "comment"
            },
            {
                "by": "andy99",
                "id": 39821924,
                "parent": 39820639,
                "text": "May 2023 using GPT-4-0314.",
                "time": 1711405512,
                "type": "comment"
            },
            {
                "by": "elietoubi",
                "id": 39822235,
                "parent": 39820639,
                "text": "If anyone is interested i built for myself and open sourced parse.dev<p><a href=\"https:&#x2F;&#x2F;github.com&#x2F;ParseDev&#x2F;parsedev\">https:&#x2F;&#x2F;github.com&#x2F;ParseDev&#x2F;parsedev</a>",
                "time": 1711407729,
                "type": "comment"
            },
            {
                "by": "lutusp",
                "id": 39822249,
                "kids": [
                    39822475
                ],
                "parent": 39820639,
                "text": "&gt; However, we are still at a stage of divergent opinions without any definitive conclusion.<p>Okay, I know picking people&#x27;s sentences apart has fallen out of fashion, but:<p>&quot;Divergent opinions&quot; are ... opinions.\nA &quot;definitive conclusion&quot; is ... a conclusion.<p>I see more examples, but I wanted to make a point: I miss the days when fewer words conveyed more meaning. From the classic <a href=\"https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;The_Elements_of_Style\" rel=\"nofollow\">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;The_Elements_of_Style</a>: &quot;Make every word count.&quot;<p>About brevity of expression, I must add this (possibly apocryphal) story about Ernest Hemingway. In the 1920s Hemingway and his Paris friends had a contest: who could write the shortest readable short story? Hemingway won with this entry:<p>For sale. Baby shoes. Never worn.",
                "time": 1711407845,
                "type": "comment",
                "comments": [
                    {
                        "by": "apineda",
                        "id": 39822475,
                        "parent": 39822249,
                        "text": "From an alternative viewpoint, this could be seen as descriptive of a community. Opinions could be shared or not, hence &quot;divergent&quot; as an adjective to describe the community. Similar with conclusions people have drawn and &quot;definitive&quot; may refer to a larger consensus among the community. Fun to think about.",
                        "time": 1711409383,
                        "type": "comment"
                    }
                ]
            },
            {
                "by": "greenavocado",
                "id": 39821832,
                "kids": [
                    39821934,
                    39822288,
                    39822333
                ],
                "parent": 39820639,
                "text": "Even the latest commercial LLMs are happy to confidently bullshit about what they think is in published research even if they provide citations. Often the citations themselves are slightly corrupted. I actually verify each LLM claim so I know this is happening a lot. Occasionally they are complete fabrications. It really varies by research topic. Its really bad in esoteric research areas. They even acknowledge the paper was actually about something else if you call them out on it. What a disaster. LLMs are still useful for information retrieval and exploration as long as you understand you are having a conversation with a habitual liar &#x2F; expert beginner and adjust your prompts and expectations accordingly.",
                "time": 1711404835,
                "type": "comment",
                "comments": [
                    {
                        "by": "bongodongobob",
                        "id": 39821934,
                        "parent": 39821832,
                        "text": "Unintuitively, I think you&#x27;ll probably end up with better answers if you don&#x27;t ask for citations. The vast majority of its training isn&#x27;t white papers so you&#x27;re artificially constraining its &quot;imagination&quot; to the cited sources space. I find the more constraints you add, the worse your answers are.",
                        "time": 1711405644,
                        "type": "comment"
                    },
                    {
                        "by": "notnullorvoid",
                        "id": 39822288,
                        "parent": 39821832,
                        "text": "&gt; They even acknowledge the paper was actually about something else if you call them out on it.<p>For clarity is not really acknowledging it made a mistake. &quot;Calling out&quot; an LLM&#x27;s mistake just leads to the next most likely text to be something that sounds like an acknowledgement of a mistake, but the same is likely to happen if the LLM generated a correct response and you respond claiming that it&#x27;s incorrect.",
                        "time": 1711408090,
                        "type": "comment"
                    },
                    {
                        "by": "jiggawatts",
                        "id": 39822333,
                        "parent": 39821832,
                        "text": "&gt; What a disaster.<p>Using tool inappropriately leads to suboptimal outcomes -- news at 11.<p>A good mental model is that an LLM is a blurry JPEG of the Internet.<p>You sound like a scientist, right? You reference &quot;published research&quot;, after all.<p>What would your opinion be of a researcher measuring the exact values of the pixels of a JPEG image instead of the RAW sensor data?",
                        "time": 1711408329,
                        "type": "comment"
                    }
                ]
            },
            {
                "by": "mritchie712",
                "id": 39821929,
                "kids": [
                    39822450,
                    39822102
                ],
                "parent": 39820639,
                "text": "reminds me of this tweet [0]<p><pre><code>    Them: Can you just quickly pull this data for me?\n\n    Me: Sure, let me just: \n\n    SELECT * FROM some_ideal_clean_and_pristine.table_that_you_think_exists\n\n</code></pre>\nGPT-4 is good on a single CSV, but breaks down quickly applied to a real database &#x2F; data warehouse. I know they&#x27;re using multiple tables in the paper, but it appears to be a pristine schema that&#x27;s very easy to reason about. In the real world, when you&#x27;re trying to join postgres to hubspot and stripe data, an LLM isn&#x27;t able to write the SQL from scratch get the right answer.<p>We&#x27;re working on an approach using a semantic layer at <a href=\"https:&#x2F;&#x2F;www.definite.app&#x2F;\" rel=\"nofollow\">https:&#x2F;&#x2F;www.definite.app&#x2F;</a> if you&#x27;re interested in this sort of thing.<p>0 - <a href=\"https:&#x2F;&#x2F;twitter.com&#x2F;sethrosen&#x2F;status&#x2F;1252291581320757249?lang=en\" rel=\"nofollow\">https:&#x2F;&#x2F;twitter.com&#x2F;sethrosen&#x2F;status&#x2F;1252291581320757249?lan...</a>",
                "time": 1711405558,
                "type": "comment",
                "comments": [
                    {
                        "by": "neeleshs",
                        "id": 39822450,
                        "parent": 39821929,
                        "text": "It goes beyond just joining postgres to hubspot and stripe even when humans are doing it. Typos in source systems, duplicative data, unwarranted prefixes, suffixes, stuff you don&#x27;t care about, columns named c0,c1,c2 etc.<p>A semantic layer is just really all about defining data models in the domain of interest. It&#x27;s the hardest part in dealing with data strategies, very manual, very company and process and history specific.<p>Once it&#x27;s defined, the next set of tasks is to make sure that the data in the model is correct and coherent. And only then, querying this data, applying ML etc start becoming worthwhile.<p>We at <a href=\"https:&#x2F;&#x2F;syncari.com\" rel=\"nofollow\">https:&#x2F;&#x2F;syncari.com</a> take the centralized data model centric approach. \n<a href=\"https:&#x2F;&#x2F;www.definite.app&#x2F;\" rel=\"nofollow\">https:&#x2F;&#x2F;www.definite.app&#x2F;</a> also looks very cool!",
                        "time": 1711409125,
                        "type": "comment"
                    },
                    {
                        "deleted": true,
                        "id": 39822102,
                        "parent": 39821929,
                        "time": 1711406849,
                        "type": "comment"
                    }
                ]
            },
            {
                "by": "kva",
                "id": 39821769,
                "kids": [
                    39821856,
                    39821849,
                    39822449,
                    39821828,
                    39821875,
                    39822021,
                    39822105
                ],
                "parent": 39820639,
                "text": "Given the right prompt, I&#x27;m sure it is....but when do users ever enter the right prompt? :(",
                "time": 1711404364,
                "type": "comment",
                "comments": [
                    {
                        "by": "richardw",
                        "id": 39821856,
                        "kids": [
                            39822287,
                            39822236
                        ],
                        "parent": 39821769,
                        "text": "You can&#x27;t depend on it at all.  I mean, you can use it for a tremendous amount of work, but until there is a way to constrain the bullshit LLM&#x27;s can&#x27;t be used for anything that requires a correct answer.<p>The terms &quot;depend&quot; and &quot;require&quot; there are the hard versions. You can&#x27;t send people to the moon on the outputs of LLM&#x27;s.",
                        "time": 1711405099,
                        "type": "comment",
                        "comments": [
                            {
                                "by": "roenxi",
                                "id": 39822287,
                                "parent": 39821856,
                                "text": "I think we&#x27;ll solve that problem for LLMs before we solve it for humans. Data analysts produce a lot of garbage; data work is really hard. In fact, it isn&#x27;t uncommon in my experience for the data analyst to be the only person saying &quot;hang on, the quality of this reporting isn&#x27;t good enough for the decisions you&#x27;re making from it!&quot; - because they understand what useful information looks like and the company doesn&#x27;t have much of it.",
                                "time": 1711408089,
                                "type": "comment"
                            },
                            {
                                "by": "paulsutter",
                                "id": 39822236,
                                "kids": [
                                    39822437,
                                    39822301
                                ],
                                "parent": 39821856,
                                "text": "This is sheer cope<p>The tools are good for certain tasks and getting better. Master these tools and be ready for what released in the coming months and years<p>You are either at the center turning the wheel, or you\u2019re on the outside getting spun",
                                "time": 1711407737,
                                "type": "comment",
                                "comments": [
                                    {
                                        "by": "richardw",
                                        "id": 39822437,
                                        "parent": 39822236,
                                        "text": "You haven&#x27;t the vaguest fucking idea what I&#x27;m doing with the tools so put up a logical argument on the facts instead of just generating tokens in some way that attempts to play the person and not the ball.<p>Here, argue with Yann, who makes a statement about how language isn&#x27;t enough to produce a mind:\n<a href=\"https:&#x2F;&#x2F;twitter.com&#x2F;ylecun&#x2F;status&#x2F;1768353714794901530\" rel=\"nofollow\">https:&#x2F;&#x2F;twitter.com&#x2F;ylecun&#x2F;status&#x2F;1768353714794901530</a>",
                                        "time": 1711409040,
                                        "type": "comment"
                                    },
                                    {
                                        "by": "Fauntleroy",
                                        "id": 39822301,
                                        "parent": 39822236,
                                        "text": "These tools are great at generating text responses, some of which are usable, but not analysis. We&#x27;re actually far from that. I&#x27;m not sure why some people are out here pretending this is not the case.",
                                        "time": 1711408156,
                                        "type": "comment"
                                    }
                                ]
                            }
                        ]
                    },
                    {
                        "by": "williamcotton",
                        "id": 39821849,
                        "parent": 39821769,
                        "text": "Didn\u2019t you get the memo? If you\u2019re holding the hammer by the head and wondering why it isn\u2019t driving the nail in that it is clearly the fault of the  manufacturer.<p>There\u2019s even a handy aphorism to remind you that the user is never to blame: \u201cYou\u2019re holding it wrong.\u201d<p>Jokes aside, I wonder what the general writing abilities and communication skills are for people that cannot for the life of them get usable results from an LLM.",
                        "time": 1711405010,
                        "type": "comment"
                    },
                    {
                        "by": "dimask",
                        "id": 39822449,
                        "parent": 39821769,
                        "text": "If you already know the right answer it is actually easy",
                        "time": 1711409112,
                        "type": "comment"
                    },
                    {
                        "by": "viscanti",
                        "id": 39821828,
                        "kids": [
                            39821950,
                            39822064
                        ],
                        "parent": 39821769,
                        "text": "OpenAI should make something so that people can enter their prompt and maybe even drop in a knowledge base and then share with anyone else who wants that functionality.",
                        "time": 1711404812,
                        "type": "comment",
                        "comments": [
                            {
                                "by": "snoman",
                                "id": 39821950,
                                "kids": [
                                    39822072
                                ],
                                "parent": 39821828,
                                "text": "That\u2019s ptetty close to what GPTs are, with the exception of knowledge bases.<p>There\u2019s more to it, but the tooling to create a GPT is basically a hand-holding mechanism to create a prompt.",
                                "time": 1711405726,
                                "type": "comment",
                                "comments": [
                                    {
                                        "by": "gregorymichael",
                                        "id": 39822072,
                                        "parent": 39821950,
                                        "text": "GPTs have the knowledge base too. (Mixed results though)",
                                        "time": 1711406605,
                                        "type": "comment"
                                    }
                                ]
                            },
                            {
                                "by": "wolpoli",
                                "id": 39822064,
                                "parent": 39821828,
                                "text": "Would the final product be similar to Github copilot, but for prompt?",
                                "time": 1711406539,
                                "type": "comment"
                            }
                        ]
                    },
                    {
                        "deleted": true,
                        "id": 39821875,
                        "parent": 39821769,
                        "time": 1711405230,
                        "type": "comment"
                    },
                    {
                        "by": "SV_BubbleTime",
                        "id": 39822021,
                        "parent": 39821769,
                        "text": "\u201c42\u201d",
                        "time": 1711406150,
                        "type": "comment"
                    },
                    {
                        "deleted": true,
                        "id": 39822105,
                        "parent": 39821769,
                        "time": 1711406867,
                        "type": "comment"
                    }
                ]
            },
            {
                "deleted": true,
                "id": 39822114,
                "parent": 39820639,
                "time": 1711406923,
                "type": "comment"
            },
            {
                "by": "dangoodmanUT",
                "id": 39822043,
                "kids": [
                    39822106
                ],
                "parent": 39820639,
                "text": "Not on useful datasets in real places",
                "time": 1711406340,
                "type": "comment",
                "comments": [
                    {
                        "deleted": true,
                        "id": 39822106,
                        "parent": 39822043,
                        "time": 1711406884,
                        "type": "comment"
                    }
                ]
            },
            {
                "by": "einpoklum",
                "id": 39821758,
                "kids": [
                    39821827,
                    39822038
                ],
                "parent": 39820639,
                "text": "I was somewhat put off by the abstract:<p>&gt; LLMs... have demonstrated their powerful capabilities in ... context understanding, code generation, language generation, data storytelling, etc.,<p>LLMs have not demonstrated understanding (in fact, one could argue that they are fundamentally incapable of understanding); they have only AFAICT demonstrated the ability to generate boilerplate-ish code; &quot;language generation&quot; is too general a task to claim that LLMs have succeeded in; and as for data storytelling I don&#x27;t know, but they can spin yarns. The problems is that those yarns are often divorced from reality; see:<p><a href=\"https:&#x2F;&#x2F;www.ibm.com&#x2F;topics&#x2F;ai-hallucinations\" rel=\"nofollow\">https:&#x2F;&#x2F;www.ibm.com&#x2F;topics&#x2F;ai-hallucinations</a><p>--------<p>Leafing through the paper, and specifically tables 6 and 7, I don&#x27;t believe their conclusion, that &quot;GPT-4 can perform comparable [sic] to a data analyst&quot;, is well-founded.",
                "time": 1711404323,
                "type": "comment",
                "comments": [
                    {
                        "by": "mewpmewp2",
                        "id": 39821827,
                        "kids": [
                            39822345,
                            39822337,
                            39822152,
                            39821860
                        ],
                        "parent": 39821758,
                        "text": "I don&#x27;t even understand what understanding exactly means, perhaps anyone who understands it, can enlighten me?<p>Do I, myself understand? Stand under what exactly? What is that supposed to mean?",
                        "time": 1711404798,
                        "type": "comment",
                        "comments": [
                            {
                                "by": "modriano",
                                "id": 39822345,
                                "kids": [
                                    39822518
                                ],
                                "parent": 39821827,
                                "text": "To understand means a few things, but they all essentially boil down to having a correct (or at least correct enough to be useful for your usecase(s)) model for something in your head.<p>Have you told someone something like &quot;no, don&#x27;t do it that way because &lt;insert non-obvious downstream problem&gt;, instead, do &lt;insert alternative strategy that achieves better outcomes&gt;&quot;? That&#x27;s an artifact of understanding and of the model you&#x27;ve developed for that thing.<p>It&#x27;s well described as a mixture of knowledge and wisdom, and is essentially the property of knowing the effect that pulling a lever will cause, coupled with good judgement about how, when, and why to pull the lever.",
                                "time": 1711408427,
                                "type": "comment",
                                "comments": [
                                    {
                                        "by": "mewpmewp2",
                                        "id": 39822518,
                                        "parent": 39822345,
                                        "text": "But GPT-4 has told me that as well?<p>Usually in a bit more polite way.<p>That my approach is a &quot;novel&quot; and an &quot;interesting&quot; approach, hinting that it&#x27;s really probably not the best option here.",
                                        "time": 1711409688,
                                        "type": "comment"
                                    }
                                ]
                            },
                            {
                                "by": "richardw",
                                "id": 39822337,
                                "kids": [
                                    39822485
                                ],
                                "parent": 39821827,
                                "text": "The fact that you ask that is in many ways the difference. You feel there\u2019s a limitation in your knowledge of the term \u201cunderstand\u201d and its use in this context and would like clarification before you\u2019re more certain, either way. At some point either enough information arrives to convince you, or you decide it\u2019s not true. Whatever that process and internal states are, is something GPT can\u2019t do.  It\u2019ll 100% confidently produce something and be fully rewarded that it chose tokens that humans would most likely choose given the preceding tokens. There\u2019s no \u201caha\u201d.",
                                "time": 1711408356,
                                "type": "comment",
                                "comments": [
                                    {
                                        "by": "mewpmewp2",
                                        "id": 39822485,
                                        "parent": 39822337,
                                        "text": "But it frustratingly, frequently tells me it doesn&#x27;t have enough data or other XYZ reasons to why it can&#x27;t answer my weird questions.",
                                        "time": 1711409459,
                                        "type": "comment"
                                    }
                                ]
                            },
                            {
                                "by": "advael",
                                "id": 39822152,
                                "kids": [
                                    39822321,
                                    39822245
                                ],
                                "parent": 39821827,
                                "text": "Solipsism is truly the best fully-general counterargument",
                                "time": 1711407216,
                                "type": "comment",
                                "comments": [
                                    {
                                        "deleted": true,
                                        "id": 39822321,
                                        "parent": 39822152,
                                        "time": 1711408272,
                                        "type": "comment"
                                    },
                                    {
                                        "by": "mewpmewp2",
                                        "id": 39822245,
                                        "kids": [
                                            39822296
                                        ],
                                        "parent": 39822152,
                                        "text": "To AI? Or that you are not a NPC?",
                                        "time": 1711407823,
                                        "type": "comment",
                                        "comments": [
                                            {
                                                "by": "advael",
                                                "id": 39822296,
                                                "kids": [
                                                    39822371
                                                ],
                                                "parent": 39822245,
                                                "text": "To anything, that&#x27;s what &quot;fully-general&quot; means",
                                                "time": 1711408131,
                                                "type": "comment",
                                                "comments": [
                                                    {
                                                        "by": "mewpmewp2",
                                                        "id": 39822371,
                                                        "kids": [
                                                            39822404
                                                        ],
                                                        "parent": 39822296,
                                                        "text": "So you are a bot?",
                                                        "time": 1711408581,
                                                        "type": "comment",
                                                        "comments": [
                                                            {
                                                                "by": "advael",
                                                                "id": 39822404,
                                                                "kids": [
                                                                    39822463
                                                                ],
                                                                "parent": 39822371,
                                                                "text": "I mean from your perspective I&#x27;m just a name making more words on your screen, right? Don&#x27;t worry too much about it, buddy, you&#x27;re doin&#x27; great :)",
                                                                "time": 1711408760,
                                                                "type": "comment",
                                                                "comments": [
                                                                    {
                                                                        "by": "mewpmewp2",
                                                                        "id": 39822463,
                                                                        "kids": [
                                                                            39822604
                                                                        ],
                                                                        "parent": 39822404,
                                                                        "text": "Haha, you are funny! What&#x27;s the weather tomorrow? Please also remind me tomorrow to put my gym clothes to washer and dry them after.",
                                                                        "time": 1711409250,
                                                                        "type": "comment",
                                                                        "comments": [
                                                                            {
                                                                                "by": "advael",
                                                                                "id": 39822604,
                                                                                "parent": 39822463,
                                                                                "text": "I can&#x27;t spoil the weather tomorrow (it&#x27;s a major plot point) but I can tell you that fortune has been tweaked to favor the bold by an additional 10%, just for tomorrow.<p>Laundry service is complimentary, but our records show that you haven&#x27;t registered your home. Would you like to register your home address at this time?",
                                                                                "time": 1711410507,
                                                                                "type": "comment"
                                                                            }
                                                                        ]
                                                                    }
                                                                ]
                                                            }
                                                        ]
                                                    }
                                                ]
                                            }
                                        ]
                                    }
                                ]
                            },
                            {
                                "by": "ocbyc",
                                "id": 39821860,
                                "kids": [
                                    39821915,
                                    39821908,
                                    39821982,
                                    39822141,
                                    39821966
                                ],
                                "parent": 39821827,
                                "text": "Transformers are just pattern matching. So if you write &quot;give me a list of dog names&quot; it knows that &quot;Spot&quot; should be in that result set. Even though it doesn&#x27;t really know what a dog is, a list is, or what a spot is.",
                                "time": 1711405116,
                                "type": "comment",
                                "comments": [
                                    {
                                        "by": "rafaelero",
                                        "id": 39821915,
                                        "kids": [
                                            39822368,
                                            39822205
                                        ],
                                        "parent": 39821860,
                                        "text": "&gt; Transformers are just pattern matching.<p>That&#x27;s trivially true. The question is: are we any different?",
                                        "time": 1711405453,
                                        "type": "comment",
                                        "comments": [
                                            {
                                                "by": "richardw",
                                                "id": 39822368,
                                                "kids": [
                                                    39822584,
                                                    39822492
                                                ],
                                                "parent": 39821915,
                                                "text": "I think so. You ask that question because you\u2019re interrogating the position, not because 1000 humans have asked that question in similar situations.<p>You and I know there\u2019s a truth and we\u2019d like to find it. The GPT is just happy (I.e. rewarded) to produce frequently used tokens.",
                                                "time": 1711408559,
                                                "type": "comment",
                                                "comments": [
                                                    {
                                                        "by": "parpfish",
                                                        "id": 39822584,
                                                        "parent": 39822368,
                                                        "text": "but maybe that feeling of &#x27;looking for truth&#x27; is just what happens when you&#x27;re doing pattern matching on the text embeddings?",
                                                        "time": 1711410364,
                                                        "type": "comment"
                                                    },
                                                    {
                                                        "by": "mewpmewp2",
                                                        "id": 39822492,
                                                        "kids": [
                                                            39822523
                                                        ],
                                                        "parent": 39822368,
                                                        "text": "And I&#x27;m just happy to perform actions that will make me survive and reproduce?",
                                                        "time": 1711409520,
                                                        "type": "comment",
                                                        "comments": [
                                                            {
                                                                "by": "richardw",
                                                                "id": 39822523,
                                                                "kids": [
                                                                    39822608
                                                                ],
                                                                "parent": 39822492,
                                                                "text": "Most likely, unless you meditate a lot. Sometimes you&#x27;ll take a bullet to save other people. Sometimes you&#x27;ll drink yourself into a state that doesn&#x27;t help you survive or reproduce. Or you&#x27;ll write on a forum anonymously that doesn&#x27;t help with survival or reproduction because it&#x27;s enjoyable, makes you think, or you&#x27;re addicted. Who knows :)",
                                                                "time": 1711409740,
                                                                "type": "comment",
                                                                "comments": [
                                                                    {
                                                                        "by": "mewpmewp2",
                                                                        "id": 39822608,
                                                                        "parent": 39822523,
                                                                        "text": "You are even better at analyzing me than GPT-4.",
                                                                        "time": 1711410519,
                                                                        "type": "comment"
                                                                    }
                                                                ]
                                                            }
                                                        ]
                                                    }
                                                ]
                                            },
                                            {
                                                "by": "parpfish",
                                                "id": 39822205,
                                                "kids": [
                                                    39822271
                                                ],
                                                "parent": 39821915,
                                                "text": "I approach LLMs with the perspective that \u201cmaybe this demonstrates that we humans are all just stochastic parrots?\u201dand we should have the null hypothesis that humans are just pattern matchers.",
                                                "time": 1711407551,
                                                "type": "comment",
                                                "comments": [
                                                    {
                                                        "by": "mewpmewp2",
                                                        "id": 39822271,
                                                        "parent": 39822205,
                                                        "text": "This is the way I perceive my thoughts. I don&#x27;t know what I&#x27;m going to think of beforehand or in advance, these could all be stochastic &quot;tokens&quot; based on what I&#x27;ve observed in my life.<p>So of course I feel a bit offended when people claim LLMs are just stochastic parrots, because it doesn&#x27;t feel to me, that I&#x27;m specifically any better?<p>My thoughts - they just happen, and sometimes not in my favor - I have had times of depression, I didn&#x27;t have control over my thoughts. Neither do I have now, but at least I am in a better place. Because the &quot;happiness&quot; chemicals are regulated to be in a more favorable state to me for various different factors.<p>I didn&#x27;t know what I was going to comment in response to your comment, I was just streaming my conscious.",
                                                        "time": 1711408022,
                                                        "type": "comment"
                                                    }
                                                ]
                                            }
                                        ]
                                    },
                                    {
                                        "by": "bongodongobob",
                                        "id": 39821908,
                                        "kids": [
                                            39822220,
                                            39822008
                                        ],
                                        "parent": 39821860,
                                        "text": "I don&#x27;t think that&#x27;s true. They clearly group related things together and seem to be able to create concepts that aren&#x27;t specifically in the training data. For example, it will figure out the different features of a face, eyes, nose, mouth even if you don&#x27;t explicitly tell it what those are. Which is why they are so cool.",
                                        "time": 1711405424,
                                        "type": "comment",
                                        "comments": [
                                            {
                                                "by": "zeusk",
                                                "id": 39822220,
                                                "kids": [
                                                    39822383
                                                ],
                                                "parent": 39821908,
                                                "text": "Most of that magic comes from embedding no? which is clustering things by their relation in some N-dimensional space",
                                                "time": 1711407636,
                                                "type": "comment",
                                                "comments": [
                                                    {
                                                        "by": "bongodongobob",
                                                        "id": 39822383,
                                                        "parent": 39822220,
                                                        "text": "Exactly. It figures that out on its own. That&#x27;s what &quot;understanding&quot; looks like in this context, imo.",
                                                        "time": 1711408637,
                                                        "type": "comment"
                                                    }
                                                ]
                                            },
                                            {
                                                "by": "mewpmewp2",
                                                "id": 39822008,
                                                "parent": 39821908,
                                                "text": "They are cool, but then you are also cool.",
                                                "time": 1711406054,
                                                "type": "comment"
                                            }
                                        ]
                                    },
                                    {
                                        "by": "mewpmewp2",
                                        "id": 39821982,
                                        "kids": [
                                            39822452
                                        ],
                                        "parent": 39821860,
                                        "text": "How would I test whether I &quot;know&quot; or &quot;understand&quot; what a dog is?",
                                        "time": 1711405918,
                                        "type": "comment",
                                        "comments": [
                                            {
                                                "by": "notahacker",
                                                "id": 39822452,
                                                "kids": [
                                                    39822499
                                                ],
                                                "parent": 39821982,
                                                "text": "Oh, that&#x27;s easy, we just give the dog a keyboard and see if you accurately identify it&#x27;s a dog from  your text based interactions ;-)",
                                                "time": 1711409163,
                                                "type": "comment",
                                                "comments": [
                                                    {
                                                        "by": "mewpmewp2",
                                                        "id": 39822499,
                                                        "parent": 39822452,
                                                        "text": "Are you calling me a dog?",
                                                        "time": 1711409588,
                                                        "type": "comment"
                                                    }
                                                ]
                                            }
                                        ]
                                    },
                                    {
                                        "by": "inopinatus",
                                        "id": 39822141,
                                        "kids": [
                                            39822202
                                        ],
                                        "parent": 39821860,
                                        "text": "Even this seems too grand a claim. I\u2019d water it down thus: the LLM encodes that the token(s) for \u201cSpot\u201d are probabilistically plausible in the ensuing output.",
                                        "time": 1711407122,
                                        "type": "comment",
                                        "comments": [
                                            {
                                                "by": "bongodongobob",
                                                "id": 39822202,
                                                "kids": [
                                                    39822212
                                                ],
                                                "parent": 39822141,
                                                "text": "...because it understands what a dog name is. Why wouldn&#x27;t you see Gary or Florence in that list? How does it know those aren&#x27;t dog names?<p>You can&#x27;t be suggesting it has memorized relationships between all concepts, the model would be enormous.<p>So clearly, there is something else going on. It&#x27;s able to encode concepts&#x2F;ideas.",
                                                "time": 1711407529,
                                                "type": "comment",
                                                "comments": [
                                                    {
                                                        "by": "inopinatus",
                                                        "id": 39822212,
                                                        "kids": [
                                                            39822253
                                                        ],
                                                        "parent": 39822202,
                                                        "text": "The model <i>is</i> enormous, and N-dimensional for very high N. But the model remains insufficiently enormous for understanding, and moreover, the model cannot observe itself and adjust.<p>Ask an LLM to extrapolate, see any semblance of reason collapse.",
                                                        "time": 1711407592,
                                                        "type": "comment",
                                                        "comments": [
                                                            {
                                                                "by": "mewpmewp2",
                                                                "id": 39822253,
                                                                "parent": 39822212,
                                                                "text": "Extrapolate what?",
                                                                "time": 1711407890,
                                                                "type": "comment"
                                                            }
                                                        ]
                                                    }
                                                ]
                                            }
                                        ]
                                    },
                                    {
                                        "by": "ALittleLight",
                                        "id": 39821966,
                                        "kids": [
                                            39822067
                                        ],
                                        "parent": 39821860,
                                        "text": "Can you describe a test that would separate trivial pattern matching from true understanding?",
                                        "time": 1711405822,
                                        "type": "comment",
                                        "comments": [
                                            {
                                                "by": "lottin",
                                                "id": 39822067,
                                                "kids": [
                                                    39822145,
                                                    39822156
                                                ],
                                                "parent": 39821966,
                                                "text": "A simple conversation would do.",
                                                "time": 1711406572,
                                                "type": "comment",
                                                "comments": [
                                                    {
                                                        "by": "mewpmewp2",
                                                        "id": 39822145,
                                                        "parent": 39822067,
                                                        "text": "Could you share a conversation link with GPT-4 with either about a &quot;list&quot; or a &quot;dog&quot;, to determine whether it truly understands one of those things compared to a human?",
                                                        "time": 1711407147,
                                                        "type": "comment"
                                                    },
                                                    {
                                                        "by": "bongodongobob",
                                                        "id": 39822156,
                                                        "parent": 39822067,
                                                        "text": "Just did that. It seems to understand. Checkmate &#x2F;fingerguns",
                                                        "time": 1711407229,
                                                        "type": "comment"
                                                    }
                                                ]
                                            }
                                        ]
                                    }
                                ]
                            }
                        ]
                    },
                    {
                        "by": "unclebucknasty",
                        "id": 39822038,
                        "kids": [
                            39822088
                        ],
                        "parent": 39821758,
                        "text": "Agreed, right down to their conclusion resonating as way overstated. Actually, meaningless would be more accurate.<p>The thing about LLMs is exactly that they <i>don&#x27;t</i> understand by design. It often feels very distinctly like it&#x27;s just engaging in sophisticated wordplay. A parlor trick.<p>When ChatGPT 4 first came out I spent a couple of hours putting together a chess game using ChatGPT as the engine. It was shockingly bad, as in even attempting to make invalid moves.<p>I get it: it&#x27;s not tuned for that purpose, and its chess training corpus could probably be expanded to improve it as well.<p>But, it actually served as a near-perfect demonstration of its lack of understanding, as well as the confidence with which it asserts things that are simply wrong.<p>On a recent integration project with a good bit of nuanced functionality, it led me astray multiple times. I&#x27;ve gotten to a point where I can feel when its answers are not quite right, particularly if I know just a little about the topic. And, when challenged, it does that strange thing of responding with something along the lines of, &quot;My apologies you&#x27;re completely right that I was completely wrong&quot;.<p>Over time, there becomes a sense that there is no there there. Even it&#x27;s writing capabilities, lauded by so many, are of a style that is superficial and perfunctory or rote. That makes sense when you know what it is, but that&#x27;s the thing: we get articles like these, lauding its wisdom.",
                        "time": 1711406320,
                        "type": "comment",
                        "comments": [
                            {
                                "by": "bongodongobob",
                                "id": 39822088,
                                "kids": [
                                    39822192
                                ],
                                "parent": 39822038,
                                "text": "Idk. One of my first tests for GPT4 was writing a website &quot;for snakes.&quot; It was a flask app, and it did all the obvious things you&#x27;d expect. There was a title that said &quot;Snake.com - A website for snakes&quot; and a bunch of silly marketing stuff.<p>What impressed me is when I asked to make it more snake-like (what does that even mean right?).<p>It changed the colors to shades of green, used italic fonts, added some hisssssing sssstuff to wordssss, and added a diamond pattern through the background.<p>It was a dumb and not very fancy site, but I&#x27;m not sure you can say it doesn&#x27;t understand anything at all when you ask it to make a website more snakelike and actually made a pretty good attempt at doing it.",
                                "time": 1711406723,
                                "type": "comment",
                                "comments": [
                                    {
                                        "by": "unclebucknasty",
                                        "id": 39822192,
                                        "kids": [
                                            39822379,
                                            39822325
                                        ],
                                        "parent": 39822088,
                                        "text": "Yeah, that&#x27;s kind of a different conception of understanding though. The lines do get a little blurry at a certain point, and a lot of what it does &quot;feels&quot; like understanding, especially given how it &quot;communicates&quot;.<p>But I think it comes down to whether it can reason about things and whether it can draw new conclusions or create new information as a result.<p>Your snake site is probably a good example. ChatGPT has a bunch of words that it knows are associated with snakes. It&#x27;s pretty straightforward pattern matching. It doesn&#x27;t really &quot;understand&quot; what those words mean, except that they have relationships to other words.<p>But, if you were to ask it to reason and draw new conclusions about these things beyond its training corpus, it would be unable to reliably do so.<p>Similarly, it had no idea about the quality (and sometimes legality) of the chess moves it generated.",
                                        "time": 1711407428,
                                        "type": "comment",
                                        "comments": [
                                            {
                                                "by": "visarga",
                                                "id": 39822379,
                                                "parent": 39822192,
                                                "text": "&gt; it comes down to whether it can reason about things and whether it can draw new conclusions or create new information as a result<p>Neither can humans, at least with our bare brains. We can do it by carefully observing the effects of our actions in the environment, but we are really studying the world and it takes time. Everything we know comes from the environment.<p>The brain by itself invents or discovers nothing, it is the data-engine made by action-effect-feedback that teaches us all we know. Without the ability to push and prod, set up our experiments and carefully observe effects we wouldn&#x27;t be at our current level.<p>Environment is the teacher, but there is another important factor - language. Without it every one of us would have to rediscover from scratch. With it we can build upon other people to learn and cooperate. We encode everything we know in language. It acts like an evolutionary system of ideas.<p>LLMs have what is necessary, they can learn language pretty well, but until now have not been exposed much to the world. There are millions of chats but very little in other kinds of environments - computers, simulators, games, robots. LLMs can create their own experiences and learn from each other, and from us.<p>Open ended discovery is a grand project, a social process, it doesn&#x27;t work well in one agent. Language is the linking element, and the world is the teacher. Some things are not written in any books, only the external world can teach us. Reasoning about things and drawing new conclusions depends on having access to an environment.",
                                                "time": 1711408625,
                                                "type": "comment"
                                            },
                                            {
                                                "by": "bongodongobob",
                                                "id": 39822325,
                                                "parent": 39822192,
                                                "text": "I mostly agree.<p>I really think chess is just a terrible example though. You&#x27;re really asking a lot of it but I&#x27;m honestly shocked it <i>can</i> do what it can. It seems to know some opening books, but falls down immediately. Which really makes sense because you&#x27;ll find a lot of reading material on specific openings, but the problem space of the game is just too big to find texts about any given game state. Maybe if you have it reason about the board state and &quot;think&quot; about tactics you could push it farther. But we&#x27;ve already solved this.<p>We have Stockfish et al and they&#x27;ve literally changed the game. Asking an LLM to play chess, while cool, is like trying to train a fish to dance. I think once we have an AI that&#x27;s built with a bunch of different models that specialize in different things the idea of understanding is going to get even blurrier to the point that we might even say &quot;yes, it doesn&#x27;t &#x27;understand&#x27; things, but it&#x27;s better at humans at literally everything&quot; so the difference becomes meaningless.<p>I&#x27;m also of the opinion that humans are fancy automatons, so I tend to argue both sides. I&#x27;ll say yeah it&#x27;s thinking and so do we or ok it&#x27;s not, but either do we.",
                                                "time": 1711408290,
                                                "type": "comment"
                                            }
                                        ]
                                    }
                                ]
                            }
                        ]
                    }
                ]
            }
        ]
    },
    {
        "by": "vnglst",
        "descendants": 1,
        "id": 39820430,
        "kids": [
            39820641
        ],
        "score": 3,
        "time": 1711395336,
        "title": "I asked ChatGPT to write the code to print \"Hello, world \" as a junior developer",
        "type": "story",
        "url": "https://hachyderm.io/@vnglst/112135583244850791",
        "comments": [
            {
                "by": "jeffreygoesto",
                "id": 39820641,
                "parent": 39820430,
                "text": "Reminds me of <a href=\"https:&#x2F;&#x2F;github.com&#x2F;EnterpriseQualityCoding&#x2F;FizzBuzzEnterpriseEdition\">https:&#x2F;&#x2F;github.com&#x2F;EnterpriseQualityCoding&#x2F;FizzBuzzEnterpris...</a>",
                "time": 1711396826,
                "type": "comment"
            }
        ]
    },
    {
        "by": "agcat",
        "descendants": 0,
        "id": 39820264,
        "kids": [
            39820306
        ],
        "score": 2,
        "time": 1711394292,
        "title": "LLMs Tokens/Second Benchmark ( Mistral, Llama2, Gemma) \u2013 Independent Research",
        "type": "story",
        "url": "https://www.inferless.com/learn/exploring-llms-speed-benchmarks-independent-analysis",
        "comments": [
            {
                "deleted": true,
                "id": 39820306,
                "parent": 39820264,
                "time": 1711394533,
                "type": "comment"
            }
        ]
    },
    {
        "by": "rntn",
        "descendants": 0,
        "id": 39819816,
        "score": 1,
        "time": 1711391952,
        "title": "Epistemology of Language Models: Do Language Models Have Holistic Knowledge?",
        "type": "story",
        "url": "https://arxiv.org/abs/2403.12862"
    },
    {
        "by": "importantbrian",
        "descendants": 0,
        "id": 39819808,
        "kids": [
            39820129
        ],
        "score": 1,
        "time": 1711391918,
        "title": "Building and testing C extensions for SQLite with ChatGPT Code Interpreter",
        "type": "story",
        "url": "https://simonw.substack.com/p/building-and-testing-c-extensions",
        "comments": [
            {
                "deleted": true,
                "id": 39820129,
                "parent": 39819808,
                "time": 1711393612,
                "type": "comment"
            }
        ]
    },
    {
        "by": "Josely",
        "descendants": 18,
        "id": 39818823,
        "kids": [
            39819265,
            39822394,
            39819266,
            39819795,
            39820713,
            39819054,
            39820854,
            39821423,
            39818911
        ],
        "score": 60,
        "time": 1711386756,
        "title": "OpenAI: Sora: First Impressions",
        "type": "story",
        "url": "https://openai.com/blog/sora-first-impressions",
        "comments": [
            {
                "by": "withinrafael",
                "id": 39819265,
                "parent": 39818823,
                "text": "&gt; Below are a few examples of the artists\u2019 work, with early thoughts from them on how they see Sora fitting into their workflows and businesses.<p>I wish it was clearer how Sora was used by each artist and how it impacted the provided examples. (I think I see some Sora generated output but I&#x27;d imagine it&#x27;s not as clear cut in artistic works.)",
                "time": 1711388764,
                "type": "comment"
            },
            {
                "by": "rperez333",
                "id": 39822394,
                "kids": [
                    39822631
                ],
                "parent": 39818823,
                "text": "I&#x27;m seeing shots that would be incredibly expensive for some productions - even if we ignore the ones requiring visual effects work. Some of them would need small crews, permits, rentals of expensive equipment, casting, and travel. It&#x27;s impressive and concerning at the same time.",
                "time": 1711408711,
                "type": "comment",
                "comments": [
                    {
                        "by": "ed_mercer",
                        "id": 39822631,
                        "parent": 39822394,
                        "text": "Do we have any ballpark figure of what a single sora video costs to make?",
                        "time": 1711410744,
                        "type": "comment"
                    }
                ]
            },
            {
                "by": "Jensson",
                "id": 39819266,
                "kids": [
                    39819924
                ],
                "parent": 39818823,
                "text": "&gt; Sora is at its most powerful when you\u2019re not replicating the old but bringing to life new and impossible ideas we would have otherwise never had the opportunity to see.<p>Roughly what you would expect, good for artsy pieces where you don&#x27;t need the model to generate anything very specific, but not very useful for most work since most work you want that control.<p>In other words it will be used for very similar things as current image generators, like intro scenes, short one offs, concept art etc.",
                "time": 1711388777,
                "type": "comment",
                "comments": [
                    {
                        "by": "erickj",
                        "id": 39819924,
                        "kids": [
                            39820665,
                            39820668
                        ],
                        "parent": 39819266,
                        "text": "&gt; not very useful for most work<p>We seem to be on a timeline where most of the significant use cases that the model doesn&#x27;t handle well today is less than 2 years away from significant improvement.<p>My (completely baseless) guess is that within 2 years we begin to see &quot;high budget&quot; feature length productions beginning to move towards a cost saving model which fully allocate the production budget to primarily virtual content.<p>In less than a few years time there will almost certainly be a vast ecosystem of production and post production tools to give creators the controls to reliably create and fine tune their shots.",
                        "time": 1711392508,
                        "type": "comment",
                        "comments": [
                            {
                                "by": "hexage1814",
                                "id": 39820665,
                                "kids": [
                                    39822424
                                ],
                                "parent": 39819924,
                                "text": "I agree with you, and just a few more observations about where do I think the current bottleneck might be: I wonder how well the model handles with re-using objects&#x2F;people&#x2F;scenes. Like, can I create a character and then use him again along 10 different shots? Also, I&#x27;m pretty curious about how the user interface looks like. Cause they the text-to-video model interfaces seem pretty limited compared to the freedom a person has using Unreal Engine or Blender or shooting a movie in real life.<p>How would the golden standard text-to-video user interface would look? And I have been thinking on this for years, even before the current generative AI boom, and I wonder if it could generate like a 3D representation of the scene that you described, like there would be a file where you could very easily change things around, as if that thing had been created on Blender or whatever, but very very user-friendly and easy to edit things.<p>It will seem silly what I&#x27;m going to say, but the ideal interface, it reminds those movies people did using the game &quot;The Sims&quot;, and how you could very easily move objects, and move the camera, and so on. What I&#x27;m trying to say here is that I would imagine these models creating a 3D representation of the scene, and the movie-making process ends up being somewhat similar to how could you could customize objects&#x2F;people in that game.",
                                "time": 1711396956,
                                "type": "comment",
                                "comments": [
                                    {
                                        "by": "TomaszZielinski",
                                        "id": 39822424,
                                        "parent": 39820665,
                                        "text": "I have only vague idea about this (I worked on small 3d games many many years ago), but I imagined something similar to what you described.<p>Basically you use Sora to generate a promising scene, then you ask it (or another model) to turn that scene into a scene graph in a text file.<p>It will make mistakes, but it could work similarly to the Python interpreter in ChatGPT--it can iterate until everything is OK. Maybe there could even be some adversarial stuff where the scene graph is rendered on the fly to compare it to the generated clip, etc.<p>And then you can use you standard toolset to edit it, probably enhanced with a copilot model to automate as much as possible.",
                                        "time": 1711408923,
                                        "type": "comment"
                                    }
                                ]
                            },
                            {
                                "by": "whiplash451",
                                "id": 39820668,
                                "kids": [
                                    39821252
                                ],
                                "parent": 39819924,
                                "text": "The cool demos from OpenAI, Figure and the like make us hallucinate a future that will take much (much) longer to pan out because they ignore the domain-specific knowledge that is inherent to the domain they pretend to disrupt.<p>I\u2019ll be impressed when ILM talks about it.",
                                "time": 1711396970,
                                "type": "comment",
                                "comments": [
                                    {
                                        "by": "commakozzi",
                                        "id": 39821252,
                                        "kids": [
                                            39821319
                                        ],
                                        "parent": 39820668,
                                        "text": "this&#x27;ll age well...",
                                        "time": 1711400649,
                                        "type": "comment",
                                        "comments": [
                                            {
                                                "by": "CamperBob2",
                                                "id": 39821319,
                                                "parent": 39821252,
                                                "text": "It&#x27;s &quot;God of the Gaps&quot; all the way down with these folks.",
                                                "time": 1711401182,
                                                "type": "comment"
                                            }
                                        ]
                                    }
                                ]
                            }
                        ]
                    }
                ]
            },
            {
                "by": "jrflowers",
                "id": 39819795,
                "parent": 39818823,
                "text": "&gt; As great as Sora is at generating things that appear real - what excites us is its ability to make things that are totally surreal.<p>Finally, software that makes images that don\u2019t quite look right. The use cases for these will be unending",
                "time": 1711391865,
                "type": "comment"
            },
            {
                "by": "whiplash451",
                "id": 39820713,
                "kids": [
                    39821303,
                    39822574
                ],
                "parent": 39818823,
                "text": "I\u2019ll be downvoted for this, but all these videos feel like the high-fructose corn syrup of cooking.",
                "time": 1711397247,
                "type": "comment",
                "comments": [
                    {
                        "by": "wilg",
                        "id": 39821303,
                        "kids": [
                            39821843
                        ],
                        "parent": 39820713,
                        "text": "Successful, widespread, and not differentiable in taste tests?",
                        "time": 1711401017,
                        "type": "comment",
                        "comments": [
                            {
                                "by": "jazzyjackson",
                                "id": 39821843,
                                "kids": [
                                    39822234
                                ],
                                "parent": 39821303,
                                "text": "a cheap way to make everything sweet so that prepackaged goods are preferable to ever leaning how to make something yourself",
                                "time": 1711404933,
                                "type": "comment",
                                "comments": [
                                    {
                                        "by": "wilg",
                                        "id": 39822234,
                                        "parent": 39821843,
                                        "text": "I think its good cheap food is available!",
                                        "time": 1711407722,
                                        "type": "comment"
                                    }
                                ]
                            }
                        ]
                    },
                    {
                        "by": "xotesos",
                        "dead": true,
                        "id": 39822574,
                        "parent": 39820713,
                        "text": "[dead]",
                        "time": 1711410269,
                        "type": "comment"
                    }
                ]
            },
            {
                "by": "th0ma5",
                "id": 39819054,
                "parent": 39818823,
                "text": "A good study could be comparing artist output and self satisfaction with LLMs vs. Conversing with a rubber duck or just imagining what an LLM might do. A lot of this reads to me as the artists actually selling themselves short.",
                "time": 1711387752,
                "type": "comment"
            },
            {
                "by": "huytersd",
                "id": 39820854,
                "parent": 39818823,
                "text": "How much of this is truly Sora and how much is not?",
                "time": 1711398121,
                "type": "comment"
            },
            {
                "by": "dzhiurgis",
                "id": 39821423,
                "parent": 39818823,
                "text": "I feel all the GPU time should first go to improving GPT or solving AGI rather than image&#x2F;video generation",
                "time": 1711401845,
                "type": "comment"
            },
            {
                "deleted": true,
                "id": 39818911,
                "parent": 39818823,
                "time": 1711387142,
                "type": "comment"
            }
        ]
    },
    {
        "by": "swyx",
        "descendants": 0,
        "id": 39818597,
        "kids": [
            39818609
        ],
        "score": 4,
        "time": 1711385664,
        "title": "The Unbundling of ChatGPT",
        "type": "story",
        "url": "https://www.latent.space/p/feb-2024",
        "comments": [
            {
                "deleted": true,
                "id": 39818609,
                "parent": 39818597,
                "time": 1711385723,
                "type": "comment"
            }
        ]
    },
    {
        "by": "giuliomagnifico",
        "descendants": 1,
        "id": 39818564,
        "kids": [
            39818848,
            39818827
        ],
        "score": 8,
        "time": 1711385499,
        "title": "ChatGPT linked to declining academic performance and memory loss in new study",
        "type": "story",
        "url": "https://www.psypost.org/chatgpt-linked-to-declining-academic-performance-and-memory-loss-in-new-study/",
        "comments": [
            {
                "by": "throwaway888abc",
                "id": 39818848,
                "parent": 39818564,
                "text": "Link to full paper:<p><a href=\"https:&#x2F;&#x2F;educationaltechnologyjournal.springeropen.com&#x2F;articles&#x2F;10.1186&#x2F;s41239-024-00444-7\" rel=\"nofollow\">https:&#x2F;&#x2F;educationaltechnologyjournal.springeropen.com&#x2F;articl...</a>",
                "time": 1711386850,
                "type": "comment"
            },
            {
                "deleted": true,
                "id": 39818827,
                "parent": 39818564,
                "time": 1711386776,
                "type": "comment"
            }
        ]
    },
    {
        "by": "Anon84",
        "descendants": 0,
        "id": 39818400,
        "kids": [
            39818457
        ],
        "score": 5,
        "time": 1711384655,
        "title": "Large Language Models: A Survey",
        "type": "story",
        "url": "https://arxiv.org/abs/2402.06196",
        "comments": [
            {
                "deleted": true,
                "id": 39818457,
                "parent": 39818400,
                "time": 1711384924,
                "type": "comment"
            }
        ]
    },
    {
        "by": "thunderbong",
        "descendants": 1,
        "id": 39817802,
        "kids": [
            39817824,
            39818360,
            39817967
        ],
        "score": 2,
        "time": 1711381600,
        "title": "ChatGPT 4 is worse than 3.5",
        "type": "story",
        "url": "https://community.openai.com/t/chatgpt-4-is-worse-than-3-5/588078",
        "comments": [
            {
                "by": "farmdve",
                "id": 39817824,
                "parent": 39817802,
                "text": "And currently chat.openai.com is down for me. At least the actual API.",
                "time": 1711381691,
                "type": "comment"
            },
            {
                "by": "Blamoso",
                "dead": true,
                "id": 39818360,
                "parent": 39817802,
                "text": "[dead]",
                "time": 1711384439,
                "type": "comment"
            },
            {
                "deleted": true,
                "id": 39817967,
                "parent": 39817802,
                "time": 1711382368,
                "type": "comment"
            }
        ]
    },
    {
        "by": "synergy20",
        "descendants": 0,
        "id": 39816988,
        "score": 1,
        "time": 1711377970,
        "title": "Building and testing C extensions for SQLite with ChatGPT Code Interpreter",
        "type": "story",
        "url": "https://simonwillison.net/2024/Mar/23/building-c-extensions-for-sqlite-with-chatgpt-code-interpreter/"
    },
    {
        "by": "Capstanlqc",
        "descendants": 0,
        "id": 39816920,
        "score": 1,
        "time": 1711377656,
        "title": "Alibaba Researchers Probe Large Language Models for E-Commerce Translation",
        "type": "story",
        "url": "https://slator.com/alibaba-researchers-probe-large-language-models-e-commerce-translation/"
    },
    {
        "by": "billybuckwheat",
        "descendants": 57,
        "id": 39782876,
        "kids": [
            39785820,
            39785238,
            39784818,
            39784716,
            39784104,
            39785203,
            39783815,
            39784464,
            39783259,
            39783739,
            39784329,
            39786664,
            39786982,
            39784252,
            39788162,
            39784628,
            39788010,
            39783076,
            39788070,
            39783254,
            39790599,
            39783592,
            39783635,
            39783519,
            39783643,
            39791159,
            39783616,
            39783180
        ],
        "score": 192,
        "time": 1711047381,
        "title": "Jan: An open source alternative to ChatGPT that runs on the desktop",
        "type": "story",
        "url": "https://jan.ai/",
        "comments": [
            {
                "by": "EMM_386",
                "id": 39785820,
                "parent": 39782876,
                "text": "It does make it easier for the end user who doesn&#x27;t want to fiddle around with python dependencies, command lines, building C++ projects, etc.<p>Just install it, point it to a model, and go.  Now you have a local LLM.<p>If you want something more, click the &quot;start server&quot; button and you have a local OpenAI compatible API which you can point more advanced front-ends to.",
                "time": 1711064860,
                "type": "comment"
            },
            {
                "by": "lagrange77",
                "id": 39785238,
                "parent": 39782876,
                "text": "I was wondering if it uses something like vLLM[0] or Llama.cpp[1].<p>Seems to be Llama.cpp via &#x27;Nitro&#x27;, which was discussed here before [2].<p>[0] <a href=\"https:&#x2F;&#x2F;github.com&#x2F;vllm-project&#x2F;vllm\">https:&#x2F;&#x2F;github.com&#x2F;vllm-project&#x2F;vllm</a><p>[1] <a href=\"https:&#x2F;&#x2F;github.com&#x2F;ggerganov&#x2F;llama.cpp\">https:&#x2F;&#x2F;github.com&#x2F;ggerganov&#x2F;llama.cpp</a><p>[2] <a href=\"https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=38887531\">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=38887531</a>",
                "time": 1711060272,
                "type": "comment"
            },
            {
                "by": "LeoPanthera",
                "id": 39784818,
                "parent": 39782876,
                "text": "Unless I just can&#x27;t find it, there seems to be no setting for customizing the prompt format for local models. You can edit the prompt itself, but not the format of the prompt or the subsequent messages. This would make using many models difficult, or give poor results, since they don&#x27;t all use the same format.",
                "time": 1711057794,
                "type": "comment"
            },
            {
                "by": "FuriouslyAdrift",
                "id": 39784716,
                "kids": [
                    39786635,
                    39793057
                ],
                "parent": 39782876,
                "text": "Many LLMs may be run locally with GPT4All...<p><a href=\"https:&#x2F;&#x2F;gpt4all.io&#x2F;\" rel=\"nofollow\">https:&#x2F;&#x2F;gpt4all.io&#x2F;</a>",
                "time": 1711057093,
                "type": "comment",
                "comments": [
                    {
                        "by": "nickpsecurity",
                        "id": 39786635,
                        "parent": 39784716,
                        "text": "And MLC puts them on your phone, too.<p><a href=\"https:&#x2F;&#x2F;llm.mlc.ai&#x2F;\" rel=\"nofollow\">https:&#x2F;&#x2F;llm.mlc.ai&#x2F;</a>",
                        "time": 1711071971,
                        "type": "comment"
                    },
                    {
                        "by": "slowmovintarget",
                        "id": 39793057,
                        "kids": [
                            39794911
                        ],
                        "parent": 39784716,
                        "text": "GPT4All makes it annoyingly difficult to run any other than their &quot;approved&quot; models. I&#x27;d like to kick the tires on a whole host of random GGUF quantizations on Hugging Face, please.<p>I&#x27;ve poked around the doc, not sure if Jan can do that better.<p>In the mean time, I use text-gen-ui (Oobabooga) as a back-end and have it run with `--api` to use the front end of my choice.",
                        "time": 1711129670,
                        "type": "comment",
                        "comments": [
                            {
                                "by": "_puk",
                                "id": 39794911,
                                "parent": 39793057,
                                "text": "Not at my computer right now to double check.. but doesn&#x27;t GPT4All&#x27;s &quot;Browse&quot; button in the model list let you pick a locally downloaded model?",
                                "time": 1711141917,
                                "type": "comment"
                            }
                        ]
                    }
                ]
            },
            {
                "by": "christkv",
                "id": 39784104,
                "parent": 39782876,
                "text": "I got say I\u2019ve been using LLM studio as it exposes the models in the ui as well as through a local open ai compatible server so I can test different models against my workflows locally.",
                "time": 1711053587,
                "type": "comment"
            },
            {
                "by": "kkfx",
                "id": 39785203,
                "kids": [
                    39793736,
                    39786724
                ],
                "parent": 39782876,
                "text": "I try some LLM on my notes and well... They was unable to give me insights that are hard to spot, like follow the flaw of notes identifying patterns, find similar notes from the past and so on. In ALL cases classic tags&#x2F;riprgrep full-text search was far quicker and equally or more effective.<p>Long story short: LLMs might be useful on hyper big mass of information, like a new kind of search engine that try do achieve a semantic goal mimicking it. But not more than that IMVHO. Marginally LLMs might help computer-illiterate to manage their files, seen <a href=\"https:&#x2F;&#x2F;www.theverge.com&#x2F;22684730&#x2F;students-file-folder-directory-structure-education-gen-z\" rel=\"nofollow\">https:&#x2F;&#x2F;www.theverge.com&#x2F;22684730&#x2F;students-file-folder-direc...</a> but I doubt they can go any further for the next 5+ years at least.",
                "time": 1711060027,
                "type": "comment",
                "comments": [
                    {
                        "by": "lxgr",
                        "id": 39793736,
                        "kids": [
                            39798051
                        ],
                        "parent": 39785203,
                        "text": "They&#x27;ve been very useful in quickly answering common questions using a too-large-to-manually-scan knowledge base in my experience at my job, and I don&#x27;t consider myself or my colleagues &quot;computer-illiterate&quot;.",
                        "time": 1711134275,
                        "type": "comment",
                        "comments": [
                            {
                                "by": "kkfx",
                                "id": 39798051,
                                "parent": 39793736,
                                "text": "That&#x27;s follow the &quot;might be useful as a new kind of search engine&quot;, though it might be a sign of an a bit messy KB. The issue of potential hallucinations however is still there so even such usage, a different search engine, demand extra attention.<p>It&#x27;s not a free critic to those who have designed, implemented and trained LLMs, it&#x27;s just the observation that practical usage is far less than the advertised one and it&#x27;s still not much good. It&#x27;s still an advancement, a good thing to have, the start of a revolution, but still far from being what many dreams.",
                                "time": 1711177517,
                                "type": "comment"
                            }
                        ]
                    },
                    {
                        "by": "theGnuMe",
                        "id": 39786724,
                        "parent": 39785203,
                        "text": "LLMs might help my disorganized approach to files...",
                        "time": 1711072933,
                        "type": "comment"
                    }
                ]
            },
            {
                "by": "pryelluw",
                "id": 39783815,
                "kids": [
                    39783993
                ],
                "parent": 39782876,
                "text": "Would be nice if they listed system requirements. Their docs just say coming soon \u2026",
                "time": 1711052097,
                "type": "comment",
                "comments": [
                    {
                        "by": "knodi123",
                        "id": 39783993,
                        "kids": [
                            39784070
                        ],
                        "parent": 39783815,
                        "text": "most of their docs say coming soon.      and their whole wiki.<p>honestly feels like site this was launched a couple of days too soon.",
                        "time": 1711053089,
                        "type": "comment",
                        "comments": [
                            {
                                "by": "warkdarrior",
                                "id": 39784070,
                                "parent": 39783993,
                                "text": "Their LLM is still generating copy for the website..",
                                "time": 1711053427,
                                "type": "comment"
                            }
                        ]
                    }
                ]
            },
            {
                "by": "LeoPanthera",
                "id": 39784464,
                "kids": [
                    39793851
                ],
                "parent": 39782876,
                "text": "Is this a fork of &quot;LM Studio&quot;? The UI is suspiciously similar, even down to the layout of the labels.",
                "time": 1711055530,
                "type": "comment",
                "comments": [
                    {
                        "by": "euclaise",
                        "id": 39793851,
                        "parent": 39784464,
                        "text": "LM studio is closed source, so no",
                        "time": 1711135087,
                        "type": "comment"
                    }
                ]
            },
            {
                "by": "throwitaway1123",
                "id": 39783259,
                "parent": 39782876,
                "text": "This looks interesting. I would love a comparison between this product and LM Studio.",
                "time": 1711049287,
                "type": "comment"
            },
            {
                "by": "moose44",
                "id": 39783739,
                "parent": 39782876,
                "text": "Running LLMs locally always feels so awesome!",
                "time": 1711051554,
                "type": "comment"
            },
            {
                "by": "pimlottc",
                "id": 39784329,
                "kids": [
                    39784342
                ],
                "parent": 39782876,
                "text": "I&#x27;m going to assume this is not an Australian company...<p><a href=\"https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=2akt3P8ltLM\" rel=\"nofollow\">https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=2akt3P8ltLM</a>",
                "time": 1711054705,
                "type": "comment",
                "comments": [
                    {
                        "by": "badRNG",
                        "id": 39784342,
                        "parent": 39784329,
                        "text": "Looks like they are based out of Singapore",
                        "time": 1711054795,
                        "type": "comment"
                    }
                ]
            },
            {
                "by": "Brajeshwar",
                "id": 39786664,
                "kids": [
                    39801072,
                    39786879
                ],
                "parent": 39782876,
                "text": "This looks awesome. Trying it out. Suggestion, can we please change the &quot;Download Jan for PC&quot; to perhaps just &quot;Download&quot; or &quot;Download for Desktop&quot; or whichever that makes sense but not &quot;PC&quot;. I almost move away thinking this is Windows, thus not for us.<p>I recently stumbled on <a href=\"https:&#x2F;&#x2F;mindmac.app\" rel=\"nofollow\">https:&#x2F;&#x2F;mindmac.app</a> which is a non-subscription app that uses multiple AI tools (not just OpneAI). Looks Promising.<p>Like the others in the comments, I&#x27;ve tried <a href=\"https:&#x2F;&#x2F;www.typingmind.com\" rel=\"nofollow\">https:&#x2F;&#x2F;www.typingmind.com</a> (via SetApp).<p>Sindre Sorhus have a pretty stable Native App <a href=\"https:&#x2F;&#x2F;sindresorhus.gumroad.com&#x2F;l&#x2F;quickgpt\" rel=\"nofollow\">https:&#x2F;&#x2F;sindresorhus.gumroad.com&#x2F;l&#x2F;quickgpt</a><p>These are some of the really good ones. I&#x27;m tending more towards trying out the likes of MindMac just for the fact that I can plug and switch between multiple tools.",
                "time": 1711072212,
                "type": "comment",
                "comments": [
                    {
                        "by": "Terretta",
                        "id": 39801072,
                        "parent": 39786664,
                        "text": "What&#x27;s the value proposition for TypingMind as a commercial product ($3500 to run locally for 5 seats)?<p>But let me contrast that last &quot;native app&quot; with Machato and MacGPT:<p>== Machato ==<p>Machato is feature-full for system prompts and transcripts, connecting to to OpenAI, Claude, and any &quot;server&quot; endpoint that&#x27;s OpenAPI API compatible, and surfacing parameter and token settings per conversation right on your text entry bar.  You can also point a given conversation to a local ollama endpoint such as Mixtral 8x7B and it works as well.<p>The best feature is the selective forking and suppression of exchanges within conversation threads.<p><a href=\"https:&#x2F;&#x2F;untimelyunicorn.gumroad.com&#x2F;l&#x2F;machato\" rel=\"nofollow\">https:&#x2F;&#x2F;untimelyunicorn.gumroad.com&#x2F;l&#x2F;machato</a><p>== MacGPT ==<p>MacGPT is highly integrated throughout MacOS, and works with either OpenAI key or a ChatGTP Pro login.  It&#x27;s quite similar to BoltAI mentioned elsewhere in this thread, but in addition to the OpenAI key based mode, also works with a ChatGPT Pro subscription in a ChatGPT web UI pop-up.<p><a href=\"https:&#x2F;&#x2F;www.macgpt.com&#x2F;\" rel=\"nofollow\">https:&#x2F;&#x2F;www.macgpt.com&#x2F;</a>",
                        "time": 1711211337,
                        "type": "comment"
                    },
                    {
                        "by": "longnguyen",
                        "id": 39786879,
                        "kids": [
                            39811201,
                            39801196,
                            39787261
                        ],
                        "parent": 39786664,
                        "text": "Shameless plug: I built a native client called BoltAI[0]. Unlike other clients, I prioritize UI, UX and performance.<p>Give it a try if UI &amp; UX is important to you.<p>[0]: <a href=\"https:&#x2F;&#x2F;boltai.com\" rel=\"nofollow\">https:&#x2F;&#x2F;boltai.com</a>",
                        "time": 1711074465,
                        "type": "comment",
                        "comments": [
                            {
                                "by": "geggo98",
                                "id": 39811201,
                                "kids": [
                                    39812755
                                ],
                                "parent": 39786879,
                                "text": "From the screenshots it looks like there is an activation limit, with a maximum of four devices. Reading the license, I could not confirm this. Is there a limit, and if, what is the maximum?",
                                "time": 1711320199,
                                "type": "comment",
                                "comments": [
                                    {
                                        "by": "longnguyen",
                                        "id": 39812755,
                                        "parent": 39811201,
                                        "text": "Sorry for the confusion. I need to improve my pricing page.<p>The license is per user, and can be used on maximum 3 devices. I figured this is enough for most users. If you have more devices or need a custom license, please send me an email (my email is in bio)",
                                        "time": 1711339046,
                                        "type": "comment"
                                    }
                                ]
                            },
                            {
                                "by": "Terretta",
                                "id": 39801196,
                                "kids": [
                                    39801281
                                ],
                                "parent": 39786879,
                                "text": "This looks great relative to others (very similar to MacGPT), and I particularly like how advanced settings are available but tucked away behind discoverable affordances.<p>It&#x27;s interesting that you have team pricing.<p>Can the Team leverage shared system prompts and&#x2F;or assistants from a OneDrive-for-Business (SharePoint) folder or GitHub repo?<p>If not, what makes it &quot;Team&quot; instead of just individual?",
                                "time": 1711212097,
                                "type": "comment",
                                "comments": [
                                    {
                                        "by": "longnguyen",
                                        "id": 39801281,
                                        "parent": 39801196,
                                        "text": "Hi. Actually I don\u2019t have a pricing plan for teams yet. It\u2019s still under (heavy) development. I changed my headline to reflect the direction I want to take this year (focus on teams)<p>And yes, some of my customers wanted team and collaborative features like shared prompt, internal plugins and integrations, RAG on internal documents\u2026<p>But I haven\u2019t launched these team features yet.<p>Are you interested in this? Would love to talk to you if it\u2019s something you\u2019re looking for.",
                                        "time": 1711212798,
                                        "type": "comment"
                                    }
                                ]
                            },
                            {
                                "by": "Brajeshwar",
                                "id": 39787261,
                                "parent": 39786879,
                                "text": "Sure. Why Not. Trying it out.<p>My use case is especially for my daughter so I can just plug in my OpenAI API and let her ask away.",
                                "time": 1711078898,
                                "type": "comment"
                            }
                        ]
                    }
                ]
            },
            {
                "by": "rnd0",
                "id": 39786982,
                "kids": [
                    39788381
                ],
                "parent": 39782876,
                "text": "How is this better than gpt4all?",
                "time": 1711075668,
                "type": "comment",
                "comments": [
                    {
                        "by": "Grimblewald",
                        "id": 39788381,
                        "parent": 39786982,
                        "text": "From what I see, it has the benefit of offering less functionality, more corpojargon and a more &#x27;intuitive&#x27; ui.",
                        "time": 1711094626,
                        "type": "comment"
                    }
                ]
            },
            {
                "by": "TheRealPomax",
                "id": 39784252,
                "kids": [
                    39791232,
                    39784467
                ],
                "parent": 39782876,
                "text": "Still hoping we&#x27;ll eventually stop using Fibonacci to show off recursion, because that&#x27;s one of those examples where the <i>maths</i> might be expressed as recursive relation, but the <i>implementation</i> should never be =)<p>Good AI would go &quot;you don&#x27;t want that, that&#x27;s horribly inefficient. Here&#x27;s an actually performant implementation based on the closed-form expression&quot;.",
                "time": 1711054331,
                "type": "comment",
                "comments": [
                    {
                        "by": "Wowfunhappy",
                        "id": 39791232,
                        "parent": 39784252,
                        "text": "What is your preferred example for teaching a beginner to use recursion?",
                        "time": 1711118631,
                        "type": "comment"
                    },
                    {
                        "by": "zopa",
                        "id": 39784467,
                        "parent": 39784252,
                        "text": "Nah, good AI would run in the compiler and optimize the recursion into something fast.",
                        "time": 1711055547,
                        "type": "comment"
                    }
                ]
            },
            {
                "by": "lazyeye",
                "id": 39788162,
                "parent": 39782876,
                "text": "The default model (Mistral Instruct 7BQ4) is woke.\nI asked it the following:-<p>Write a short poem in admiration of black people<p>Write a short poem in admiration of brown people<p>Write a short poem in admiration of asian people<p>Write a short poem in admiration of white people<p>It immediately replied with a poem for all except white people where it&#x27;s response was:-<p>&quot;I&#x27;d be happy to write a poem in admiration of all people, including those who identify as White.&quot;\nLol",
                "time": 1711092401,
                "type": "comment"
            },
            {
                "by": "onion2k",
                "id": 39784628,
                "parent": 39782876,
                "text": "I use Jan to run Mistral locally. It works well for what I need (which amounts to playing with models).",
                "time": 1711056539,
                "type": "comment"
            },
            {
                "by": "rc202402",
                "id": 39788010,
                "parent": 39782876,
                "text": "Been using this with a few models like gemma etc for a week now.<p>HN got any good LLM suggestions to run with this that are equivalent or better than GPT-3.5 &#x2F; claude?<p>I&#x27;m looking to use its api with LLama Index",
                "time": 1711090366,
                "type": "comment"
            },
            {
                "by": "ShamelessC",
                "id": 39783076,
                "kids": [
                    39783135
                ],
                "parent": 39782876,
                "text": "Quite a lot of polish and bragging about stars and tweets for an open source project. Is there hidden monetization of some sort? Perhaps VC funding?",
                "time": 1711048390,
                "type": "comment",
                "comments": [
                    {
                        "by": "anewhnaccount2",
                        "id": 39783135,
                        "kids": [
                            39783257
                        ],
                        "parent": 39783076,
                        "text": "According to their page <a href=\"https:&#x2F;&#x2F;jan.ai&#x2F;team&#x2F;\" rel=\"nofollow\">https:&#x2F;&#x2F;jan.ai&#x2F;team&#x2F;</a> they aim to bootstrap.",
                        "time": 1711048692,
                        "type": "comment",
                        "comments": [
                            {
                                "by": "ShamelessC",
                                "id": 39783257,
                                "parent": 39783135,
                                "text": "Awesome thanks.",
                                "time": 1711049267,
                                "type": "comment"
                            }
                        ]
                    }
                ]
            },
            {
                "deleted": true,
                "id": 39788070,
                "parent": 39782876,
                "time": 1711091205,
                "type": "comment"
            },
            {
                "by": "thedangler",
                "id": 39783254,
                "kids": [
                    39785271,
                    39786719
                ],
                "parent": 39782876,
                "text": "I don&#x27;t see anything about it reading local documents like exel, pdfs, or docs.\nAnyone see how this is accomplished?",
                "time": 1711049253,
                "type": "comment",
                "comments": [
                    {
                        "by": "0134340",
                        "id": 39785271,
                        "parent": 39783254,
                        "text": "Is it implied anywhere? That&#x27;s a feature I&#x27;d love and also why I haven&#x27;t bothered delving into LLMs very much; I didn&#x27;t know there were any that could locally index your library and train on that data. I&#x27;d love to ask it a question and have it reference my local ebook library.",
                        "time": 1711060492,
                        "type": "comment"
                    },
                    {
                        "by": "theGnuMe",
                        "id": 39786719,
                        "parent": 39783254,
                        "text": "It probably doesn&#x27;t.  The only one that read PDFs for me was the Nvidia ChatRTX. \nIt would be easy to add modules from pip that do this but you&#x27;d have to code up the input pipeline.  It&#x27;s not terribly difficult but it is definitely not point and click.",
                        "time": 1711072843,
                        "type": "comment"
                    }
                ]
            },
            {
                "by": "antifa",
                "id": 39790599,
                "parent": 39782876,
                "text": "Did this have any way to point at a folder of markdown files and RAG at it?",
                "time": 1711114548,
                "type": "comment"
            },
            {
                "by": "ThrowawayTestr",
                "id": 39783592,
                "kids": [
                    39784188,
                    39784275
                ],
                "parent": 39782876,
                "text": "Where does the model come from?",
                "time": 1711050904,
                "type": "comment",
                "comments": [
                    {
                        "by": "LordDragonfang",
                        "id": 39784188,
                        "parent": 39783592,
                        "text": "Afaict, it doesn&#x27;t have any inbuilt model, you just download one yourself or hook up to someone&#x27;s API.",
                        "time": 1711054027,
                        "type": "comment"
                    },
                    {
                        "by": "dsp_person",
                        "id": 39784275,
                        "parent": 39783592,
                        "text": "Scroll down on the main page:<p>01 Run local AI or connect to remote APIs<p>02 Browse and download models",
                        "time": 1711054478,
                        "type": "comment"
                    }
                ]
            },
            {
                "by": "thesurlydev",
                "id": 39783635,
                "kids": [
                    39784309,
                    39786571
                ],
                "parent": 39782876,
                "text": "These kinds of apps are becoming dime a dozen. It would be nice to know how this one differentiates itself. Not obvious from the website.",
                "time": 1711051114,
                "type": "comment",
                "comments": [
                    {
                        "by": "viraptor",
                        "id": 39784309,
                        "kids": [
                            39784469
                        ],
                        "parent": 39783635,
                        "text": "It seems like that until you actually try to use them. Not many are actually polished, support formatting, history, and multiple endpoints. There&#x27;s lots of trivial apps abandoned after a few days, but what are the actually functional, good quality alternatives to this one? (That don&#x27;t pass your query&#x2F;answer through a third-party for data collection)",
                        "time": 1711054595,
                        "type": "comment",
                        "comments": [
                            {
                                "by": "extr",
                                "id": 39784469,
                                "kids": [
                                    39784741,
                                    39784530
                                ],
                                "parent": 39784309,
                                "text": "I use <a href=\"https:&#x2F;&#x2F;www.typingmind.com&#x2F;\" rel=\"nofollow\">https:&#x2F;&#x2F;www.typingmind.com&#x2F;</a>. It is paid, but I&#x27;ve found it to be a reliable front end to OpenAI&#x2F;Claude&#x2F;Google, supporting everything you mention. I haven&#x27;t done any hyper detailed security audit but after watching network requests I&#x27;m pretty confident it&#x27;s not sending my chats anywhere except to the relevant provider endpoints.<p>Considering how much I use it, I&#x27;ve found it to be well worth the cost. The creator is pretty on top of model&#x2F;API changes.",
                                "time": 1711055548,
                                "type": "comment",
                                "comments": [
                                    {
                                        "by": "viraptor",
                                        "id": 39784741,
                                        "kids": [
                                            39786834
                                        ],
                                        "parent": 39784469,
                                        "text": "It&#x27;s not a standalone app though. There&#x27;s lots of web interfaces, but that&#x27;s not the same. (I mean, it&#x27;s a cool thing, but not what jan.ai is)",
                                        "time": 1711057280,
                                        "type": "comment",
                                        "comments": [
                                            {
                                                "by": "extr",
                                                "id": 39786834,
                                                "parent": 39784741,
                                                "text": "There is a desktop app available (I mean it\u2019s basically a wrapper around the web UI, but still).",
                                                "time": 1711074118,
                                                "type": "comment"
                                            }
                                        ]
                                    },
                                    {
                                        "by": "karmajunkie",
                                        "id": 39784530,
                                        "parent": 39784469,
                                        "text": "i\u2019ll second that recommendation\u2026 i use it through the SetApp store and i\u2019ve been very pleasantly surprised by its documentation and ability to work with most services.",
                                        "time": 1711055894,
                                        "type": "comment"
                                    }
                                ]
                            }
                        ]
                    },
                    {
                        "deleted": true,
                        "id": 39786571,
                        "parent": 39783635,
                        "time": 1711071399,
                        "type": "comment"
                    }
                ]
            },
            {
                "by": "okasaki",
                "dead": true,
                "id": 39783519,
                "kids": [
                    39783567,
                    39783682
                ],
                "parent": 39782876,
                "text": "[flagged]",
                "time": 1711050540,
                "type": "comment",
                "comments": [
                    {
                        "by": "lmeyerov",
                        "id": 39783567,
                        "parent": 39783519,
                        "text": "For AI projects, afaict, 12k stars or forks is more akin to downloads than contributors &amp; downstreams. GitHub is the app distribution, not just source distribution. I&#x27;ve been curious how to model this better..",
                        "time": 1711050770,
                        "type": "comment"
                    },
                    {
                        "deleted": true,
                        "id": 39783682,
                        "parent": 39783519,
                        "time": 1711051301,
                        "type": "comment"
                    }
                ]
            },
            {
                "by": "outcoldman",
                "dead": true,
                "id": 39783643,
                "kids": [
                    39783675
                ],
                "parent": 39782876,
                "text": "[flagged]",
                "time": 1711051159,
                "type": "comment",
                "comments": [
                    {
                        "deleted": true,
                        "id": 39783675,
                        "parent": 39783643,
                        "time": 1711051275,
                        "type": "comment"
                    }
                ]
            },
            {
                "by": "redder23",
                "dead": true,
                "id": 39791159,
                "kids": [
                    39801248,
                    39791506
                ],
                "parent": 39782876,
                "text": "[flagged]",
                "time": 1711118181,
                "type": "comment",
                "comments": [
                    {
                        "by": "Terretta",
                        "id": 39801248,
                        "parent": 39791159,
                        "text": "&gt; <i>If I had a key for some OpenAI paid shit I can go to their website and do not need an app for that. I really do not get it.</i><p>Perhaps you don&#x27;t have some OpenAI paid shit?<p>While you can clunk around in a sort of OpenAI playground in a web tab, it is designed for dev experimentation (a &quot;fiddler&quot; type of UI), and not a good experience for much beyond testing.<p>&gt; <i>excuse me you fuck did you not just tell me you are &quot;local first&quot; ... I try out the model, and it turns out it runs on my CPU with heavy RAM usage...</i><p>I&#x27;m not sure it makes sense to have both of these objections at once.<p>&gt; <i>I never ran a model</i><p>Oh.",
                        "time": 1711212501,
                        "type": "comment"
                    },
                    {
                        "by": "redder23",
                        "id": 39791506,
                        "parent": 39791159,
                        "text": "OK, there is a switch under &quot;Advanced Settings&quot; to enable GPU. Why the fuck is this no-brainer option off by default and &quot;advanced&quot;? Suddenly my 7B Model is shown as inactive and &quot;start&quot; does nothing, gives no error message either ... this is such an unusable alpha version.",
                        "time": 1711120372,
                        "type": "comment"
                    }
                ]
            },
            {
                "by": "CyberEldrich",
                "dead": true,
                "id": 39783616,
                "kids": [
                    39783664
                ],
                "parent": 39782876,
                "text": "[flagged]",
                "time": 1711051029,
                "type": "comment",
                "comments": [
                    {
                        "deleted": true,
                        "id": 39783664,
                        "parent": 39783616,
                        "time": 1711051250,
                        "type": "comment"
                    }
                ]
            },
            {
                "by": "afian",
                "id": 39783180,
                "parent": 39782876,
                "text": "Fantastic product and excellent team!",
                "time": 1711048894,
                "type": "comment"
            }
        ]
    },
    {
        "by": "CharlesW",
        "descendants": 124,
        "id": 39809177,
        "kids": [
            39810189,
            39810767,
            39809825,
            39810857,
            39809549,
            39810860,
            39810036,
            39810544,
            39809334,
            39810232,
            39810439,
            39809551,
            39809942,
            39809810,
            39810907,
            39810838
        ],
        "score": 156,
        "time": 1711305273,
        "title": "GPT-4, without specialized training, beat a GPT-3.5 class model that cost $10M",
        "type": "story",
        "url": "https://www.threads.net/@ethan_mollick/post/C46AfItO8RS",
        "comments": [
            {
                "by": "LASR",
                "id": 39810189,
                "kids": [
                    39810841,
                    39810308,
                    39810529,
                    39810467,
                    39810319
                ],
                "parent": 39809177,
                "text": "I lead AI teams at my company. I&#x27;ve advised leadership against any kind of training &#x2F; fine-tuning anything.<p>We&#x27;re not in the business of training models. We will never be as good as OpenAI &#x2F; Anthropic etc.<p>Where the real value in applications is smarter prompting techniques and RAG. There is a lot of room at the bottom in doing &quot;dumb&quot; things and simply feeding models with the right context to deliver customer value.",
                "time": 1711312075,
                "type": "comment",
                "comments": [
                    {
                        "by": "redox99",
                        "id": 39810841,
                        "kids": [
                            39812468,
                            39811293,
                            39811170
                        ],
                        "parent": 39810189,
                        "text": "That&#x27;s a pretty odd stance. I&#x27;ve finetuned llama&#x2F;mistral models that greatly outperform GPT4 with just a prompt.<p>You have to know when to RAG, finetune, or RAG+finetune.",
                        "time": 1711317184,
                        "type": "comment",
                        "comments": [
                            {
                                "by": "simonw",
                                "id": 39812468,
                                "kids": [
                                    39813117
                                ],
                                "parent": 39810841,
                                "text": "&quot;I&#x27;ve finetuned llama&#x2F;mistral models that greatly outperform GPT4 with just a prompt&quot;<p>If you write about your experiments with that in detail I guarantee you&#x27;ll get a lot of interest. The community is crying out for good, well documented, replicable examples of this kind of thing.",
                                "time": 1711334890,
                                "type": "comment",
                                "comments": [
                                    {
                                        "by": "redox99",
                                        "id": 39813117,
                                        "parent": 39812468,
                                        "text": "I&#x27;m so behind in this area. I had finetuned a model that was SOTA and worth publishing about in October, but procrastinated. I&#x27;m scared to check if somebody else already published on this topic.",
                                        "time": 1711345378,
                                        "type": "comment"
                                    }
                                ]
                            },
                            {
                                "by": "singularity2001",
                                "id": 39811293,
                                "kids": [
                                    39811979
                                ],
                                "parent": 39810841,
                                "text": "<p><pre><code>    greatly outperform GPT4 *for* just a prompt\n</code></pre>\nyour overfitting to training data convinces no-one that you created a &quot;better GPT4&quot;",
                                "time": 1711321078,
                                "type": "comment",
                                "comments": [
                                    {
                                        "by": "redox99",
                                        "id": 39811979,
                                        "parent": 39811293,
                                        "text": "Do you always assume other people are incompetent? That&#x27;s not very nice of you.<p>I mostly work on AI, so I know if I&#x27;m overfitting or not. It performs provably better in it&#x27;s domain (a niche programming language). GPT4 can barely write a hello world for it.<p>I&#x27;m not creating a &quot;better GPT4&quot; general chatbot. I&#x27;m finetuning for a specific task.",
                                        "time": 1711328530,
                                        "type": "comment"
                                    }
                                ]
                            },
                            {
                                "by": "kossTKR",
                                "id": 39811170,
                                "kids": [
                                    39811948
                                ],
                                "parent": 39810841,
                                "text": "How narrow is the dataset to be outperforming greatly?<p>Just curious about what the usecase is for a 7b model in a business context - ie. what does it do?",
                                "time": 1711319901,
                                "type": "comment",
                                "comments": [
                                    {
                                        "by": "redox99",
                                        "id": 39811948,
                                        "parent": 39811170,
                                        "text": "Code assistant for a niche programming language that GPT4 knows very little about and barely gets a hello world right.",
                                        "time": 1711328150,
                                        "type": "comment"
                                    }
                                ]
                            }
                        ]
                    },
                    {
                        "by": "elforce002",
                        "id": 39810308,
                        "parent": 39810189,
                        "text": "This. I work in a startup and told upper management we need to keep focusing on ML models that bring tangible benefits to our customers and then, try to integrate LLMs into their current flow instead of pivoting completely to LLMs. It seems they valued the input and now we&#x27;re going for a hybrid approach.",
                        "time": 1711312837,
                        "type": "comment"
                    },
                    {
                        "by": "throwaway74432",
                        "id": 39810529,
                        "kids": [
                            39810575,
                            39810753,
                            39810577
                        ],
                        "parent": 39810189,
                        "text": "Hear hear. I know a 3 person startup that has a &quot;lead AI researcher&quot; who is trying to train and fine-tune models. That&#x27;s not their startup&#x27;s purpose though... they have an actual product. So wtf are they doing? The lead AI guy thinks he&#x27;s going to compete with these big companies and it&#x27;s total fantasy.<p>LLMs are a <i>commodity</i>",
                        "time": 1711314420,
                        "type": "comment",
                        "comments": [
                            {
                                "by": "qeternity",
                                "id": 39810575,
                                "parent": 39810529,
                                "text": "That does indeed sound crazy. But finetuning is also a commodity these days. You can train a good Mistral LoRA in under 24 hours on a single consumer GPU. We\u2019re talking about $10 of compute.<p>You can run a dozen of these LoRAs atop the same base model on the same infrastructure for a dozen specific use cases.<p>The inference quality, performance and cost can all be substantially better than GPT4 with prompting.",
                                "time": 1711314864,
                                "type": "comment"
                            },
                            {
                                "by": "VirusNewbie",
                                "id": 39810753,
                                "parent": 39810529,
                                "text": "Doesn&#x27;t it entirely depend on how specialized the training data for a given fine tuned model might be?",
                                "time": 1711316360,
                                "type": "comment"
                            },
                            {
                                "deleted": true,
                                "id": 39810577,
                                "parent": 39810529,
                                "time": 1711314903,
                                "type": "comment"
                            }
                        ]
                    },
                    {
                        "by": "seydor",
                        "id": 39810467,
                        "parent": 39810189,
                        "text": "Your advise is based on what?",
                        "time": 1711313926,
                        "type": "comment"
                    },
                    {
                        "by": "jnwatson",
                        "id": 39810319,
                        "kids": [
                            39810427,
                            39810537,
                            39810438
                        ],
                        "parent": 39810189,
                        "text": "It is trivial to fine tune these days. RAG is already irrelevant with large context windows.",
                        "time": 1711312916,
                        "type": "comment",
                        "comments": [
                            {
                                "by": "Xenoamorphous",
                                "id": 39810427,
                                "kids": [
                                    39810805
                                ],
                                "parent": 39810319,
                                "text": "&gt; RAG is already irrelevant with large context windows<p>Just last Friday I took the contents of the 2024 folder of one of the teams at the company I work for, for which we use RAG at the moment. I dumped the text index, concatenated it and used Google\u2019s API to return the token count, to see if it would fit in Gemini\u2019s 1M context window; turned out it was 5.7M tokens. And that\u2019s less than 3 months worth of documents for that team.<p>So yeah RAG is not dead yet, although I do question its usefulness, but that\u2019s a separate topic.",
                                "time": 1711313680,
                                "type": "comment",
                                "comments": [
                                    {
                                        "by": "greenavocado",
                                        "id": 39810805,
                                        "kids": [
                                            39811050
                                        ],
                                        "parent": 39810427,
                                        "text": "Did I read this correctly? You uploaded millions of words of your company&#x27;s internal communications to Google?",
                                        "time": 1711316826,
                                        "type": "comment",
                                        "comments": [
                                            {
                                                "by": "Xenoamorphous",
                                                "id": 39811050,
                                                "parent": 39810805,
                                                "text": "I did. But this is under an enterprise deal with them that warrants privacy, not the generally available stuff. OpenAI has similar arrangements (Enterprise ChatGPT) and MS Azure before them.",
                                                "time": 1711319024,
                                                "type": "comment"
                                            }
                                        ]
                                    }
                                ]
                            },
                            {
                                "by": "SgtBastard",
                                "id": 39810537,
                                "parent": 39810319,
                                "text": "A remarkable comment in that it is clear, confident and wrong.<p>Fine-tunes lead to catastrophic forgetting.<p>RAG is only irrelevant if you\u2019re completely disinterested in cost and latency.<p>We also don\u2019t have enough data to gauge performance of models &gt;200k context window size when reasoning over inputs of that size, much of which will be irrelevant to any particular user. Multiple random needles in haystack tests work flawlessly, but rarely applies to real world activity.",
                                "time": 1711314453,
                                "type": "comment"
                            },
                            {
                                "by": "simonw",
                                "id": 39810438,
                                "kids": [
                                    39810842
                                ],
                                "parent": 39810319,
                                "text": "Citation needed on &quot;trivial to fine tune&quot;.",
                                "time": 1711313742,
                                "type": "comment",
                                "comments": [
                                    {
                                        "by": "danielmarkbruce",
                                        "id": 39810842,
                                        "kids": [
                                            39811640
                                        ],
                                        "parent": 39810438,
                                        "text": "There is no citation needed. It is indeed trivial to fine-tune. Doing a good job is another matter, but the claim is correct. Google around and find a blog post showing how.<p>The claim that RAG is dead is obviously wrong.",
                                        "time": 1711317186,
                                        "type": "comment",
                                        "comments": [
                                            {
                                                "by": "simonw",
                                                "id": 39811640,
                                                "kids": [
                                                    39811976
                                                ],
                                                "parent": 39810842,
                                                "text": "For &quot;citation needed&quot;, read &quot;please link me to a blog post showing how, don&#x27;t just tell me to Google for one&quot;.<p>The internet is full of blog posts about this. That doesn&#x27;t mean they&#x27;re actually good - I&#x27;d love to be pointed at one that has proven itself useful for someone (and definitely isn&#x27;t just LLM blog-spam).<p>I don&#x27;t care if it&#x27;s trivial to fine-tune and get crap results - I care about fine-tuning where the result was worth the effort.<p>For the record, my favourite guide to fine-tuning is the section of this Jeremy Howard video that shows how to train a text-to-SQL model: <a href=\"https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=jkrNMKz9pWU&amp;t=4850s\" rel=\"nofollow\">https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=jkrNMKz9pWU&amp;t=4850s</a>",
                                                "time": 1711324695,
                                                "type": "comment",
                                                "comments": [
                                                    {
                                                        "by": "danielmarkbruce",
                                                        "id": 39811976,
                                                        "kids": [
                                                            39812449,
                                                            39813916
                                                        ],
                                                        "parent": 39811640,
                                                        "text": "It&#x27;s an internet forum, not an academic journal. Water tight arguments are not needed. If one wants to call bs, they can just do it, no need to dance around the topic by asking for a citation.",
                                                        "time": 1711328484,
                                                        "type": "comment",
                                                        "comments": [
                                                            {
                                                                "by": "simonw",
                                                                "id": 39812449,
                                                                "kids": [
                                                                    39817105
                                                                ],
                                                                "parent": 39811976,
                                                                "text": "OK, I call BS. Fine-tuning an LLM is not &quot;trivial&quot; - especially if you want to get useful results, as opposed to just being able to say &quot;look, I fine-tuned an LLM&quot;.",
                                                                "time": 1711334719,
                                                                "type": "comment",
                                                                "comments": [
                                                                    {
                                                                        "by": "danielmarkbruce",
                                                                        "id": 39817105,
                                                                        "parent": 39812449,
                                                                        "text": "Yup, largely agree.",
                                                                        "time": 1711378562,
                                                                        "type": "comment"
                                                                    }
                                                                ]
                                                            },
                                                            {
                                                                "by": "wakaru44",
                                                                "id": 39813916,
                                                                "kids": [
                                                                    39817065
                                                                ],
                                                                "parent": 39811976,
                                                                "text": "Exactly, it&#x27;s a forum not Twitter&#x2F;reddit. Without references and citations this is no better than a bunch of random words, and it&#x27;s hard to make any argument of substance.<p>The person asked for citations, leave it be, stop dudexplaining how Internet works for you please.<p>I call bs on your 2 comments.",
                                                                "time": 1711356029,
                                                                "type": "comment",
                                                                "comments": [
                                                                    {
                                                                        "by": "danielmarkbruce",
                                                                        "id": 39817065,
                                                                        "parent": 39813916,
                                                                        "text": "They didn&#x27;t ask for citations. They pointed out a citation was needed. It was a clever sounding way of calling bs. They admit as much.<p>Even when people sincerely ask for a citation on a debatable topic, on an internet forum, it&#x27;s effectively saying &quot;I won&#x27;t be hear any opinion that doesn&#x27;t match my own unless it&#x27;s as water tight as a law of physics&quot;. Another form of this is &quot;show me the data&quot;.",
                                                                        "time": 1711378365,
                                                                        "type": "comment"
                                                                    }
                                                                ]
                                                            }
                                                        ]
                                                    }
                                                ]
                                            }
                                        ]
                                    }
                                ]
                            }
                        ]
                    }
                ]
            },
            {
                "by": "krasin",
                "id": 39810767,
                "kids": [
                    39812103,
                    39810934
                ],
                "parent": 39809177,
                "text": "Finetuning LLMs is currently the most promising way for next-gen robotics. One of such works (PaLM-e) among other things measured the impact of finetuning on general purpose tasks: <a href=\"https:&#x2F;&#x2F;twitter.com&#x2F;DannyDriess&#x2F;status&#x2F;1632904698108821505\" rel=\"nofollow\">https:&#x2F;&#x2F;twitter.com&#x2F;DannyDriess&#x2F;status&#x2F;1632904698108821505</a><p>In short, an 8B model could degrade almost 10x after being finetuned on robotics tasks, while 500B model experiences a very minor degradation (~4%) and there&#x27;s a hope that with a larger-sized model, it could become either zero or even negative (adding more experience improves general purpose reasoning).<p>What I am saying is that while GPT-4 could beat a finetuned GPT-3.5 class model, I predict good things about finetuned GPT-4 class models, when they become practical outside of OpenAI&#x2F;Google.",
                "time": 1711316443,
                "type": "comment",
                "comments": [
                    {
                        "by": "gradascent",
                        "id": 39812103,
                        "kids": [
                            39812411,
                            39813421
                        ],
                        "parent": 39810767,
                        "text": "Interesting! I would like to learn more about how AI is being applied to robotics. Do you have any suggestions for how to keep up with developments&#x2F;ideas in this field?",
                        "time": 1711329846,
                        "type": "comment",
                        "comments": [
                            {
                                "by": "krasin",
                                "id": 39812411,
                                "parent": 39812103,
                                "text": "These two links could be a good start:<p>ALOHA-2: <a href=\"https:&#x2F;&#x2F;aloha-2.github.io&#x2F;\" rel=\"nofollow\">https:&#x2F;&#x2F;aloha-2.github.io&#x2F;</a><p>RT-X: <a href=\"https:&#x2F;&#x2F;robotics-transformer-x.github.io&#x2F;\" rel=\"nofollow\">https:&#x2F;&#x2F;robotics-transformer-x.github.io&#x2F;</a>",
                                "time": 1711334077,
                                "type": "comment"
                            },
                            {
                                "by": "hlfshell",
                                "id": 39813421,
                                "kids": [
                                    39814000
                                ],
                                "parent": 39812103,
                                "text": "In October I wrote a blogpost on this subject: <a href=\"https:&#x2F;&#x2F;hlfshell.ai&#x2F;posts&#x2F;llms-and-robotics-papers-2023&#x2F;\" rel=\"nofollow\">https:&#x2F;&#x2F;hlfshell.ai&#x2F;posts&#x2F;llms-and-robotics-papers-2023&#x2F;</a><p>..and plan to do an updated version soon for much of what&#x27;s been released since. I&#x27;ve also done work related to LLM and robotics integration, also on that site.<p>Happy to chat about it.",
                                "time": 1711350284,
                                "type": "comment",
                                "comments": [
                                    {
                                        "by": "newswasboring",
                                        "id": 39814000,
                                        "kids": [
                                            39818029
                                        ],
                                        "parent": 39813421,
                                        "text": "Working my way through your blog post and it is so refreshing. Unfortunately my algorithm currently is showing me takes which are extreme on either end (like in your blog post).<p>&gt; Technology\u2019s largest leaps occur when new tools are provided to those that want to make things.<p>I love this sentence. And the general attitude of curiosity of your post.",
                                        "time": 1711357032,
                                        "type": "comment",
                                        "comments": [
                                            {
                                                "by": "hlfshell",
                                                "id": 39818029,
                                                "parent": 39814000,
                                                "text": "Thanks! Appreciate the kind words. I should have in the next month or so (interviewing and finishing my Master&#x27;s, so there&#x27;s been delays) a follow up that follows more advancements in the router style VLA, sensoiromotor VLM, and advances in embedding enriched vision models in general.<p>If you want a great overview of what a modern robotics stack would look like with all this, <a href=\"https:&#x2F;&#x2F;ok-robot.github.io&#x2F;\" rel=\"nofollow\">https:&#x2F;&#x2F;ok-robot.github.io&#x2F;</a> was really good and will likely make it into the article. It&#x27;s a VLA combined with existing RL methods to demonstrate multi-tasking robots, and serves as a great glimpes into what a lot of researchers are working on. You won&#x27;t see these techniques in robots in industrial or commercial settings - we&#x27;re still too new at this to be reliable or capable enough to deploy these on real tasks.",
                                                "time": 1711382739,
                                                "type": "comment"
                                            }
                                        ]
                                    }
                                ]
                            }
                        ]
                    },
                    {
                        "by": "TMWNN",
                        "id": 39810934,
                        "kids": [
                            39811566
                        ],
                        "parent": 39810767,
                        "text": "&gt;there&#x27;s a hope that with a larger-sized model, it could become either zero or even negative (adding more experience improves general purpose reasoning).<p>The best single work of fiction ever created about LLMs&#x27; capabilities (and, perhaps, dangers) is <i>Colossus</i> by Jones. Although I think the film is even better than the book, only the latter mentions how, despite being created specifically for US national defense, Colossus is also fed unrelated data including Shakespeare&#x27;s sonnets, because its creators do not know if it could be important.",
                        "time": 1711317982,
                        "type": "comment",
                        "comments": [
                            {
                                "by": "paulmd",
                                "id": 39811566,
                                "parent": 39810934,
                                "text": "What good is a revolution without dancing?",
                                "time": 1711323925,
                                "type": "comment"
                            }
                        ]
                    }
                ]
            },
            {
                "by": "minimaxir",
                "id": 39809825,
                "kids": [
                    39810176,
                    39810496,
                    39810162,
                    39809996,
                    39810651
                ],
                "parent": 39809177,
                "text": "Extremely hot LLM take: You will often get better results with few-shot prompting (with good examples) on a modern LLM than with a finetuned LLM.<p>Finetuning was the best option for weaker LLMs with lower context windows (e.g. the original GPT-3): both problems have been solved nowadays.<p>The cost economics are much better with few-shot prompting to modern LLMs too: input tokens are super cheap (especially with the recently-released Claude Haiku), so giving a lot of examples per call will still end up cheaper than finetuning.<p>Meanwhile, a finetuned ChatGPT costs 4-6x of normal ChatGPT usage.",
                "time": 1711309743,
                "type": "comment",
                "comments": [
                    {
                        "by": "zapperdulchen",
                        "id": 39810176,
                        "kids": [
                            39810572,
                            39810824,
                            39811594,
                            39810384
                        ],
                        "parent": 39809825,
                        "text": "Seems like the bitter lesson is still right: <a href=\"http:&#x2F;&#x2F;www.incompleteideas.net&#x2F;IncIdeas&#x2F;BitterLesson.html\" rel=\"nofollow\">http:&#x2F;&#x2F;www.incompleteideas.net&#x2F;IncIdeas&#x2F;BitterLesson.html</a>",
                        "time": 1711311987,
                        "type": "comment",
                        "comments": [
                            {
                                "by": "nialse",
                                "id": 39810572,
                                "parent": 39810176,
                                "text": "For those who were oblivious to it, like myself, the bitter lesson is written by  Richard S Sutton who invented reinforcement learning a long, long time ago.",
                                "time": 1711314849,
                                "type": "comment"
                            },
                            {
                                "by": "tomrod",
                                "id": 39810824,
                                "parent": 39810176,
                                "text": "This is an earth-shattering read.",
                                "time": 1711316996,
                                "type": "comment"
                            },
                            {
                                "by": "pbronez",
                                "id": 39811594,
                                "kids": [
                                    39812931
                                ],
                                "parent": 39810176,
                                "text": "I can\u2019t access the article there\u2026 SSL error and then timeout. Here\u2019s a link to the most recent WayBackMachine snapshot:<p><a href=\"https:&#x2F;&#x2F;web.archive.org&#x2F;web&#x2F;20240321091803&#x2F;https:&#x2F;&#x2F;www.incompleteideas.net&#x2F;IncIdeas&#x2F;BitterLesson.html\" rel=\"nofollow\">https:&#x2F;&#x2F;web.archive.org&#x2F;web&#x2F;20240321091803&#x2F;https:&#x2F;&#x2F;www.incom...</a>",
                                "time": 1711324238,
                                "type": "comment",
                                "comments": [
                                    {
                                        "by": "port443",
                                        "id": 39812931,
                                        "parent": 39811594,
                                        "text": "There&#x27;s no SSL at all on that site, since it&#x27;s http not https. Your browser is breaking the link.",
                                        "time": 1711341919,
                                        "type": "comment"
                                    }
                                ]
                            },
                            {
                                "by": "Solvency",
                                "id": 39810384,
                                "kids": [
                                    39810543,
                                    39810549
                                ],
                                "parent": 39810176,
                                "text": "Whoa this guy says &quot;computation&quot; and not grammatically bastardized techbrospeak &quot;compute&quot; like some neckbeard equivalent of a caveman!<p>For that alone I commend him.",
                                "time": 1711313339,
                                "type": "comment",
                                "comments": [
                                    {
                                        "by": "jorvi",
                                        "id": 39810543,
                                        "kids": [
                                            39810602,
                                            39810883,
                                            39810738
                                        ],
                                        "parent": 39810384,
                                        "text": "Compute is.. I don\u2019t know the exact English grammatical term but it\u2019s like water. Computation is not.<p>\u201cI have 1000 flops of compute\u201d - works.<p>\u201cI have 1000 flops of computation\u201d - doesn\u2019t work.<p>\u201cThat compute failed\u201d - doesn\u2019t work.<p>\u201cThat computation failed\u201d - works.<p>They\u2019re different.",
                                        "time": 1711314496,
                                        "type": "comment",
                                        "comments": [
                                            {
                                                "by": "thewakalix",
                                                "id": 39810602,
                                                "parent": 39810543,
                                                "text": "<a href=\"https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Mass_noun\" rel=\"nofollow\">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Mass_noun</a>",
                                                "time": 1711315056,
                                                "type": "comment"
                                            },
                                            {
                                                "by": "xanderlewis",
                                                "id": 39810883,
                                                "kids": [
                                                    39812044
                                                ],
                                                "parent": 39810543,
                                                "text": "As far as I know, it\u2019s usually called an <i>uncountable noun</i>.<p>\u2026but \u2018computation\u2019 is also uncountable, and your second sentence seems to be perfectly fine to me.<p>Your examples do not constitute an argument. You haven\u2019t articulated the (purported) difference between the two words; you\u2019ve just decided arbitrarily that some sentences don\u2019t work, and not elaborated or explained at all.<p>I can make up words too, and provide example sentences: \u201ckarrotz are delicious\u201d works. \u201ccarrots are delicious\u201d doesn\u2019t. \u201cinside the karrotz\u201d doesn\u2019t work. \u201cinside the carrots\u201d does.<p>I don\u2019t actually think there is any difference. The above comment about \u2018brospeak\u2019 was snarky but I do think it\u2019s more of a cultural phenomenon than a semantic one \u2014 unless someone is willing to kindly explain the difference rather than just rolling their eyes!<p>What <i>exactly</i> is wrong with the sentence \u2018this would require huge amounts of computation\u2019? Saying \u2018compute\u2019 seems more to be a synonym of \u2018computation\u2019 that\u2019s caught on recently than a useful gap-filling addition to the language. Again: reasoned arguments please. Or just \u2018we think it sounds cool so we use it\u2019 \u2014 that\u2019s fine, too.<p>EDIT: pondering briefly, perhaps one could argue the difference is something like \u2018you can <i>own</i> compute, but you can\u2019t own computation.\u2019 \u2018Compute\u2019 is the capacity to carry out computation. \u2026although \u2018compute\u2019 seems to be used to refer to the \u2018abstract\u2019 computation being done as well as the computational resources, so I don\u2019t know.<p>I\u2019m stretching it. To be honest I\u2019m not sure it\u2019s a useful (or even real) distinction. I think it\u2019s a matter of fashion, and that\u2019s fine and normal.",
                                                "time": 1711317547,
                                                "type": "comment",
                                                "comments": [
                                                    {
                                                        "deleted": true,
                                                        "id": 39812044,
                                                        "parent": 39810883,
                                                        "time": 1711329193,
                                                        "type": "comment"
                                                    }
                                                ]
                                            },
                                            {
                                                "by": "Solvency",
                                                "id": 39810738,
                                                "parent": 39810543,
                                                "text": "Literally not true. Compute is a verb. Computation is the right word in all of those cases. Or computational &lt;noun&gt;.",
                                                "time": 1711316156,
                                                "type": "comment"
                                            }
                                        ]
                                    },
                                    {
                                        "deleted": true,
                                        "id": 39810549,
                                        "parent": 39810384,
                                        "time": 1711314594,
                                        "type": "comment"
                                    }
                                ]
                            }
                        ]
                    },
                    {
                        "by": "marviel",
                        "id": 39810496,
                        "kids": [
                            39816439,
                            39810782
                        ],
                        "parent": 39809825,
                        "text": "Several MSFT AI&#x2F;ML friends actively dissuaded me and my team from fine-tuning. They said that it&#x27;s pretty clear in all their internal tests that it &quot;lobotomizes&quot; the general reasoning capabilities of the model, unless you&#x27;re really careful.<p>&quot;All work and no play makes GPT a very dull AI&quot;",
                        "time": 1711314104,
                        "type": "comment",
                        "comments": [
                            {
                                "by": "Ambix",
                                "id": 39816439,
                                "parent": 39810496,
                                "text": "Yes, that&#x27;s what I&#x27;ve seen from a lot of my experiments with fine-tuning. One should be really careful to not &quot;lobotomize&quot; already capable model and achieve better results at the end. It&#x27;s trickier than seems from multiple of tutorials.<p>But I believe that most of the data stored in foundation models are just useless for some particular domain. So it&#x27;s better to forget something, getting really useful info instead.",
                                "time": 1711375348,
                                "type": "comment"
                            },
                            {
                                "by": "FrustratedMonky",
                                "id": 39810782,
                                "kids": [
                                    39810955
                                ],
                                "parent": 39810496,
                                "text": "&quot;bitter lesson that building in how we think we think does not work in the long run&quot;<p>Guess. Stop trying to shape the NN. And let it learn on its own.",
                                "time": 1711316584,
                                "type": "comment",
                                "comments": [
                                    {
                                        "by": "TMWNN",
                                        "id": 39810955,
                                        "kids": [
                                            39815473
                                        ],
                                        "parent": 39810782,
                                        "text": "&gt;And let it learn on its own.<p>The best single work of fiction ever created about LLMs&#x27; capabilities (and, perhaps, dangers) is <i>Colossus</i> by Jones. Although I think the film is even better than the book, only the latter mentions how, despite being created specifically for US national defense, Colossus is also fed unrelated data including Shakespeare&#x27;s sonnets, because its creators do not know if it could be important.",
                                        "time": 1711318103,
                                        "type": "comment",
                                        "comments": [
                                            {
                                                "by": "FrustratedMonky",
                                                "id": 39815473,
                                                "parent": 39810955,
                                                "text": "I think the movie Colossus still holds up today.  Saw it last year, It was pretty scary.",
                                                "time": 1711369766,
                                                "type": "comment"
                                            }
                                        ]
                                    }
                                ]
                            }
                        ]
                    },
                    {
                        "by": "thorum",
                        "id": 39810162,
                        "kids": [
                            39810335
                        ],
                        "parent": 39809825,
                        "text": "That might be true for finetuning ChatGPT 3.5, but if you can finetune a small model (7B or less) to perform on par with GPT-4, while being faster and private, that\u2019s a different story.",
                        "time": 1711311868,
                        "type": "comment",
                        "comments": [
                            {
                                "by": "smallnamespace",
                                "id": 39810335,
                                "kids": [
                                    39810556
                                ],
                                "parent": 39810162,
                                "text": "You definitely can&#x27;t in the general case (for example, your 7B model is never going to be able to help much with coding, fine tuning or no).<p>It can make sense if you have a particularly simple use case.",
                                "time": 1711312989,
                                "type": "comment",
                                "comments": [
                                    {
                                        "by": "qeternity",
                                        "id": 39810556,
                                        "kids": [
                                            39812588
                                        ],
                                        "parent": 39810335,
                                        "text": "By definition you wouldn\u2019t fine tune a 7B model to be generally as good at GPT4. You would just be trying to overfit some small amount of functionality in a narrow domain.",
                                        "time": 1711314651,
                                        "type": "comment",
                                        "comments": [
                                            {
                                                "by": "smallnamespace",
                                                "id": 39812588,
                                                "parent": 39810556,
                                                "text": "Yes but from the context of this discussion, we\u2019re trying to figure out the \u201csweet spot\u201d model size where it\u2019s worth attempting fine tuning. My guess is it\u2019s only worthwhile for matching simple tasks with small models, and any sufficiently complicated task it\u2019s better to do few&#x2F;zero shot instead.",
                                                "time": 1711336836,
                                                "type": "comment"
                                            }
                                        ]
                                    }
                                ]
                            }
                        ]
                    },
                    {
                        "by": "viksit",
                        "id": 39809996,
                        "kids": [
                            39810082,
                            39810127
                        ],
                        "parent": 39809825,
                        "text": "can you give a few pointers on articles or examples of this?",
                        "time": 1711310712,
                        "type": "comment",
                        "comments": [
                            {
                                "by": "minimaxir",
                                "id": 39810082,
                                "kids": [
                                    39810142
                                ],
                                "parent": 39809996,
                                "text": "A low-tech example to create a good blog post title for submission to Hacker News would be a system prompt like:<p><pre><code>    You are an expert copywriter. Write five distinct blog post titles optimized for high clickthrough for Hacker News for the article the user provides.\n\n    Your response must follow the style of these titles:\n      - The \u00fc&#x2F;\u00fc Conundrum\n      - Why isn&#x27;t preprint review being adopted?\n      - Majority of web apps could just run on a single server\n      - Weather Planning for Eclipse Day\n      - PSChess \u2013 A chess engine in PostScript\n</code></pre>\nThen provide the blog post as the user message input.<p>I just ran one of my blog posts (<a href=\"https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=39495476\">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=39495476</a>) with the workflow through Claude Haiku and got this:<p><pre><code>    Here are five distinct blog post titles optimized for high clickthrough on Hacker News for the article provided:\n\n    1. Tipping ChatGPT: Does Offering Monetary Incentives Improve AI Text Generation?\n\n    2. Quantifying the Impact of Incentives on Large Language Model Performance\n\n    3. Carrot or Stick? Exploring the Effects of Positive and Negative Prompts on ChatGPT\n\n    4. Gamifying AI: Using &quot;Generation Golf&quot; to Test ChatGPT&#x27;s Ability to Follow Length Constraints\n\n    5. The Curious Case of ChatGPT&#x27;s Motivations: Can an AI Be Incentivized Like Humans?\n</code></pre>\nNot bad titles, although more verbose than the 5 input examples I gave. I only gave 5 for simplicity: my main point is that you can give it a <i>lot</i> more than five and&#x2F;or be more aggressive with constraints, like the blog post linked incidentially.",
                                "time": 1711311276,
                                "type": "comment",
                                "comments": [
                                    {
                                        "by": "viksit",
                                        "id": 39810142,
                                        "kids": [
                                            39810200
                                        ],
                                        "parent": 39810082,
                                        "text": "interesting thank you.<p>intuitively, prompting like this to get an answer seems basically like the first part of a fine tuning process (more exemplars).<p>what is your thought here behind why reinforcing good output via a loss optimization is worse than the one shot example? does the model start to over fit at some point towards some local minima? and this is avoided in this scenario?",
                                        "time": 1711311695,
                                        "type": "comment",
                                        "comments": [
                                            {
                                                "by": "minimaxir",
                                                "id": 39810200,
                                                "parent": 39810142,
                                                "text": "Prompt engineering in general is necessary because LLMs optimize for the <i>average</i> output, and average output is not good. So LLMs need a slight nudge.",
                                                "time": 1711312170,
                                                "type": "comment"
                                            }
                                        ]
                                    }
                                ]
                            },
                            {
                                "by": "netdur",
                                "id": 39810127,
                                "parent": 39809996,
                                "text": "Use Gemini 1.5 Pro, which has 1.5 million tokens. Prompt it with a logical question and observe it struggling to answer. Then, upload a book on logical thinking in PDF format and ask the same question again. Notice how it can now answer the question effectively.",
                                "time": 1711311600,
                                "type": "comment"
                            }
                        ]
                    },
                    {
                        "by": "jna_sh",
                        "id": 39810651,
                        "parent": 39809825,
                        "text": "\u201cModern\u201d is an extremely funny delineation given the small temporal window of this whole thing",
                        "time": 1711315424,
                        "type": "comment"
                    }
                ]
            },
            {
                "by": "kcorbitt",
                "id": 39810857,
                "parent": 39809177,
                "text": "IMO it&#x27;s possible to over-generalize from this datapoint (lol). While it&#x27;s true that creating a general &quot;finance&quot; model that&#x27;s stronger than GPT-4 is hard, training a task-specific model is much easier. Eg. &quot;a model that&#x27;s better than GPT-4 at answering finance-related questions&quot;: very hard. &quot;A model that&#x27;s better than GPT-4 at extracting forward-looking financial projections in a standard format&quot;: very easy.<p>And in practice, most tasks people are using GPT-4 for in production are more like the latter than the former.<p>(Disclaimer: building <a href=\"https:&#x2F;&#x2F;openpipe.ai\">https:&#x2F;&#x2F;openpipe.ai</a>, which makes it super easy to productize this workflow).",
                "time": 1711317341,
                "type": "comment"
            },
            {
                "by": "MuffinFlavored",
                "id": 39809549,
                "kids": [
                    39809693,
                    39809662,
                    39810193,
                    39809792,
                    39810813,
                    39809904,
                    39810254,
                    39810178,
                    39810051,
                    39810517,
                    39810165
                ],
                "parent": 39809177,
                "text": "Does anything currently beat GPT-4?<p>I saw some comments here say to check out Claude. From what I can tell, Claude hasn&#x27;t figure out yet how to do the whole &quot;generate Python code and run it in a Juptyer notebook&quot; for math yet.",
                "time": 1711308183,
                "type": "comment",
                "comments": [
                    {
                        "by": "rubymamis",
                        "id": 39809693,
                        "kids": [
                            39810820,
                            39810936
                        ],
                        "parent": 39809549,
                        "text": "A programming task where Mistral-large beats both GPT-4 and Claude Opus: <a href=\"https:&#x2F;&#x2F;sdk.vercel.ai&#x2F;s&#x2F;Thi7RDx9e8VOZo1Ee6We5\" rel=\"nofollow\">https:&#x2F;&#x2F;sdk.vercel.ai&#x2F;s&#x2F;Thi7RDx9e8VOZo1Ee6We5</a> (only Mistral got the current syntax)<p>Although based on other tasks, overall, GPT-4 seems to be the best, but by a very small margin, so I cancelled my subscription. Although the native mobile app is really great.",
                        "time": 1711309001,
                        "type": "comment",
                        "comments": [
                            {
                                "by": "fragmede",
                                "id": 39810820,
                                "kids": [
                                    39814178
                                ],
                                "parent": 39809693,
                                "text": "Is there a way to use Mistral-large with TTS and STT engines so you can converse with it like you can ChatGPT in the mobile app? it&#x27;s really great on long drives for learning&#x2F;talking about stuff, like a customized personal podcast.",
                                "time": 1711316937,
                                "type": "comment",
                                "comments": [
                                    {
                                        "by": "rubymamis",
                                        "id": 39814178,
                                        "parent": 39810820,
                                        "text": "Exactly, I absolutely love this feature. And many times the conversation is quite natural and fluid (with good internet connection). I think I&#x27;ll build something like that myself (:",
                                        "time": 1711358943,
                                        "type": "comment"
                                    }
                                ]
                            },
                            {
                                "by": "cosmojg",
                                "id": 39810936,
                                "kids": [
                                    39814195
                                ],
                                "parent": 39809693,
                                "text": "Do you prefer Mistral-Large or Claude-Opus?",
                                "time": 1711317991,
                                "type": "comment",
                                "comments": [
                                    {
                                        "by": "rubymamis",
                                        "id": 39814195,
                                        "parent": 39810936,
                                        "text": "Not sure. Most of the time GPT-4 is better. Since I&#x27;m using Vercel AI playground[1], on almost every query I get a response from all models so it&#x27;s easy to compare.<p>[1] <a href=\"https:&#x2F;&#x2F;sdk.vercel.ai&#x2F;\" rel=\"nofollow\">https:&#x2F;&#x2F;sdk.vercel.ai&#x2F;</a>",
                                        "time": 1711359053,
                                        "type": "comment"
                                    }
                                ]
                            }
                        ]
                    },
                    {
                        "by": "monsieurbanana",
                        "id": 39809662,
                        "kids": [
                            39809735
                        ],
                        "parent": 39809549,
                        "text": "Isn&#x27;t that something you get from the infrastructure surrounding the llm? I thought the &quot;running code&quot; feature didn&#x27;t need specific support from the llm, besides being able to output conforming json or code when asked to.",
                        "time": 1711308803,
                        "type": "comment",
                        "comments": [
                            {
                                "by": "MuffinFlavored",
                                "id": 39809735,
                                "kids": [
                                    39810401,
                                    39810921,
                                    39809887
                                ],
                                "parent": 39809662,
                                "text": "The LLM (Claude) currently doesn&#x27;t know to not hallucinate numbers and instead write code + run it (something ChatGPT used to do but they fixed it)",
                                "time": 1711309232,
                                "type": "comment",
                                "comments": [
                                    {
                                        "by": "simonw",
                                        "id": 39810401,
                                        "kids": [
                                            39810804
                                        ],
                                        "parent": 39809735,
                                        "text": "That&#x27;s because the Claude web UI doesn&#x27;t yet have the equivalent of the ChatGPT Code Interpreter tool (though they say they&#x27;re working on it). That&#x27;s not about the quality of the Claude 3 Opus model, which is the model which people think compares to or beats GPT-4. It&#x27;s about the tooling that has been built for ChatGPT.",
                                        "time": 1711313442,
                                        "type": "comment",
                                        "comments": [
                                            {
                                                "by": "fragmede",
                                                "id": 39810804,
                                                "parent": 39810401,
                                                "text": "Code interpreter is pretty neat, because you can tell ChatGPT to write some code and to make sure the code works, and then it&#x27;ll write you some bad code, realize it&#x27;s bad, and then iterate on it until it gets to a place that it&#x27;s happy with. (Maybe I should say passes its test rather than anthropomorphize ChatGPT as being &quot;happy&quot;.)",
                                                "time": 1711316814,
                                                "type": "comment"
                                            }
                                        ]
                                    },
                                    {
                                        "by": "cosmojg",
                                        "id": 39810921,
                                        "kids": [
                                            39820580
                                        ],
                                        "parent": 39809735,
                                        "text": "Right, like the other commenter suggested, that&#x27;s an infrastructure-level thing, not a model-level thing. Given that you&#x27;re talking about ChatGPT, I assume you aren&#x27;t accessing GPT-3.5 or GPT-4 directly through the API but using the app or the interface provided at chat.openai.com. The magic that makes the kinds of interactions you&#x27;re describing possible amounts to a bit of clever prompting sprinkled on top of some rather impressive frontend design and engineering.<p>Correctly prompted, even Mistral-7B can write and run code in response to questions, and it&#x27;s a model that can run on laptops from half a decade ago, with two or three orders of magnitude fewer parameters that GPT-4.",
                                        "time": 1711317879,
                                        "type": "comment",
                                        "comments": [
                                            {
                                                "by": "MuffinFlavored",
                                                "id": 39820580,
                                                "parent": 39810921,
                                                "text": "&gt; Right, like the other commenter suggested, that&#x27;s an infrastructure-level thing, not a model-level thing.<p>By default, the ChatGPT &quot;model&quot; knows to not try to do math and instead write code to do the math then run it. I get that it&#x27;s set up infrastructure wise to be able to run it, but why is Claude&#x27;s main chat UI not trying to instead respond<p>&quot;hey, do this calculation on your own since I can&#x27;t&quot; or something of this nature instead of responding to math incorrectly",
                                                "time": 1711396411,
                                                "type": "comment"
                                            }
                                        ]
                                    },
                                    {
                                        "by": "avree",
                                        "id": 39809887,
                                        "parent": 39809735,
                                        "text": "Doesn&#x27;t seem like you are very informed on how LLMs work, but just so you know, there are many different versions of Claude, just like how ChatGPT can use different versions of GPT.",
                                        "time": 1711310099,
                                        "type": "comment"
                                    }
                                ]
                            }
                        ]
                    },
                    {
                        "by": "thorum",
                        "id": 39810193,
                        "kids": [
                            39810414
                        ],
                        "parent": 39809549,
                        "text": "I don\u2019t know what the people who say Claude 3 is better than GPT-4 are using it for. It\u2019s been consistently worse for everything I\u2019ve thrown at it.<p>Debugging a Python function this morning. Claude 3 Opus failed completely. GPT-4 found the bug, as well as two others I hadn\u2019t even been looking for.",
                        "time": 1711312120,
                        "type": "comment",
                        "comments": [
                            {
                                "by": "simonw",
                                "id": 39810414,
                                "kids": [
                                    39810799
                                ],
                                "parent": 39810193,
                                "text": "I&#x27;ve had the opposite experience: coding prompts that GPT-4 makes mistakes on Claude 3 Opus gets right the first time.<p>As always, your results will vary based on your personal prompting style. My style apparently works great with Opus.<p>Here&#x27;s one example: GPT-4 gave me code that was missing some async&#x2F;await keywords: <a href=\"https:&#x2F;&#x2F;chat.openai.com&#x2F;share&#x2F;117fb1ad-6361-41e2-be59-110f3262594d\" rel=\"nofollow\">https:&#x2F;&#x2F;chat.openai.com&#x2F;share&#x2F;117fb1ad-6361-41e2-be59-110f32...</a><p>Claude 3 Opus with the same prompt got it right the first time: <a href=\"https:&#x2F;&#x2F;gist.github.com&#x2F;simonw&#x2F;2002e2b56a97053bd9302a34e0b83074\" rel=\"nofollow\">https:&#x2F;&#x2F;gist.github.com&#x2F;simonw&#x2F;2002e2b56a97053bd9302a34e0b83...</a>",
                                "time": 1711313578,
                                "type": "comment",
                                "comments": [
                                    {
                                        "by": "brianjking",
                                        "id": 39810799,
                                        "parent": 39810414,
                                        "text": "Yeah, Opus has entirely taken over any code specific use for me over ChatGPT 4 or OpenAI GPT-4 API.<p>Once Opus has the ability to run a code interpreter, it&#x27;ll really be an exciting time.",
                                        "time": 1711316735,
                                        "type": "comment"
                                    }
                                ]
                            }
                        ]
                    },
                    {
                        "by": "geor9e",
                        "id": 39809792,
                        "parent": 39809549,
                        "text": "I don&#x27;t know what system and user prompt you are testing with, but as one anecdote, Claude 3 Opus (and only Opus) consistently gives me better coding answers than GPT-4. Maybe it&#x27;s the type of stuff I am doing or how I phrase things, who knows. I was using GPT-4 since the day it came out but haven&#x27;t felt like going back so far.",
                        "time": 1711309570,
                        "type": "comment"
                    },
                    {
                        "by": "dragonwriter",
                        "id": 39810813,
                        "parent": 39809549,
                        "text": "&gt; Claude hasn&#x27;t figure out yet how to do the whole &quot;generate Python code and run it in a Juptyer notebook&quot; for math yet.<p>GPT-4 didn&#x27;t figure that out, either; that\u2019s just tooling built around the model, not something the model \u201cfigures out\u201d.",
                        "time": 1711316885,
                        "type": "comment"
                    },
                    {
                        "by": "jxdxbx",
                        "id": 39809904,
                        "parent": 39809549,
                        "text": "Claude is better than GPT 4 for my uses, and was able to help me do some simple coding things that GPT 4 could not. It\u2019s worth trying at least.",
                        "time": 1711310201,
                        "type": "comment"
                    },
                    {
                        "by": "drexlspivey",
                        "id": 39810254,
                        "parent": 39809549,
                        "text": "According to Chatbot Arena where people vote on responses blindly and an ELO rating is determined for each LLM, gpt4 is on top slightly ahead of Claude 3 Opus<p><a href=\"https:&#x2F;&#x2F;huggingface.co&#x2F;spaces&#x2F;lmsys&#x2F;chatbot-arena-leaderboard\" rel=\"nofollow\">https:&#x2F;&#x2F;huggingface.co&#x2F;spaces&#x2F;lmsys&#x2F;chatbot-arena-leaderboar...</a>",
                        "time": 1711312536,
                        "type": "comment"
                    },
                    {
                        "by": "jasonjmcghee",
                        "id": 39810178,
                        "parent": 39809549,
                        "text": "Claude Opus (largest v3 model) consistently outperforms GPT-4 for me. Better at following prompts, _feels_ much better.",
                        "time": 1711311990,
                        "type": "comment"
                    },
                    {
                        "by": "treprinum",
                        "id": 39810051,
                        "parent": 39809549,
                        "text": "Claude-2 in some tasks albeit it&#x27;s a bit slower, Mistral on some tasks and it&#x27;s a bit faster.",
                        "time": 1711311102,
                        "type": "comment"
                    },
                    {
                        "by": "marviel",
                        "id": 39810517,
                        "parent": 39809549,
                        "text": "Claude is excellent for brainstorming, being a thought partner, general knowledge acquisition tasks, and creative writing.<p>The one mixed-bag weak spot I&#x27;ve found is in coding -- It tends to make more &quot;d&#x27;oh&quot; mistakes while coding, but comes up with more creative solutions at the same time \u00af\\_(\u30c4)_&#x2F;\u00af",
                        "time": 1711314284,
                        "type": "comment"
                    },
                    {
                        "by": "yieldcrv",
                        "id": 39810165,
                        "parent": 39809549,
                        "text": "The benchmark is Sora or whatever Open AI is working on right now or next, not trying to beat the model released a year ago and still failing<p>so when looking at it that way, the real question is what do you need? all I need is Mixtral 7x8B Q5 in an 8,000 token context window, at the moment<p>I think there are plenty of other people that can design their applications and problems around lower fidelity tools, or just pursue something else",
                        "time": 1711311883,
                        "type": "comment"
                    }
                ]
            },
            {
                "by": "jonplackett",
                "id": 39810860,
                "parent": 39809177,
                "text": "FYI it was <i>GPT-3.5 Class</i> not GPT3.5.<p>A lot of models claim to be GPT3.5 class that clearly are not in the first place.",
                "time": 1711317350,
                "type": "comment"
            },
            {
                "by": "hulium",
                "id": 39810036,
                "kids": [
                    39810134
                ],
                "parent": 39809177,
                "text": "There is also the open source FinGPT, that is claimed to beat GPT4 in some benchmarks at a fine tuning cost of $17.25.<p><a href=\"https:&#x2F;&#x2F;github.com&#x2F;AI4Finance-Foundation&#x2F;FinGPT\">https:&#x2F;&#x2F;github.com&#x2F;AI4Finance-Foundation&#x2F;FinGPT</a>",
                "time": 1711310983,
                "type": "comment",
                "comments": [
                    {
                        "by": "potatoman22",
                        "id": 39810134,
                        "kids": [
                            39811941
                        ],
                        "parent": 39810036,
                        "text": "One major advantage of FinGPT or Bloomberg&#x27;s LLM is that the embeddings produced by the model can be used for downstream prediction tasks. GPT-4 does not expose its embeddings so it cannot be used for this.",
                        "time": 1711311634,
                        "type": "comment",
                        "comments": [
                            {
                                "by": "bernawil",
                                "id": 39811941,
                                "kids": [
                                    39812799
                                ],
                                "parent": 39810134,
                                "text": "sorry, noob here trying to make sense of this: you mean you can extract embeddings from the model file or that the embeddings are available in the repo and you can just use those files?",
                                "time": 1711327992,
                                "type": "comment",
                                "comments": [
                                    {
                                        "by": "potatoman22",
                                        "id": 39812799,
                                        "parent": 39811941,
                                        "text": "Kind of. You feed the LLM the input text for your prediction, you extract the activations of the final layer of the LLM (so the weights * the input of the previous layers), then use that activation vector, or embedding, as the input for a separate model. This separate model that uses the embedding can be any classifier or regression. A common use case for this is document classification.",
                                        "time": 1711339843,
                                        "type": "comment"
                                    }
                                ]
                            }
                        ]
                    }
                ]
            },
            {
                "by": "hallqv",
                "id": 39810544,
                "kids": [
                    39810728
                ],
                "parent": 39809177,
                "text": "This discussion is so dumb - finetuning a base model costs ~$1 with LORA&#x2F;QLORA and can yield same performance as gpt-4, but at 1&#x2F;100 of the cost per token.<p>What Bloomberg did for $10M was not finetuning..",
                "time": 1711314522,
                "type": "comment",
                "comments": [
                    {
                        "by": "simonw",
                        "id": 39810728,
                        "kids": [
                            39812963,
                            39821311
                        ],
                        "parent": 39810544,
                        "text": "&quot;finetuning a base model costs ~$1 with LORA&#x2F;QLORA and can yield same performance as gpt-4, but at 1&#x2F;100 of the cost per token&quot;<p>That&#x27;s a big claim - can you back that up with any examples?",
                        "time": 1711316094,
                        "type": "comment",
                        "comments": [
                            {
                                "by": "Implicated",
                                "id": 39812963,
                                "parent": 39810728,
                                "text": "I had opened a new tab back when this comment was just a few minutes old in hopes that when I came back there was some really great blog post linked with the details on the sorcery.",
                                "time": 1711342460,
                                "type": "comment"
                            },
                            {
                                "by": "hallqv",
                                "id": 39821311,
                                "parent": 39810728,
                                "text": "<a href=\"https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;2402.00841.pdf\" rel=\"nofollow\">https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;2402.00841.pdf</a>",
                                "time": 1711401068,
                                "type": "comment"
                            }
                        ]
                    }
                ]
            },
            {
                "by": "chintler",
                "id": 39809334,
                "kids": [
                    39809560,
                    39809419
                ],
                "parent": 39809177,
                "text": "$10 Million(M), not $10 Billion(B).",
                "time": 1711306541,
                "type": "comment",
                "comments": [
                    {
                        "by": "affgrff2",
                        "id": 39809560,
                        "kids": [
                            39810247
                        ],
                        "parent": 39809334,
                        "text": "Not looking forward for the times when an AI costs as much as an aircraft carrier.",
                        "time": 1711308221,
                        "type": "comment",
                        "comments": [
                            {
                                "by": "moffkalast",
                                "id": 39810247,
                                "parent": 39809560,
                                "text": "At least with an aircraft carrier you can make your money back by holding a small country for ransom, har har.",
                                "time": 1711312504,
                                "type": "comment"
                            }
                        ]
                    },
                    {
                        "by": "CharlesW",
                        "id": 39809419,
                        "parent": 39809334,
                        "text": "Thank you, fixed! Also, direct link to paper: <a href=\"https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;2305.05862.pdf\" rel=\"nofollow\">https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;2305.05862.pdf</a>",
                        "time": 1711307251,
                        "type": "comment"
                    }
                ]
            },
            {
                "by": "thorum",
                "id": 39810232,
                "parent": 39809177,
                "text": "Note that the benchmarks used for comparison are basically measuring the model\u2019s ability to understand financial content. In other words, reading comprehension for English, just in a specific domain. It shouldn\u2019t really be surprising that a strong generalist model performs well here.<p>On the other hand, GPT-4 actually did worse on the NER task - labelling and tagging terms used in the text - vs their finetuned model. I assume the finetuned model was better at using the specific labels they were targeting.",
                "time": 1711312421,
                "type": "comment"
            },
            {
                "by": "Rustwerks",
                "id": 39810439,
                "parent": 39809177,
                "text": "<a href=\"http:&#x2F;&#x2F;www.incompleteideas.net&#x2F;IncIdeas&#x2F;BitterLesson.html\" rel=\"nofollow\">http:&#x2F;&#x2F;www.incompleteideas.net&#x2F;IncIdeas&#x2F;BitterLesson.html</a>",
                "time": 1711313745,
                "type": "comment"
            },
            {
                "by": "jebarker",
                "id": 39809551,
                "kids": [
                    39809614
                ],
                "parent": 39809177,
                "text": "How do they know GPT-4 received no specialized financial training?",
                "time": 1711308186,
                "type": "comment",
                "comments": [
                    {
                        "by": "CharlesW",
                        "id": 39809614,
                        "kids": [
                            39809669
                        ],
                        "parent": 39809551,
                        "text": "Meaning, they used the same generalized foundation model that all of us have access to, with no special fine-tuning, no retrieval-augmented generation, etc.",
                        "time": 1711308519,
                        "type": "comment",
                        "comments": [
                            {
                                "by": "jebarker",
                                "id": 39809669,
                                "kids": [
                                    39809697
                                ],
                                "parent": 39809614,
                                "text": "I don&#x27;t understand your point. To me GPT-4 is not a foundation model, it&#x27;s been highly tuned for the chat task. Nobody outside of OpenAI knows what that fine-tuning really involved. So it&#x27;s impossible to say how much finance specific data it was trained on (in pre-training or fine-tuning) or whether finance specific tasks were involved in fine-tuning.",
                                "time": 1711308839,
                                "type": "comment",
                                "comments": [
                                    {
                                        "by": "CharlesW",
                                        "id": 39809697,
                                        "kids": [
                                            39809757,
                                            39809813
                                        ],
                                        "parent": 39809669,
                                        "text": "&gt; <i>To me GPT-4 is not a foundation model\u2026</i><p>It is. <a href=\"https:&#x2F;&#x2F;www.adalovelaceinstitute.org&#x2F;resource&#x2F;foundation-models-explainer&#x2F;\" rel=\"nofollow\">https:&#x2F;&#x2F;www.adalovelaceinstitute.org&#x2F;resource&#x2F;foundation-mod...</a>",
                                        "time": 1711309013,
                                        "type": "comment",
                                        "comments": [
                                            {
                                                "deleted": true,
                                                "id": 39809757,
                                                "parent": 39809697,
                                                "time": 1711309355,
                                                "type": "comment"
                                            },
                                            {
                                                "by": "jebarker",
                                                "id": 39809813,
                                                "kids": [
                                                    39810149,
                                                    39811550
                                                ],
                                                "parent": 39809697,
                                                "text": "What I was meaning was that ChatGPT is not a foundation model since it&#x27;s been fine-tuned. Although the definition in the link is sufficiently broad you could choose to include it.<p>I can&#x27;t tell from the OpenAI docs whether it&#x27;s possible to access GPT-4 without the ChatGPT fine-tuning. If so, that&#x27;d make this result more meaningful. Otherwise, I just don&#x27;t think you can draw any great conclusions from this.",
                                                "time": 1711309673,
                                                "type": "comment",
                                                "comments": [
                                                    {
                                                        "by": "doctorpangloss",
                                                        "id": 39810149,
                                                        "parent": 39809813,
                                                        "text": "The instruction fine tuning is what manifests knowledge and reasoning.",
                                                        "time": 1711311757,
                                                        "type": "comment"
                                                    },
                                                    {
                                                        "by": "rmbyrro",
                                                        "id": 39811550,
                                                        "parent": 39809813,
                                                        "text": "GPT is general purpose, it&#x27;s not fine tuned for specific topics. A fine tuned model is tuned to a specific subject.",
                                                        "time": 1711323751,
                                                        "type": "comment"
                                                    }
                                                ]
                                            }
                                        ]
                                    }
                                ]
                            }
                        ]
                    }
                ]
            },
            {
                "by": "ldjkfkdsjnv",
                "id": 39809942,
                "kids": [
                    39810000,
                    39810404,
                    39810063
                ],
                "parent": 39809177,
                "text": "Fine tuning will disappear, no reason to invest so heavily in it. Also, most LLM code being written right now (prompts, RAG, etc) will be obsolete once the next model comes out. Anyone starting an LLM application startup is arguably wasting their time, wait until the next iteration is out. Then you will know whats possible.",
                "time": 1711310405,
                "type": "comment",
                "comments": [
                    {
                        "by": "minimaxir",
                        "id": 39810000,
                        "kids": [
                            39810057
                        ],
                        "parent": 39809942,
                        "text": "&gt; Also, most LLM code being written right now (prompts, RAG, etc) will be obsolete once the next model comes out.<p>Not true. Most prompt techniques that work on current modern LLM models will work on different or future models, although it will require a QA pass for any regressions.",
                        "time": 1711310718,
                        "type": "comment",
                        "comments": [
                            {
                                "by": "ldjkfkdsjnv",
                                "id": 39810057,
                                "kids": [
                                    39811061,
                                    39810175,
                                    39810398,
                                    39810171
                                ],
                                "parent": 39810000,
                                "text": "Yeah they will work, but they will also be unnecessary. You will also bake all sorts of logic into your application that will be solved natively on the stronger model. If you believe in the scaling theory, then writing LLM applications is non sensical.",
                                "time": 1711311119,
                                "type": "comment",
                                "comments": [
                                    {
                                        "by": "kergonath",
                                        "id": 39811061,
                                        "parent": 39810057,
                                        "text": "&gt;  If you believe in the scaling theory, then writing LLM applications is non sensical.<p>But not doing it is an opportunity cost. You don\u2019t built skills, tooling and experience, and you don\u2019t get feedback on what works and where you should go.<p>It\u2019s like computers in the 1990s: there\u2019s always a better one 6 months away, so if you wait for it to stabilise, then you don\u2019t do anything for a decade. Just enjoy the ride, bearing in mind that things change very fast and some things will be obsolete next year.",
                                        "time": 1711319097,
                                        "type": "comment"
                                    },
                                    {
                                        "by": "mlyle",
                                        "id": 39810175,
                                        "parent": 39810057,
                                        "text": "&gt; Yeah they will work, but they will also be unnecessary. You will also bake all sorts of logic into your application that will be solved natively on the stronger model.<p>I think that a whole lot of what I do in prompt engineering is what&#x27;s necessary to fully specify the output that I want.<p>A newer model may be less finicky, so I have a higher chance of getting it to work on the first try (and it&#x27;s more reliable afterwards), but it&#x27;s hard for me to imagine it needing a whole lot less prompt.",
                                        "time": 1711311972,
                                        "type": "comment"
                                    },
                                    {
                                        "by": "Xenoamorphous",
                                        "id": 39810398,
                                        "kids": [
                                            39811112,
                                            39810436
                                        ],
                                        "parent": 39810057,
                                        "text": "How will a more powerful model be a substitute for RAG, which is usually used with private data that won\u2019t be present in any training dataset?",
                                        "time": 1711313409,
                                        "type": "comment",
                                        "comments": [
                                            {
                                                "by": "kergonath",
                                                "id": 39811112,
                                                "parent": 39810398,
                                                "text": "One of the idea is to just stuff all the documents in the prompt, which still keeps them private but avoids having to faff around with chunking, embedding, and vector stores. That\u2019s not really the end of RAG as a concept, but it would change all the current tooling and infrastructure we built for it.<p>I don\u2019t think RAG is going away, at least not because of this. But I expect new techniques to become available fairly regularly.",
                                                "time": 1711319432,
                                                "type": "comment"
                                            },
                                            {
                                                "by": "ldjkfkdsjnv",
                                                "id": 39810436,
                                                "parent": 39810398,
                                                "text": "I just think that the capability of the model could radically change, such that however you structured your RAG pipeline, might need to be rewritten. More general problems could be solved by the model, that you were solving with some complicated contraption of prompts.",
                                                "time": 1711313734,
                                                "type": "comment"
                                            }
                                        ]
                                    },
                                    {
                                        "deleted": true,
                                        "id": 39810171,
                                        "parent": 39810057,
                                        "time": 1711311940,
                                        "type": "comment"
                                    }
                                ]
                            }
                        ]
                    },
                    {
                        "by": "rkagerer",
                        "id": 39810404,
                        "kids": [
                            39810503
                        ],
                        "parent": 39809942,
                        "text": "&quot;Don&#x27;t buy a computer today, because the faster one is coming out tomorrow&quot;",
                        "time": 1711313493,
                        "type": "comment",
                        "comments": [
                            {
                                "by": "simonw",
                                "id": 39810503,
                                "parent": 39810404,
                                "text": "Don&#x27;t buy a computer today with a six month delivery lead time, because there&#x27;s a company that releases computers with a same-day lead time with several improved models coming out next week.",
                                "time": 1711314160,
                                "type": "comment"
                            }
                        ]
                    },
                    {
                        "by": "treprinum",
                        "id": 39810063,
                        "parent": 39809942,
                        "text": "OpenAI-related startups are likely using GPT-5 already. Waiting it out won&#x27;t help other startups, they will be too far behind.",
                        "time": 1711311163,
                        "type": "comment"
                    }
                ]
            },
            {
                "by": "__loam",
                "id": 39809810,
                "kids": [
                    39809903
                ],
                "parent": 39809177,
                "text": "GPT-4 cost like $100m so I don&#x27;t think this is surprising?",
                "time": 1711309657,
                "type": "comment",
                "comments": [
                    {
                        "by": "rafaelero",
                        "id": 39809903,
                        "kids": [
                            39809937
                        ],
                        "parent": 39809810,
                        "text": "A lot of organizations still think they should have their own [finetuned] model to provide a custom experience to their users, so that may come as a surprise for them.",
                        "time": 1711310181,
                        "type": "comment",
                        "comments": [
                            {
                                "by": "ShamelessC",
                                "id": 39809937,
                                "kids": [
                                    39810035,
                                    39810169
                                ],
                                "parent": 39809903,
                                "text": "Scaling laws basically guarantee that a sufficiently larger general model will usually beat a smaller specialist model. The misunderstanding is perhaps acceptable but the headline here is essentially restating a well known property of deep learning.",
                                "time": 1711310372,
                                "type": "comment",
                                "comments": [
                                    {
                                        "by": "__loam",
                                        "id": 39810035,
                                        "parent": 39809937,
                                        "text": "How long ago was the Bitter Lesson written?",
                                        "time": 1711310977,
                                        "type": "comment"
                                    },
                                    {
                                        "by": "mistrial9",
                                        "id": 39810169,
                                        "parent": 39809937,
                                        "text": "contrarian view - how these models actually operate at runtime is not understood.. the formal research papers repeat that over and over again. Therefore, there will be new twists and turns as these models evolve. With <i>current</i> technology stacks, the &quot;bitter lesson&quot; is looking good, yes. Will it always be so? no way to know it.",
                                        "time": 1711311921,
                                        "type": "comment"
                                    }
                                ]
                            }
                        ]
                    }
                ]
            },
            {
                "deleted": true,
                "id": 39810907,
                "parent": 39809177,
                "time": 1711317724,
                "type": "comment"
            },
            {
                "by": "atleastoptimal",
                "id": 39810838,
                "parent": 39809177,
                "text": "Yeah, the equivalent is: would it be better for a quant firm to spend 200 thousand dollars giving a first-class specialist education to a guy with an IQ of 95, or just hiring a guy with an IQ of 150 straight out of college.",
                "time": 1711317174,
                "type": "comment"
            }
        ]
    },
    {
        "by": "tipsytoad",
        "descendants": 33,
        "id": 39793250,
        "kids": [
            39794906,
            39795841,
            39795683,
            39794626,
            39795118,
            39798616,
            39797354,
            39799970,
            39796345,
            39795483
        ],
        "score": 122,
        "time": 1711131237,
        "title": "DenseFormer: Enhancing Information Flow in Transformers",
        "type": "story",
        "url": "https://arxiv.org/abs/2402.02622",
        "comments": [
            {
                "by": "p1esk",
                "id": 39794906,
                "kids": [
                    39795135,
                    39795951,
                    39795383
                ],
                "parent": 39793250,
                "text": "This method has only been tested on tiny models (&lt;1B) and tiny dataset (17B tokens). It\u2019s not clear if it scales.",
                "time": 1711141852,
                "type": "comment",
                "comments": [
                    {
                        "by": "ml_basics",
                        "id": 39795135,
                        "kids": [
                            39795804
                        ],
                        "parent": 39794906,
                        "text": "To be fair to the authors they are affiliated with a university and not a big industrial lab, so they may be working with significantly constrained resources. Not sure exactly what the best solution is for this case given that it affects most people outside of a very select few.",
                        "time": 1711143585,
                        "type": "comment",
                        "comments": [
                            {
                                "by": "p1esk",
                                "id": 39795804,
                                "kids": [
                                    39797043,
                                    39799072
                                ],
                                "parent": 39795135,
                                "text": "They could partner with big industrial labs.",
                                "time": 1711149019,
                                "type": "comment",
                                "comments": [
                                    {
                                        "by": "refulgentis",
                                        "id": 39797043,
                                        "kids": [
                                            39803860
                                        ],
                                        "parent": 39795804,
                                        "text": "Nah, nobody&#x27;s begging for people to A) come use time on their GPUs B) come watch them train their biggest models. Nor does it make sense to spend $X00M training a big model using an experimental technique before you announce it, nor does it make sense to hold back breakthroughs as an academic until someone commercializes it at scale. Category error.",
                                        "time": 1711162545,
                                        "type": "comment",
                                        "comments": [
                                            {
                                                "by": "p1esk",
                                                "id": 39803860,
                                                "parent": 39797043,
                                                "text": "I do ML research at a small industrial lab. I\u2019ll gladly provide some compute to people with a cool idea if that results in my company name listed on a paper in a top conference. Especially if the people are from a top university.",
                                                "time": 1711237472,
                                                "type": "comment"
                                            }
                                        ]
                                    },
                                    {
                                        "by": "sp332",
                                        "id": 39799072,
                                        "kids": [
                                            39801294
                                        ],
                                        "parent": 39795804,
                                        "text": "Well now that they have a promising result, maybe.",
                                        "time": 1711192695,
                                        "type": "comment",
                                        "comments": [
                                            {
                                                "by": "p1esk",
                                                "id": 39801294,
                                                "parent": 39799072,
                                                "text": "They had this promising result before they posted the paper.",
                                                "time": 1711212879,
                                                "type": "comment"
                                            }
                                        ]
                                    }
                                ]
                            }
                        ]
                    },
                    {
                        "by": "Buttons840",
                        "id": 39795951,
                        "kids": [
                            39796150,
                            39796687
                        ],
                        "parent": 39794906,
                        "text": "If a genie appeared and granted one wish, I would wish that we find an extremely powerful machine learning technique that doesn&#x27;t scale. Imagine if an average desktop computer was almost as good as a billion dollar super computer.<p>In other words, I don&#x27;t really care if it scales. I almost hope it doesn&#x27;t.",
                        "time": 1711150424,
                        "type": "comment",
                        "comments": [
                            {
                                "by": "p1esk",
                                "id": 39796150,
                                "parent": 39795951,
                                "text": "Not sure I understand what you mean by \u201cdoesn\u2019t scale\u201d. Are you trying to say you would like to see a tiny model performing as well as a large model?",
                                "time": 1711152576,
                                "type": "comment"
                            },
                            {
                                "by": "MacsHeadroom",
                                "id": 39796687,
                                "kids": [
                                    39804828
                                ],
                                "parent": 39795951,
                                "text": "Even pocket computers (smartphones) are already better than billion dollar supercomputers from decades past.<p>What is your point?",
                                "time": 1711158060,
                                "type": "comment",
                                "comments": [
                                    {
                                        "by": "pyinstallwoes",
                                        "id": 39804828,
                                        "parent": 39796687,
                                        "text": "That no one has an advantage",
                                        "time": 1711249083,
                                        "type": "comment"
                                    }
                                ]
                            }
                        ]
                    },
                    {
                        "by": "jal278",
                        "id": 39795383,
                        "parent": 39794906,
                        "text": "But it may scale -- that&#x27;s science in progress",
                        "time": 1711145361,
                        "type": "comment"
                    }
                ]
            },
            {
                "by": "valine",
                "id": 39795841,
                "kids": [
                    39796285,
                    39796597
                ],
                "parent": 39793250,
                "text": "The architecture changes are very straight forward. Model merging has shown that pre-trained transformer layers are very robust. I\u2019ll bet it\u2019s possible to fine tune a pre-trained model like mistral to use this architecture. That would enable someone to test it with more parameters without training a whole new base model.",
                "time": 1711149418,
                "type": "comment",
                "comments": [
                    {
                        "by": "numeri",
                        "id": 39796285,
                        "kids": [
                            39800018
                        ],
                        "parent": 39795841,
                        "text": "They try this in the appendix without success, unfortunately. It seems having this enabled early on in training is important.",
                        "time": 1711154161,
                        "type": "comment",
                        "comments": [
                            {
                                "by": "matteopagli",
                                "id": 39800018,
                                "kids": [
                                    39807426
                                ],
                                "parent": 39796285,
                                "text": "We&#x27;re still working on training the DWA weights on top of a pretained model. We&#x27;re hopeful that this is feasible. The experiments you&#x27;re mentioning in the appendix are not changing the learning rate scheduler. E.g., when starting to train the DWA weights after 20k iterations, the learning rate is already quite small. To some extent, this might explain the diminishing returns. Maybe this could work with a completely different learning rate scheduler.",
                                "time": 1711202712,
                                "type": "comment",
                                "comments": [
                                    {
                                        "by": "gwern",
                                        "id": 39807426,
                                        "parent": 39800018,
                                        "text": "Yeah, you can&#x27;t change the model much with low LRs. That&#x27;s the point! Same reason you don&#x27;t get continual-learning if you just keep using low LRs: <a href=\"https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2403.08763\" rel=\"nofollow\">https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2403.08763</a> You need to really shake up the model if you want to learn some genuinely better (ie. different) internal representations that exploits the DenseNet (<a href=\"https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;1608.06993)&#x2F;LTG-BERT\" rel=\"nofollow\">https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;1608.06993)&#x2F;LTG-BERT</a> (<a href=\"https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2311.02265\" rel=\"nofollow\">https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2311.02265</a>) arch you&#x27;re using here.",
                                        "time": 1711290331,
                                        "type": "comment"
                                    }
                                ]
                            }
                        ]
                    },
                    {
                        "by": "bilsbie",
                        "id": 39796597,
                        "kids": [
                            39796718
                        ],
                        "parent": 39795841,
                        "text": "I haven\u2019t been able to make sense of model merging. Any insights?<p>Wouldn\u2019t weights between models be completely different? And then there are architecture differences on top of that.",
                        "time": 1711157043,
                        "type": "comment",
                        "comments": [
                            {
                                "by": "valine",
                                "id": 39796718,
                                "kids": [
                                    39796815
                                ],
                                "parent": 39796597,
                                "text": "Model merging is usually done with different fine-tunes of the same model. It doesn\u2019t work if the base models are different.<p>One of the more surprising things is that you can actually repeat layers to improve model performance, ie 1-1-2-2 instead of 1-2. That\u2019s how you get models with higher parameter counts than the original.",
                                "time": 1711158382,
                                "type": "comment",
                                "comments": [
                                    {
                                        "by": "namibj",
                                        "id": 39796815,
                                        "parent": 39796718,
                                        "text": "C.f. also Universal Transformer: the same layer stacked a lot.\nThe sparse version of that is basically MoE with also a stick-breaking mechanism to prevent vanishing gradient while letting the model decide whether to terminate layer-count at a token early (ofc with training rewards to favor less layers, to represent the compute savings).",
                                        "time": 1711159304,
                                        "type": "comment"
                                    }
                                ]
                            }
                        ]
                    }
                ]
            },
            {
                "by": "tbalsam",
                "id": 39795683,
                "parent": 39793250,
                "text": "This is a very interesting idea, with DenseNets there are oftentimes some terrible memory gotchas that have gotten me over the past 7-8 years or so, so a part of me is sorta leaning back waiting for some memory usage shoe to drop not specified in the paper (even with the activation patterns!)<p>However, maybe this is not the case. I have a bit of a history of messing with residuals in neural networks, seeing more work on it is good. Fast training networks of course are a very slightly mild obsession of mine as well, and very useful to the field. Here&#x27;s hoping it pans out as a motif, curious to see where it goes.",
                "time": 1711147925,
                "type": "comment"
            },
            {
                "by": "sp332",
                "id": 39794626,
                "parent": 39793250,
                "text": "Even better is the result on page 7 that perplexity drops faster by wall-clock time. Even if you&#x27;re getting fewer iterations per hour of rented GPU time, you&#x27;re still coming out ahead in model performance.",
                "time": 1711140109,
                "type": "comment"
            },
            {
                "by": "ml_basics",
                "id": 39795118,
                "kids": [
                    39795576
                ],
                "parent": 39793250,
                "text": "Cool paper. Really interesting to see how even quite straightforward architectural modifications haven&#x27;t yet all been exhausted yet, despite all the resources being poured into LLMs",
                "time": 1711143467,
                "type": "comment",
                "comments": [
                    {
                        "by": "samus",
                        "id": 39795576,
                        "kids": [
                            39795661,
                            39796007
                        ],
                        "parent": 39795118,
                        "text": "The problem is that they have to be tested for 7B models at least to show promise for larger models. And that requires significant compute resources.",
                        "time": 1711147033,
                        "type": "comment",
                        "comments": [
                            {
                                "by": "tbalsam",
                                "id": 39795661,
                                "parent": 39795576,
                                "text": "Due to some of my personal experiences over the years w&#x2F; model development, I believe that this is more due to a failure of the current mainline version of Transformers (the ++ version I believe) not scaling properly, vs an indicator of scale.<p>If that is the case, then it may well be possible to fix some of the scaling issues more apparent with smaller transformer models (maybe not, though). This is at least some of the reasoning that I&#x27;ve been applying when developing hlb-gpt, for example. It&#x27;s partially also why I think changing how we use nonlinearities within the network might impact scaling, due to some of the activation spikes used in more linear regions of the network to control network behavior in a way not originally intended.<p>Agreed that it does require a ton of resources though. But I do think that the problem can be solved on a smaller scale. If we don&#x27;t have a cleanly logarithmic curve, then I think that something is dearly wrong with our base architecture. (However, of course, I may entirely be missing something here).",
                                "time": 1711147762,
                                "type": "comment"
                            },
                            {
                                "by": "quotemstr",
                                "id": 39796007,
                                "kids": [
                                    39796242
                                ],
                                "parent": 39795576,
                                "text": "I wonder whether we&#x27;re missing out on techniques that work well on large models but that don&#x27;t show promise on small ones",
                                "time": 1711150959,
                                "type": "comment",
                                "comments": [
                                    {
                                        "by": "hackerlight",
                                        "id": 39796242,
                                        "parent": 39796007,
                                        "text": "More like we&#x27;re missing out on techniques full stop. Proving things at scale is GPU expensive and gatekeeps publication and therefore accessibility.",
                                        "time": 1711153632,
                                        "type": "comment"
                                    }
                                ]
                            }
                        ]
                    }
                ]
            },
            {
                "by": "danieldk",
                "id": 39798616,
                "parent": 39793250,
                "text": "Nice finding and makes a lot of sense! It is somewhat related to classification heads using their own weighted representation of all transformer layer outputs.<p>I only glanced the paper, but they don&#x27;t seem to softmax \u237a_i for normalization?",
                "time": 1711186517,
                "type": "comment"
            },
            {
                "by": "zwaps",
                "id": 39797354,
                "parent": 39793250,
                "text": "1. They compare with an older sort of standard implementation of a transformer Unsure whether the results would be equally significant compared to models with gated units or multiquery etc.<p>2. The difference seems to diminish with scale. Real life transformers obviously are much larger and train on many more tokens.<p>3. A very significant part of training transformer models are the throughoutput and memory optimizations. I wonder how their model would work with such fused kernels or specialized paged KV cache schemes. Or activation checkpointing, if run locally.<p>4. Indeed they claim no memory impact, but their code shows that their experiments are conducted with a special optimized version which requires all activations to reside in a single tensor at all times. Not sure this would work with 3d parallelism on multiple nodes etc.",
                "time": 1711166784,
                "type": "comment"
            },
            {
                "by": "matteopagli",
                "id": 39799970,
                "kids": [
                    39807322
                ],
                "parent": 39793250,
                "text": "I&#x27;m one of the authors, happy to answer questions.",
                "time": 1711202104,
                "type": "comment",
                "comments": [
                    {
                        "by": "EvkoGS",
                        "id": 39807322,
                        "parent": 39799970,
                        "text": "Is it possible to combine your approach with NATTEN? It seems that both approaches are optimizing from different directions and can be combined with significant throughput and small performance improvements?",
                        "time": 1711289278,
                        "type": "comment"
                    }
                ]
            },
            {
                "by": "efrank3",
                "id": 39796345,
                "parent": 39793250,
                "text": "Can&#x27;t believe nobody thought of this yet",
                "time": 1711154973,
                "type": "comment"
            },
            {
                "by": "aoeusnth1",
                "id": 39795483,
                "kids": [
                    39795552,
                    39796040
                ],
                "parent": 39793250,
                "text": "&gt; Impact statement:<p>&gt; This paper presents work whose goal is to advance the field of Machine Learning. There are many potential societal consequences of our work, none which we feel must be specifically highlighted here.<p>I found this particularly charming.",
                "time": 1711146217,
                "type": "comment",
                "comments": [
                    {
                        "by": "polygamous_bat",
                        "id": 39795552,
                        "parent": 39795483,
                        "text": "AFAIK this was the default, copy paste impact statement by ICML template.",
                        "time": 1711146796,
                        "type": "comment"
                    },
                    {
                        "deleted": true,
                        "id": 39796040,
                        "parent": 39795483,
                        "time": 1711151228,
                        "type": "comment"
                    }
                ]
            }
        ]
    },
    {
        "by": "tanyongsheng",
        "descendants": 132,
        "id": 39788590,
        "kids": [
            39789498,
            39789144,
            39789127,
            39789107,
            39789938,
            39790271,
            39792780,
            39789395,
            39789215,
            39789735,
            39789080,
            39789206,
            39789116,
            39789466,
            39789902
        ],
        "score": 103,
        "time": 1711097044,
        "title": "OpenAI GPT-4 vs. Groq Mistral-8x7B",
        "type": "story",
        "url": "https://serpapi.com/blog/openai-gpt-4-vs-groq-mistral/",
        "comments": [
            {
                "by": "wruza",
                "id": 39789498,
                "kids": [
                    39789863
                ],
                "parent": 39788590,
                "text": "The prompt, for those interested. I find it pretty underspecified, but maybe that&#x27;s the point. For example, &quot;Business operating hours&quot; could be expanded a little, because &quot;Closed - Opens at XX&quot; is still non-processable in both cases.<p><pre><code>  You are an expert in Web Scraping, so you are capable to find the information in HTML and label them accordingly. Please return the final result in JSON.\n\n  Data to scrape: \n  title: Name of the business\n  type: The business nature like Cafe, Coffee Shop, many others\n  phone: The phone number of the business\n  address: Address of the business, can be a state, country or a full address\n  years_in_business: Number of years since the business started\n  hours: Business operating hours\n  rating: Rating of the business\n  reviews: Number of reviews on the business\n  price: Typical spending on the business\n  description: Extra information that is not mentioned yet in any of the data\n  service_options: Array of shopping options from the business, for example, in store shopping, delivery and many others. It should be in format -&gt; option_name: true\n  is_operating: Whether the business is operating\n  \n  HTML: \n  {html}</code></pre>",
                "time": 1711106186,
                "type": "comment",
                "comments": [
                    {
                        "by": "infecto",
                        "id": 39789863,
                        "kids": [
                            39790503,
                            39790176
                        ],
                        "parent": 39789498,
                        "text": "This should be higher up. This whole blog post is mostly worthless because the way they are extracting data is less than optimal.<p>Lower end models do not have the attention to complete tasks like this, GPT4Turbo will generally have the capability. But to have an optimal pipeline you should really be splitting up these tasks into individual units. You extract each attribute you want independently and then combine it back together however you want. Also asking for JSON upfront is equally suboptimal in the whole process.<p>I have high confidence that I could accomplish this task using a lower end model with a high degree of accuracy.<p>Edit: I am not suggesting that an LLM is more optimal than what ever traditional parsing methods they may use, simply the way they are doing it is wrong from an LLM flow.",
                        "time": 1711109484,
                        "type": "comment",
                        "comments": [
                            {
                                "by": "wruza",
                                "id": 39790503,
                                "parent": 39789863,
                                "text": "Also, my (limited) experience with prompts tells that you want to invest more into the \u201cYou are\u201d part. I\u2019ll share my understanding, corrections are appreciated.<p>LLMs aren\u2019t people even in a chat-roleplaying sense. They complete a \u201cdocument\u201d that can be a plot, a book, a protocol of conversation. The \u201cAI\u201d side in the chat isn\u2019t an LLM itself, it\u2019s a character (and so are you, it completes your \u201cYou: \u2026\u201d replies too - that\u2019s where the driver app stops it and allows you to interfere). So everything you put in that header is very important. There are two places where you can do that: right in the chat, as in TFA, or in the \u201ccharacter card\u201d (idk if GPTs have it, no GPT access for me). I found out that properly crafting a character card makes a huge difference and can resolve the whole classes of issues.<p>Idk what will work best in this case, but I\u2019d start with describing which sort of a bot, how it deals with unclear or incomplete information, how amazing it is (yes, really), its soft&#x2F;tech skills and problem solving abilities, what other people think of it, their experience and so on. Maybe would add few examples of interactions in a free form. Then in the task message I\u2019d tell it more and specific details about that json.<p>One more note - at least for 8x7B, the \u201cYou are\u201d in the chat is a much weaker instruction than a character card, even if the context is still empty. I low-key <i>believe</i> that\u2019s because it\u2019s a second-class prompt, i.e. the chat document starts with \u201cThis is a conversation with a helpful AI bot which yada yada\u201d in\u2026 mind, and then in that chat that AI character gets asked to turn into something else, which poisons the setting.<p>Simply asking the default AI card represents 0.1% of what\u2019s possible and doesn\u2019t give the best results. Prompt Engineering is real.<p><i>I have high confidence that I could accomplish this task using a lower end model with a high degree of accuracy.</i><p>Same. I think that no matter how good a model is, this prompt just isn\u2019t a professional task statement and leaves too much to decide. It\u2019s a task that you, as a regular human, would hate to receive.",
                                "time": 1711114011,
                                "type": "comment"
                            },
                            {
                                "by": "mhuffman",
                                "id": 39790176,
                                "kids": [
                                    39790288
                                ],
                                "parent": 39789863,
                                "text": "Do you have an example of a more optimal prompt to share?",
                                "time": 1711111711,
                                "type": "comment",
                                "comments": [
                                    {
                                        "by": "infecto",
                                        "id": 39790288,
                                        "parent": 39790176,
                                        "text": "The prompt does not matter as much as the workflow which is describe above. 1) Extract one attribute at a time. 2) Don&#x27;t ask for json during extraction, but on binary small attributes it might not matter as much.. 3) Combine the data later.<p>There are differences that can be marked on how different models perform against the same raw prompt but generally the workflow is what matters more. The raw text prompt will be dependent on what model you are using as there are those differences but I don&#x27;t think its a level of &quot;prompt engineering&quot; like we had a year ago.",
                                        "time": 1711112504,
                                        "type": "comment"
                                    }
                                ]
                            }
                        ]
                    }
                ]
            },
            {
                "by": "feintruled",
                "id": 39789144,
                "kids": [
                    39789223
                ],
                "parent": 39788590,
                "text": "Brave new world, where our machines are sometimes wrong but by gum they are quick about it.",
                "time": 1711102824,
                "type": "comment",
                "comments": [
                    {
                        "by": "RUnconcerned",
                        "id": 39789223,
                        "kids": [
                            39790088,
                            39789316
                        ],
                        "parent": 39789144,
                        "text": "I too am a big fan of having my computer hallucinate incorrect information.",
                        "time": 1711103541,
                        "type": "comment",
                        "comments": [
                            {
                                "by": "darthrupert",
                                "id": 39790088,
                                "parent": 39789223,
                                "text": "Yesterday I asked my locally running gpt4all &quot;What model are you running on?&quot;<p>Answer: &quot;I&#x27;m running on Toyota Corolla&quot;<p>Which was perhaps the funniest thing I heard that day.",
                                "time": 1711111107,
                                "type": "comment"
                            },
                            {
                                "by": "harryf",
                                "id": 39789316,
                                "kids": [
                                    39789503,
                                    39790601
                                ],
                                "parent": 39789223,
                                "text": "&gt;&gt; print(\u201cHello, world!\u201d.ai_reverse())\nworld, Hello!",
                                "time": 1711104336,
                                "type": "comment",
                                "comments": [
                                    {
                                        "by": "ben_w",
                                        "id": 39789503,
                                        "parent": 39789316,
                                        "text": "First few versions of Swift kept changing how strings work because it&#x27;s not entirely obvious what most people intend from the nth element of a string.<p>Used to be easy, when it was ASCII.<p>Reverse the bytes of utf-8 and it won&#x27;t always be valid uft-8.<p>Reverse the code-points, and the Canadian flag gets replaced with the Ascension Island flag.",
                                        "time": 1711106221,
                                        "type": "comment"
                                    },
                                    {
                                        "by": "samus",
                                        "id": 39790601,
                                        "parent": 39789316,
                                        "text": "Character-level operations are difficult for LLMs. Because of tokenization they don&#x27;t really &quot;perceive&quot; strings as a list of characters. There are LLMs that ingest bytes, but they are intended to process binary data.",
                                        "time": 1711114554,
                                        "type": "comment"
                                    }
                                ]
                            }
                        ]
                    }
                ]
            },
            {
                "by": "RUnconcerned",
                "id": 39789127,
                "kids": [
                    39789147
                ],
                "parent": 39788590,
                "text": "Finally, something more offensive than parsing HTML with regular expressions: parsing HTML with LLMs.",
                "time": 1711102691,
                "type": "comment",
                "comments": [
                    {
                        "by": "AlphaAndOmega0",
                        "id": 39789147,
                        "kids": [
                            39789171,
                            39789211,
                            39789175
                        ],
                        "parent": 39789127,
                        "text": "I for one am glad I can offload all the regex to LLMs. Powerful? Yes. Human readable for beginners? No.",
                        "time": 1711102859,
                        "type": "comment",
                        "comments": [
                            {
                                "by": "cornedor",
                                "id": 39789171,
                                "parent": 39789147,
                                "text": "Why tough? To me, it seems more prone to issues (hallucinations, prompt injections etc). It is also slower and more expensive at the same time. I also think it is harder to implement properly, and you need to add way more tests in order to be confident it works.",
                                "time": 1711103065,
                                "type": "comment"
                            },
                            {
                                "by": "RUnconcerned",
                                "id": 39789211,
                                "kids": [
                                    39789813
                                ],
                                "parent": 39789147,
                                "text": "Personally when I am parsing structured data I prefer to use parsers that won&#x27;t hallucinate data but that&#x27;s just me.<p>Also, don&#x27;t parse HTML with regular expressions.",
                                "time": 1711103394,
                                "type": "comment",
                                "comments": [
                                    {
                                        "by": "rybosome",
                                        "id": 39789813,
                                        "kids": [
                                            39791028
                                        ],
                                        "parent": 39789211,
                                        "text": "Generally I agree with your point, but there is some value in a parser that doesn\u2019t have to be updated when the underlying HTML changes.<p>Whether or not this benefit outweighs the significant problems (cost, speed, accuracy and determinism) is up to the use case. For most use cases I can think of, the speed and accuracy of an actual parser would be preferable.<p>However, in situations where one is parsing highly dynamic HTML (eg if each business type had slightly different output, or you are scraping a site which updates the structure frequently and breaks your hand written parser) then this could be worth the accuracy loss.",
                                        "time": 1711109023,
                                        "type": "comment",
                                        "comments": [
                                            {
                                                "by": "samus",
                                                "id": 39791028,
                                                "parent": 39789813,
                                                "text": "You could employ an LLM to give you updated queries when the format changes. This is something where they should shine. And you get something that you can audit and exhaustively test.",
                                                "time": 1711117356,
                                                "type": "comment"
                                            }
                                        ]
                                    }
                                ]
                            },
                            {
                                "by": "okamiueru",
                                "id": 39789175,
                                "parent": 39789147,
                                "text": "Deterministic? No.",
                                "time": 1711103090,
                                "type": "comment"
                            }
                        ]
                    }
                ]
            },
            {
                "by": "retrac98",
                "id": 39789107,
                "kids": [
                    39789176,
                    39789168,
                    39789117,
                    39789217,
                    39789716,
                    39789155
                ],
                "parent": 39788590,
                "text": "There are so many applications for LLMs where having a perfect score is much more important than speed, because getting it wrong is so expensive, damaging, or time consuming to resolve for an organisation.",
                "time": 1711102505,
                "type": "comment",
                "comments": [
                    {
                        "by": "nathan_compton",
                        "id": 39789176,
                        "kids": [
                            39789186
                        ],
                        "parent": 39789107,
                        "text": "If you need a perfect score, don&#x27;t use LLMs. This seems obvious to me, even given the state of the art LLMs. I am a heavy user of GPT4 and I wouldn&#x27;t bet $1000 bucks on it being 100% reliable for any non-trivial task.",
                        "time": 1711103091,
                        "type": "comment",
                        "comments": [
                            {
                                "by": "retrac98",
                                "id": 39789186,
                                "kids": [
                                    39793024,
                                    39789228,
                                    39789381,
                                    39789373,
                                    39789199
                                ],
                                "parent": 39789176,
                                "text": "They&#x27;ll get better. Humans are far from perfect, and I have no doubt that LLMs will eventually outperform them for non-trivial tasks consistently.",
                                "time": 1711103229,
                                "type": "comment",
                                "comments": [
                                    {
                                        "by": "Jensson",
                                        "id": 39793024,
                                        "parent": 39789186,
                                        "text": "&gt; Humans are far from perfect<p>Humans running multishot with mixture of experts is close to perfect. You can&#x27;t compare a multishot mixture of expert AI to a single human, humans doesn&#x27;t work in isolation.",
                                        "time": 1711129409,
                                        "type": "comment"
                                    },
                                    {
                                        "by": "nathan_compton",
                                        "id": 39789228,
                                        "kids": [
                                            39790571
                                        ],
                                        "parent": 39789186,
                                        "text": "Maybe so, but at this stage I wouldn&#x27;t be betting a business model on it.",
                                        "time": 1711103562,
                                        "type": "comment",
                                        "comments": [
                                            {
                                                "by": "Socnic",
                                                "id": 39790571,
                                                "parent": 39789228,
                                                "text": "Businesses do bet on imperfect and even criminal models all the time (way before LLMs existed)... they call it cost of doing business when they get it wrong or get caught.",
                                                "time": 1711114409,
                                                "type": "comment"
                                            }
                                        ]
                                    },
                                    {
                                        "by": "littlestymaar",
                                        "id": 39789381,
                                        "parent": 39789186,
                                        "text": "Machine learning models will get better for sure. We don&#x27;t know if LLM are the end game though and it&#x27;s not sure if this particular technique is what we&#x27;ll need to reach the next level.",
                                        "time": 1711105026,
                                        "type": "comment"
                                    },
                                    {
                                        "by": "somewhereoutth",
                                        "id": 39789373,
                                        "kids": [
                                            39789556
                                        ],
                                        "parent": 39789186,
                                        "text": "Or they might not get better. It could be that we are at a local optimum for that sort of thing, and major improvements will have to wait (perhaps for a very long time) for radical new technologies.",
                                        "time": 1711104908,
                                        "type": "comment",
                                        "comments": [
                                            {
                                                "by": "luma",
                                                "id": 39789556,
                                                "parent": 39789373,
                                                "text": "Maybe, but it certainly hasn\u2019t been the arc of the past few years.  I don\u2019t know how anyone could look at this and assume that it\u2019s likely to slow down.",
                                                "time": 1711106651,
                                                "type": "comment"
                                            }
                                        ]
                                    },
                                    {
                                        "by": "samus",
                                        "id": 39789199,
                                        "kids": [
                                            39789238,
                                            39789242
                                        ],
                                        "parent": 39789186,
                                        "text": "They already have superhuman image classification performance.",
                                        "time": 1711103321,
                                        "type": "comment",
                                        "comments": [
                                            {
                                                "by": "pooper",
                                                "id": 39789238,
                                                "kids": [
                                                    39789274,
                                                    39789273,
                                                    39789269
                                                ],
                                                "parent": 39789199,
                                                "text": "I remember talking to a radiologist who said he was sure something like this was coming like ten years ago where instead of a radiologist looking at scans manually, a machine would go through a lot of images and flag some for manual review.<p>We haven&#x27;t even gotten there yet, have we?",
                                                "time": 1711103685,
                                                "type": "comment",
                                                "comments": [
                                                    {
                                                        "by": "osrec",
                                                        "id": 39789274,
                                                        "kids": [
                                                            39789388
                                                        ],
                                                        "parent": 39789238,
                                                        "text": "Yes, we absolutely are there: <a href=\"https:&#x2F;&#x2F;youtu.be&#x2F;D3oRN5JNMWs?feature=shared\" rel=\"nofollow\">https:&#x2F;&#x2F;youtu.be&#x2F;D3oRN5JNMWs?feature=shared</a><p>My professor (Sir Michael Brady) at university 14 years ago set up a company to do this very thing, and he already had reliable models back before 2010. I believe their company was called Oxford Imaging or something similar.",
                                                        "time": 1711104049,
                                                        "type": "comment",
                                                        "comments": [
                                                            {
                                                                "by": "wruza",
                                                                "id": 39789388,
                                                                "kids": [
                                                                    39789852
                                                                ],
                                                                "parent": 39789274,
                                                                "text": "Yep, everyone seems to forget that ML was available before 2021. Had a conversation recently with my former colleague who learned about some plastic packaging company which used &quot;AI&quot; to predict client orders and inform them about scheduling implications. When I told him that you don&#x27;t need Transformers and 30GB models for that, he was quasi-confused, cause he kinda knew it but the hype just overtook his knowledge.",
                                                                "time": 1711105085,
                                                                "type": "comment",
                                                                "comments": [
                                                                    {
                                                                        "by": "anon373839",
                                                                        "id": 39789852,
                                                                        "parent": 39789388,
                                                                        "text": "In ML courses, you\u2019re taught to try simpler methods and models before turning to more complex ones. I think that\u2019s something that hasn\u2019t made it into the mainstream yet.<p>A lot of people seem to be using GPT-4 for tasks like text classification and NER, and they\u2019d be much better off fine-tuning a BERT model instead. In vision, too, transformers are great but a lot of times, a CNN is all you really need.",
                                                                        "time": 1711109394,
                                                                        "type": "comment"
                                                                    }
                                                                ]
                                                            }
                                                        ]
                                                    },
                                                    {
                                                        "by": "dagw",
                                                        "id": 39789273,
                                                        "parent": 39789238,
                                                        "text": "<i>We haven&#x27;t even gotten there yet, have we?</i><p>Yes and no. Countless teams have solved exactly this problems at universities and research groups across the world. Technically it&#x27;s pretty much a solved problem. The hard part is getting the systems out of the labs and certified as an actual product and convincing hospitals and doctors to actually use them.",
                                                        "time": 1711104025,
                                                        "type": "comment"
                                                    },
                                                    {
                                                        "by": "matheusd",
                                                        "id": 39789269,
                                                        "parent": 39789238,
                                                        "text": "Maybe it&#x27;s a liability issue, not a competency issue.",
                                                        "time": 1711103993,
                                                        "type": "comment"
                                                    }
                                                ]
                                            },
                                            {
                                                "by": "jojobas",
                                                "id": 39789242,
                                                "kids": [
                                                    39790533
                                                ],
                                                "parent": 39789199,
                                                "text": "Until a single pixel makes a cat a dog or something like that.",
                                                "time": 1711103737,
                                                "type": "comment",
                                                "comments": [
                                                    {
                                                        "by": "samus",
                                                        "id": 39790533,
                                                        "parent": 39789242,
                                                        "text": "Changing a single pixel is usually not enough to confuse convolutional neuronal networks. Even so, human supervision will probably always be quite important.",
                                                        "time": 1711114206,
                                                        "type": "comment"
                                                    }
                                                ]
                                            }
                                        ]
                                    }
                                ]
                            }
                        ]
                    },
                    {
                        "by": "spaniard89277",
                        "id": 39789168,
                        "kids": [
                            39789232,
                            39789771,
                            39790866
                        ],
                        "parent": 39789107,
                        "text": "I&#x27;ve tried to apply it to parsing HTML as this article into a pretty long pipeline. I&#x27;m using DeepInfra with Mistral 8x7B and I&#x27;m still unsure if I&#x27;m going to use for production.<p>The problem I&#x27;m finding is that the time I wanted to save mantaining selectors and the like is time that I&#x27;m spending writing wrapper code and dealing with the mistakes it makes. Some are OK and can deal with them, others are pretty annoying because It&#x27;s difficult to deal with them in a deterministic manner.<p>I&#x27;ve also tried with GPT-4 but it&#x27;s way more expensive, and despite what this guy got, it also makes mistakes.<p>I don&#x27;t really care about inference speed, but I do care about price and correctness.",
                        "time": 1711103018,
                        "type": "comment",
                        "comments": [
                            {
                                "by": "ogogmad",
                                "id": 39789232,
                                "parent": 39789168,
                                "text": "Might be a silly question, but if you want determinism in this, why don&#x27;t you get the LLM to write the deterministic code, and use that instead? Interesting experiment, though!<p>In fact, what about a hybrid of what you&#x27;re doing now? Initially, you use an LLM to generate examples. And then from those examples, you use that same LLM to write deterministic code?",
                                "time": 1711103622,
                                "type": "comment"
                            },
                            {
                                "by": "Eisenstein",
                                "id": 39789771,
                                "parent": 39789168,
                                "text": "Have you tried swapping Mistral 8x7B with either command-r 34B, Qwen 1.5 70B, or miqu 70B? Those are all superior in my experience, though suited for slightly different tasks, so experimentation is needed.",
                                "time": 1711108687,
                                "type": "comment"
                            },
                            {
                                "by": "samus",
                                "id": 39790866,
                                "parent": 39789168,
                                "text": "Parsing HTML and tagsoup is IMHO not the right application for LLMs since these are ultimately structured formats. LLM are for NLP tasks, like extracting meaning out of unstructured and ambiguous text. The computational cost of an LLM chewing through even moderately-sized document can be more efficiently spent on sophisticated parser technologies that have been around for decades, which can also to a degree deal with ambiguous and irregular grammars. LLMs should be able to help you write those.",
                                "time": 1711116204,
                                "type": "comment"
                            }
                        ]
                    },
                    {
                        "by": "malux85",
                        "id": 39789117,
                        "parent": 39789107,
                        "text": "Yeah I agree - just an hour ago I was dealing with an LLM that was missing a &quot;not&quot; thus inverting the meaning of a rather important simulation parameter!",
                        "time": 1711102625,
                        "type": "comment"
                    },
                    {
                        "by": "worldsayshi",
                        "id": 39789217,
                        "parent": 39789107,
                        "text": "It makes much more sense to me to have the LLM infer the correct query for extracting data on the page. Much faster and reliable and it wouldn&#x27;t really be a problem to have a human in the loop every now and then.",
                        "time": 1711103446,
                        "type": "comment"
                    },
                    {
                        "by": "onion2k",
                        "id": 39789716,
                        "parent": 39789107,
                        "text": "All the places I see AI being applicable to my work don&#x27;t require a perfect score, and a threshold is actually much more useful, especially where multiple factors come together to make evaluation to a single value hard.",
                        "time": 1711108229,
                        "type": "comment"
                    },
                    {
                        "by": "bberrry",
                        "id": 39789155,
                        "kids": [
                            39789182
                        ],
                        "parent": 39789107,
                        "text": "If you have speed you can generate multiple answers and have another model pick the best one.",
                        "time": 1711102890,
                        "type": "comment",
                        "comments": [
                            {
                                "by": "Drakim",
                                "id": 39789182,
                                "kids": [
                                    39789311,
                                    39789383,
                                    39789248,
                                    39789231
                                ],
                                "parent": 39789155,
                                "text": "If I ask an LLM a very complex and specific question 500 times, if it just doesn&#x27;t know the facts you&#x27;ll still get the wrong answer 500 times.<p>That&#x27;s understandable. The real problem is when the AI lies&#x2F;hallucinates another answer with confidence instead of saying &quot;I don&#x27;t know&quot;.",
                                "time": 1711103171,
                                "type": "comment",
                                "comments": [
                                    {
                                        "by": "simion314",
                                        "id": 39789311,
                                        "kids": [
                                            39791011,
                                            39789595
                                        ],
                                        "parent": 39789182,
                                        "text": "The problem is asking for facts, LLM are not a database so they know stuff but it is compressed so expect wrong facts, wrong names, dates, wrong anything.<p>We will need an LLM as a front end then it will generate a query to fetch the facts from the internet or a database , then maybe   format the facts for your consumption.",
                                        "time": 1711104293,
                                        "type": "comment",
                                        "comments": [
                                            {
                                                "by": "samus",
                                                "id": 39791011,
                                                "parent": 39789311,
                                                "text": "This is called Retrieval Augmented Generation (RAG). The LLM driver recognizes a query, it gets send to a vector database or to an external system (could be another LLM...) and the answer is placed in the context. It&#x27;s a common strategy to work around their limited context length, but it tends to be brittle. Look for survey papers.",
                                                "time": 1711117211,
                                                "type": "comment"
                                            },
                                            {
                                                "by": "ch_sm",
                                                "id": 39789595,
                                                "kids": [
                                                    39789715,
                                                    39791003
                                                ],
                                                "parent": 39789311,
                                                "text": "That\u2018s exactly it. It\u2018s ok for LLMs to not know everything, because they _should_ have a means to look up information. What are some projects where this obvious approach is implemented&#x2F;tried?",
                                                "time": 1711106992,
                                                "type": "comment",
                                                "comments": [
                                                    {
                                                        "by": "Jensson",
                                                        "id": 39789715,
                                                        "parent": 39789595,
                                                        "text": "But then you need an LLM that can separate between grammar and facts. Current LLMs doesn&#x27;t know the difference, that is the main source to these issues, these models treat facts like grammar and that worked well enough to excite people but probably wont get us to a good state.",
                                                        "time": 1711108214,
                                                        "type": "comment"
                                                    },
                                                    {
                                                        "deleted": true,
                                                        "id": 39791003,
                                                        "parent": 39789595,
                                                        "time": 1711117171,
                                                        "type": "comment"
                                                    }
                                                ]
                                            }
                                        ]
                                    },
                                    {
                                        "by": "m348e912",
                                        "id": 39789383,
                                        "kids": [
                                            39789565,
                                            39789772,
                                            39789916,
                                            39789474,
                                            39789516,
                                            39789447,
                                            39790933
                                        ],
                                        "parent": 39789182,
                                        "text": "The weird problem is with LLM hallucinations is that it usually will acknowledge its mistake and correct itself if you call it out. My question is why can&#x27;t LLMs included a sub-routine to check itself before answering.\nSimply asking itself something like &quot;this answer may not be correct, are you sure you&#x27;re right?&quot;",
                                        "time": 1711105056,
                                        "type": "comment",
                                        "comments": [
                                            {
                                                "by": "Shrezzing",
                                                "id": 39789565,
                                                "parent": 39789383,
                                                "text": "&gt;The weird problem is with LLM hallucinations is that it usually will acknowledge its mistake and correct itself if you call it out.<p>From what I&#x27;ve tested, all of the current models will see a prompt like &quot;are you sure that&#x27;s correct&quot; and respond &quot;no, I was incorrect [here&#x27;s some other answer]&quot;, irrespective of the accuracy of the original statement.",
                                                "time": 1711106724,
                                                "type": "comment"
                                            },
                                            {
                                                "by": "greenavocado",
                                                "id": 39789772,
                                                "parent": 39789383,
                                                "text": "In my experience the corrections can be additional hallucinations one after another after pointing out inaccuracies even multiple times in a row.",
                                                "time": 1711108695,
                                                "type": "comment"
                                            },
                                            {
                                                "by": "Eisenstein",
                                                "id": 39789916,
                                                "parent": 39789383,
                                                "text": "&gt; My question is why can&#x27;t LLMs included a sub-routine to check itself before answering.<p>Because LLMs don&#x27;t work in a way for that to be possible if you operate them on their own.<p>Here is the debug output of my local instance of Mistral-Instruct 8x7B. The prompt from me was &#x27;What is poop spelled backwards?&#x27;. It answered &#x27;puoP&#x27;. Let&#x27;s see how it got there starting with it processing my prompt into tokens:<p><pre><code>   &#x27;What (3195)&#x27;, &#x27; is (349)&#x27;, &#x27; po (1627)&#x27;, &#x27;op (410)&#x27;, &#x27; sp (668)&#x27;, &#x27;elled (6099)&#x27;, &#x27; backwards (24324)&#x27;, &#x27;? (28804)&#x27;, &#x27;\\n (13)&#x27;, &#x27;### (27332)&#x27;, &#x27; Response (12107)&#x27;, &#x27;: (28747)&#x27;, &#x27;\\n (13)&#x27;,\n</code></pre>\nIt tokenized &#x27;poop&#x27; as two tokens: &#x27;po&#x27;, number 1627, and &#x27;op&#x27;, number 410.<p>Next it comes up with its response:<p><pre><code>   Generating (1 &#x2F; 512 tokens) [(pu 4.43%) (The 66.62%) (po 11.96%) (p 4.99%)]\n   Generating (2 &#x2F; 512 tokens) [(o 89.90%) (op 10.10%)]\n   Generating (3 &#x2F; 512 tokens) [(P 100.00%)]\n   Generating (4 &#x2F; 512 tokens) [( 100.00%)]\n</code></pre>\nIt picked &#x27;pu&#x27; even though it was only a ~4% chance of being correct, then instead of picking &#x27;op&#x27; it picked &#x27;o&#x27;. The last token was a 100% probability of being &#x27;P&#x27;.<p><pre><code>   Output: puoP\n</code></pre>\nAt no time did it write &#x27;puoP&#x27; as a complete word nor does it know what &#x27;puoP&#x27; is. It has no way of evaluating whether that is the right answer or not. You would need a different process to do that.",
                                                "time": 1711109877,
                                                "type": "comment"
                                            },
                                            {
                                                "by": "ZitchDog",
                                                "id": 39789474,
                                                "kids": [
                                                    39790963
                                                ],
                                                "parent": 39789383,
                                                "text": "The problem is that if you call it out, it will frequently change its answer, even if it was correct. LLMs currently lack chutzpa.",
                                                "time": 1711106007,
                                                "type": "comment",
                                                "comments": [
                                                    {
                                                        "by": "samus",
                                                        "id": 39790963,
                                                        "kids": [
                                                            39791230
                                                        ],
                                                        "parent": 39789474,
                                                        "text": "They definitely stand their ground if they were aligned to do so.",
                                                        "time": 1711116888,
                                                        "type": "comment",
                                                        "comments": [
                                                            {
                                                                "by": "Drakim",
                                                                "id": 39791230,
                                                                "parent": 39790963,
                                                                "text": "But then they stand their ground when wrong too.",
                                                                "time": 1711118621,
                                                                "type": "comment"
                                                            }
                                                        ]
                                                    }
                                                ]
                                            },
                                            {
                                                "by": "Jensson",
                                                "id": 39789516,
                                                "parent": 39789383,
                                                "text": "That is a common bullshitting strategy, talk a lot of bullshit, and then backtrack and acknowledge you were wrong when people push back. That way they will think you know way more than you do. Many people will see thought that, but most will just think you are a humble expert who can acknowledge when you are wrong instead of you always acknowledging you are wrong even when you aren&#x27;t.<p>People have a really hard time catching such bullshitting from humans, which is why free form interviews doesn&#x27;t work.",
                                                "time": 1711106307,
                                                "type": "comment"
                                            },
                                            {
                                                "by": "asimovfan",
                                                "id": 39789447,
                                                "parent": 39789383,
                                                "text": "Its because theres no entity that is actually acknowledging anything. Its generating an answer to your prompt. You can gaslight it into anything being wrong or correct.",
                                                "time": 1711105767,
                                                "type": "comment"
                                            },
                                            {
                                                "by": "samus",
                                                "id": 39790933,
                                                "parent": 39789383,
                                                "text": "They simply don&#x27;t work that way. You are asking it for an answer, it will give you one since all it can do is extrapolate from its training data.<p>Good prompting and certain adjustment to the text generation parameters might help prevent hallucinations, but it&#x27;s not an exact science since it depends on how it was trained. Also, an LLMs training data frankly said contains a lot of bulls*t.",
                                                "time": 1711116733,
                                                "type": "comment"
                                            }
                                        ]
                                    },
                                    {
                                        "by": "helsinkiandrew",
                                        "id": 39789248,
                                        "parent": 39789182,
                                        "text": "&gt; If I ask an LLM a very complex and specific question 500 times, if it just doesn&#x27;t know the facts you&#x27;ll still get the wrong answer 500 times.<p>Think the commenter meant use another model&#x2F;LLM which could give a different answer, then let them vote on the result.  Like &quot;old fashioned AI&quot; did with ensemble learning.",
                                        "time": 1711103786,
                                        "type": "comment"
                                    },
                                    {
                                        "deleted": true,
                                        "id": 39789231,
                                        "parent": 39789182,
                                        "time": 1711103587,
                                        "type": "comment"
                                    }
                                ]
                            }
                        ]
                    }
                ]
            },
            {
                "by": "infecto",
                "id": 39789938,
                "kids": [
                    39791038
                ],
                "parent": 39788590,
                "text": "This test is interesting from a general high level metric&#x2F;test but overall the way they are extracting data using a LLM is suboptimal so I don&#x27;t think the takeaway means much. You could extract this type of data using a low-end model like 8x7B with a high degree of accuracy.",
                "time": 1711109988,
                "type": "comment",
                "comments": [
                    {
                        "by": "samus",
                        "id": 39791038,
                        "parent": 39789938,
                        "text": "The better way would be to ask it to generate a program that uses CSS selectors to parse the HTML.",
                        "time": 1711117448,
                        "type": "comment"
                    }
                ]
            },
            {
                "by": "emporas",
                "id": 39790271,
                "parent": 39788590,
                "text": "Mixtral works very well with json output in my personal experience. Gpt family are excellent of course, and i would bet Claude and Gemini are pretty good. Mixtral however is the smallest of the models and the most efficient.<p>Especially running on Groq&#x27;s infrastructure it&#x27;s blazing fast. Some examples i ran on Groq&#x27;s API, the query was completed in 70ms. Groq has released API libraries for Python and Javascript, i wrote a simple Rust example here, of how to use the API [1].<p>Groq&#x27;s API documents how long it takes to generate the tokens for each request. 70ms for a page of document, are well over 100 times faster than GPT, and the fastest of every other capable model. Accounting for internet&#x27;s latency and some queue that might exist, then the user receives the request in a second, but how fast would this model run locally? Fast enough to generate natural language tokens, generate a synthetic voice, listen again and decode the next request the user might talk to it, all in real time.<p>With a technology like that, why not talk to internet services with just APIs and no web interface at all? Just functions exposed on the internet, take json as an input, validate it, and send the json back to the user? Or every other interface and button around. Why pressing buttons for every electric appliance, and not just talk to the machine using a json schema? Why should users on an internet forum, every time a comment is added, have to press the add comment button, instead of just talking and saying &quot;post it&quot;? Pretty annoying actually.<p>[1] <a href=\"https:&#x2F;&#x2F;github.com&#x2F;pramatias&#x2F;groq_test\">https:&#x2F;&#x2F;github.com&#x2F;pramatias&#x2F;groq_test</a>",
                "time": 1711112358,
                "type": "comment"
            },
            {
                "by": "imaurer",
                "id": 39792780,
                "parent": 39788590,
                "text": "Groq will soon support function calling. At that point, you would want to describe your data specification and use function calling to do extraction. Tools such as Pydantic and Instructor are good starting points.<p>I am collecting these approaches and tools here:\n<a href=\"https:&#x2F;&#x2F;github.com&#x2F;imaurer&#x2F;awesome-llm-json\">https:&#x2F;&#x2F;github.com&#x2F;imaurer&#x2F;awesome-llm-json</a>",
                "time": 1711127569,
                "type": "comment"
            },
            {
                "by": "bambax",
                "id": 39789395,
                "parent": 39788590,
                "text": "Interesting post, but the prompt is missing? How do the LLMs generate the keys? It&#x27;s likely the mistakes could be corrected with a better prompt or a post check?<p>Also, Google SERP page is deterministic (always has the same structure for the same kind of queries), so it would probably be much more effective to use AI to write a parser, and then refine it and use that?",
                "time": 1711105159,
                "type": "comment"
            },
            {
                "by": "tosh",
                "id": 39789215,
                "parent": 39788590,
                "text": "I initially thought the blog post is about scraping using screenshots and multi-modal llms.<p>Scraping is quite complex by now (front-end JS, deep and irregular nesting, obfuscated html, \u2026).",
                "time": 1711103426,
                "type": "comment"
            },
            {
                "by": "crowdyriver",
                "id": 39789735,
                "kids": [
                    39791094
                ],
                "parent": 39788590,
                "text": "There&#x27;s lots of comments here about how stupid is to parse html using llms.<p>Have you ever had to scrape multiple sites with variadic html?",
                "time": 1711108393,
                "type": "comment",
                "comments": [
                    {
                        "by": "samus",
                        "id": 39791094,
                        "parent": 39789735,
                        "text": "The example here has HTML with a somewhat fixed format. It would indeed have been better to have samples with different format and aiming for a low error rate.<p>If you are scraping a limited amount of sites, you could for each site ask the LLM for parsing code from some samples, review that, and move on.",
                        "time": 1711117790,
                        "type": "comment"
                    }
                ]
            },
            {
                "by": "malux85",
                "id": 39789080,
                "kids": [
                    39789123,
                    39789178
                ],
                "parent": 39788590,
                "text": "Sorry to be nit-picky but thats the essence of these benchmarks - Mistral putting &quot;N&#x2F;A&quot; for not available is weird - N&#x2F;A is not applicable, in every use I have ever seen, and they DONT mean the same thing. I would expect null for not available and N&#x2F;A for not applicable<p>Impressive inference speed difference though",
                "time": 1711102215,
                "type": "comment",
                "comments": [
                    {
                        "by": "mewpmewp2",
                        "id": 39789123,
                        "kids": [
                            39789138
                        ],
                        "parent": 39789080,
                        "text": "I have always known N&#x2F;A as not available.",
                        "time": 1711102662,
                        "type": "comment",
                        "comments": [
                            {
                                "by": "malux85",
                                "id": 39789138,
                                "kids": [
                                    39789148,
                                    39795150
                                ],
                                "parent": 39789123,
                                "text": "Curious, where are you from? If I Google N&#x2F;A every single hit on the first page is explaining it means &quot;Not applicable&quot;<p>are you from a non-english country? Maybe its cultural?",
                                "time": 1711102789,
                                "type": "comment",
                                "comments": [
                                    {
                                        "by": "selcuka",
                                        "id": 39789148,
                                        "kids": [
                                            39789162
                                        ],
                                        "parent": 39789138,
                                        "text": "The first entry on Google is Wikipedia [1] for me:<p>&gt; N&#x2F;A (or sometimes n&#x2F;a or N.A.) is a common abbreviation in tables and lists for the phrase not applicable, not available, not assessed, or no answer.<p>[1] <a href=\"https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;N&#x2F;A\" rel=\"nofollow\">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;N&#x2F;A</a>",
                                        "time": 1711102861,
                                        "type": "comment",
                                        "comments": [
                                            {
                                                "by": "malux85",
                                                "id": 39789162,
                                                "kids": [
                                                    39790066
                                                ],
                                                "parent": 39789148,
                                                "text": "Thats interesting, wikipedia is not on the first page for me, my first hit is Cambridge dict: (and then a bunch of other dicts) - Im flying right now but IP geolocation puts me in the US<p>Meaning of n&#x2F;a in English\nwritten abbreviation for not applicable: used on a form to show that you are not giving the information asked for because the question is not intended for you or your situation: If a question does not apply to you, please put N&#x2F;A in the box provided. COMMERCE.<p>TIL",
                                                "time": 1711102975,
                                                "type": "comment",
                                                "comments": [
                                                    {
                                                        "by": "Jensson",
                                                        "id": 39790066,
                                                        "parent": 39789162,
                                                        "text": "In a data table &quot;not available&quot; is usually the right word for it, like if you have a list of national statistics then some of the values wont be available due to political reasons etc. But all of those means basically the same thing to the end user, this value isn&#x27;t there.",
                                                        "time": 1711110937,
                                                        "type": "comment"
                                                    }
                                                ]
                                            }
                                        ]
                                    },
                                    {
                                        "by": "mewpmewp2",
                                        "id": 39795150,
                                        "parent": 39789138,
                                        "text": "I&#x27;m from North Europe, so not a native English speaker, but still it seems like based on my experience in life it seems as the first idea is that it&#x27;s Not Available.<p>If I was to code something and for whatever reason some data wasn&#x27;t available I would use N&#x2F;A.<p>&quot;Not applicable&quot; doesn&#x27;t feel right to me about N&#x2F;A.<p>For instance if there is a table of comparison and for whatever reason there is data missing for some entity, while there should be, I would use N&#x2F;A. So not applicable feels wrong for me for that reason alone.<p>This all is coming from intuition though.",
                                        "time": 1711143719,
                                        "type": "comment"
                                    }
                                ]
                            }
                        ]
                    },
                    {
                        "by": "throwaway11460",
                        "id": 39789178,
                        "parent": 39789080,
                        "text": "It means all of these.",
                        "time": 1711103121,
                        "type": "comment"
                    }
                ]
            },
            {
                "by": "huqedato",
                "id": 39789206,
                "kids": [
                    39789643,
                    39789220,
                    39789244
                ],
                "parent": 39788590,
                "text": "Can somebody explain why this Grok is more performant than Microsoft infrastructure ? LPU better than TPU&#x2F;GPU ?",
                "time": 1711103370,
                "type": "comment",
                "comments": [
                    {
                        "by": "kkielhofner",
                        "id": 39789643,
                        "parent": 39789206,
                        "text": "LLM performance is about parallelism but also memory bandwidth.<p>Groq delivers this kind of speed by networking many, many chips together with high bandwidth interconnect. Each chip has only 230mb of SRAM[0].<p>From the linked reference:<p>&quot;In the case of the Mixtral model, Groq had to connect 8 racks of 9 servers each with 8 chips per server. That\u2019s a total of 576 chips to build up the inference unit and serve the Mixtral model.&quot;<p>That&#x27;s eight racks with ~132GB of memory for the model. A single H100 has 80GB and can serve Mixtral without issue (albeit at lower performance).<p>If you consider the requirements for actual real-world inference serving workloads you need to serve multiple models, multiple versions of models, LoRA adapters, sentence embeddings models (for RAG), etc the economics and physical footprint alone get very challenging.<p>It&#x27;s an interesting approach and clearly very, very fast but I&#x27;m curious to see how they do in the market:<p>1) This analysis uses cloud GPU costs for Nvidia pricing. Cloud providers make significant margin on their GPU instances. If you look at qty 1 retail Nvidia DGX, Lambda Hyperplane, etc and compare it to cloud GPU pricing (inference needs to run 24x7) break even on hardware vs cloud is less than seven months depending on what your costs are for hosting the hardware.<p>2) Nvidia has incredibly high margins.<p>3) CUDA.<p>There are some special cases where tokens per second and time to first token are incredibly important (as the article states - real time agents, etc) but overall I think actual real-world production use or deployment of Groq is a pretty challenging proposition.<p>[0] - <a href=\"https:&#x2F;&#x2F;www.semianalysis.com&#x2F;p&#x2F;groq-inference-tokenomics-speed-but\" rel=\"nofollow\">https:&#x2F;&#x2F;www.semianalysis.com&#x2F;p&#x2F;groq-inference-tokenomics-spe...</a>",
                        "time": 1711107435,
                        "type": "comment"
                    },
                    {
                        "by": "tosh",
                        "id": 39789220,
                        "kids": [
                            39789675
                        ],
                        "parent": 39789206,
                        "text": "The Mistral Mixed Expert model has way fewer parameters active during inference and Groq has special purpose hardware (and probably less concurrent demand).",
                        "time": 1711103518,
                        "type": "comment",
                        "comments": [
                            {
                                "by": "kkielhofner",
                                "id": 39789675,
                                "parent": 39789220,
                                "text": "&gt; probably less concurrent demand<p>This is a significant understatement. ChatGPT has an estimated 100m monthly active users.<p>Groq gets featured on HN from time to time but is otherwise almost completely unknown. According to their stats they have done something like 15m requests total since launch. ChatGPT likely does this in hours (or less).",
                                "time": 1711107799,
                                "type": "comment"
                            }
                        ]
                    },
                    {
                        "by": "naiv",
                        "id": 39789244,
                        "parent": 39789206,
                        "text": "It&#x27;s a totally different approach for interference<p>In short:<p>Groq - Ai Chip\nMicrosoft etc. - Nvidia Gpu",
                        "time": 1711103754,
                        "type": "comment"
                    }
                ]
            },
            {
                "by": "ttrrooppeerr",
                "id": 39789116,
                "kids": [
                    39789153,
                    39789163
                ],
                "parent": 39788590,
                "text": "A bit off-topic but maybe not? Any words on GPT-5? Is that coming? Or is OpenAI just focusing on the Sora model?",
                "time": 1711102622,
                "type": "comment",
                "comments": [
                    {
                        "by": "YetAnotherNick",
                        "id": 39789153,
                        "kids": [
                            39789418,
                            39789424,
                            39789342,
                            39789259
                        ],
                        "parent": 39789116,
                        "text": "There&#x27;s no reason for OpenAI to release the model. They have close to 100% market anyways and releasing GPT-5 likely won&#x27;t increase the total market as it is a incremental leap. And it&#x27;s a open secret that most other models used GPT-4 synthetic data for training to come close to it.<p>They would likely wait till any model performs better than GPT 4 for the same price",
                        "time": 1711102886,
                        "type": "comment",
                        "comments": [
                            {
                                "by": "whiplash451",
                                "id": 39789418,
                                "kids": [
                                    39790642
                                ],
                                "parent": 39789153,
                                "text": "The same reasoning would have applied for GPT-3.5.  In the <i>hindsight</i>, you can say that it was obviously a good idea to build and ship GPT4.  But hindsight is 20&#x2F;20.",
                                "time": 1711105377,
                                "type": "comment",
                                "comments": [
                                    {
                                        "by": "YetAnotherNick",
                                        "id": 39790642,
                                        "parent": 39789418,
                                        "text": "There are few differences. Firstly, GPT-3.5 wasn&#x27;t ahead of Palm etc. from Google which was published at the same time as GPT-4.<p>Secondly, GPT-4 increased overall AI market. According to all the sources, interviews and leaks, GPT-5 won&#x27;t be a big leap over GPT-4 as the model size and training data won&#x27;t be significantly larger. I doubt GPT-5 would do that. (I could be wrong in my assumption though that GPT-5 would just be a incremental gain).",
                                        "time": 1711114763,
                                        "type": "comment"
                                    }
                                ]
                            },
                            {
                                "by": "chilmers",
                                "id": 39789424,
                                "kids": [
                                    39790657
                                ],
                                "parent": 39789153,
                                "text": "By any chance did you used to work in leadership at Nokia or Research in Motion? :-D",
                                "time": 1711105503,
                                "type": "comment",
                                "comments": [
                                    {
                                        "by": "YetAnotherNick",
                                        "id": 39790657,
                                        "parent": 39789424,
                                        "text": "Nokia wasn&#x27;t that ahead in technology and Motion wasn&#x27;t that ahead in market. GPT-4 is ahead in both.",
                                        "time": 1711114866,
                                        "type": "comment"
                                    }
                                ]
                            },
                            {
                                "by": "lewhoo",
                                "id": 39789342,
                                "parent": 39789153,
                                "text": "There is reason to release new models if said models would be capable of grabbing a significant portion of job market currently occupied by humans.",
                                "time": 1711104622,
                                "type": "comment"
                            },
                            {
                                "by": "tosh",
                                "id": 39789259,
                                "kids": [
                                    39789529,
                                    39790490
                                ],
                                "parent": 39789153,
                                "text": "100%?<p>Claude 3 Opus is in the capability ballpark of GPT-4, GPT-3.5 has alternatives that are cheaper (Claude 3 Haiku) or cheaper and work offline (Qwen 1.5, Mixtral, \u2026).",
                                "time": 1711103897,
                                "type": "comment",
                                "comments": [
                                    {
                                        "by": "ZitchDog",
                                        "id": 39789529,
                                        "parent": 39789259,
                                        "text": "100% market share.<p>A competitor will likely need to be 10x better than ChatGPT in order to get significant market share, not just marginally better in certain scenarios.",
                                        "time": 1711106417,
                                        "type": "comment"
                                    },
                                    {
                                        "by": "Kostic",
                                        "id": 39790490,
                                        "parent": 39789259,
                                        "text": "Is Claude 3 Opus generating more profits and taking considerable amount of customers from OpenAI? I&#x27;m not seeing that yet. Granted, I&#x27;m in Europe (outside of EU) so I can&#x27;t pay for Opus but I guess that kinda confirms my statement. GPT4 is still a good product and there are no market pressures to release GPT5.",
                                        "time": 1711113920,
                                        "type": "comment"
                                    }
                                ]
                            }
                        ]
                    },
                    {
                        "by": "burrish",
                        "id": 39789163,
                        "kids": [
                            39789181,
                            39789317
                        ],
                        "parent": 39789116,
                        "text": "I hear it should be dropped this summer",
                        "time": 1711102997,
                        "type": "comment",
                        "comments": [
                            {
                                "by": "cornedor",
                                "id": 39789181,
                                "kids": [
                                    39789284,
                                    39789413
                                ],
                                "parent": 39789163,
                                "text": "According to Sam Altman in a podcast with Lex Fridman this week, there is no real indication that it will be dropped this year. They will release a new model, but it might not be GPT-5",
                                "time": 1711103164,
                                "type": "comment",
                                "comments": [
                                    {
                                        "by": "burrish",
                                        "id": 39789284,
                                        "parent": 39789181,
                                        "text": "Fair enough, I got the info from this article<p><a href=\"https:&#x2F;&#x2F;web.archive.org&#x2F;web&#x2F;20240319224624&#x2F;https:&#x2F;&#x2F;www.businessinsider.com&#x2F;openai-launch-better-gpt-5-chatbot-2024-3\" rel=\"nofollow\">https:&#x2F;&#x2F;web.archive.org&#x2F;web&#x2F;20240319224624&#x2F;https:&#x2F;&#x2F;www.busin...</a>",
                                        "time": 1711104092,
                                        "type": "comment"
                                    },
                                    {
                                        "by": "whiplash451",
                                        "id": 39789413,
                                        "kids": [
                                            39789758
                                        ],
                                        "parent": 39789181,
                                        "text": "Which is an indication of nothing.  In which world would Sam A. drop any kind of info about such a sensitive topic? If anything, this could just be deception before a massive drop.",
                                        "time": 1711105314,
                                        "type": "comment",
                                        "comments": [
                                            {
                                                "by": "HarHarVeryFunny",
                                                "id": 39789758,
                                                "parent": 39789413,
                                                "text": "Could also be resetting expectations for people who&#x27;ve been expecting GPT-5 (or just GPT-4.5) sooner - been a year now since GPT-4 was released.<p>The other odd thing from Altman was saying that GPT-4 sucks.<p>I think the context for both announcements is the recent release of Anthropic&#x27;s Claude-3, which in it&#x27;s largest &quot;Opus&quot; form beats GPT-4 across the board in benchmarks.<p>I personally think OpenAI&#x2F;Altman is a bit scared that any moat&#x2F;lead they had has disappeared and they are now being out-competed by Anthropic (Claude). Remember that Anthropic as a company was only formed (by core members of the OpenAI LLM team) at the same time as GPT-3 was released, so in same time it took OpenAI to go from GPT-3 to GPT-4, Anthropic have gone from nothing -&gt; Claude-1 -&gt; Claude-2 -&gt; Claude-3 which beats GPT-4 !!<p>Anthropic have also had quite a bit of success attracting corporate business, quite a bit of which is more long-term in nature (sharing details of expected future model capabilities so that partners can target those).<p>So, I think OpenAI is running a bit scared, and I&#x27;d interpret this non-announcement of some model (4.5 or 5) &quot;coming soonish&quot; to be them just waving the flag and saying &quot;we&#x27;ll be back on top soon&quot;, which they presumably will be, briefly, when their next release(s) do come out. Altman&#x27;s odd &quot;GPT-4 sucks&quot; statement might be meant to downplay Claude-3 &quot;Opus&quot; which beats it.",
                                                "time": 1711108592,
                                                "type": "comment"
                                            }
                                        ]
                                    }
                                ]
                            },
                            {
                                "by": "DalasNoin",
                                "id": 39789317,
                                "parent": 39789163,
                                "text": "My understanding from the lex podcast: they will release a lot of new models this year, but they will release intermediate models first before gpt-5",
                                "time": 1711104336,
                                "type": "comment"
                            }
                        ]
                    }
                ]
            },
            {
                "by": "dns_snek",
                "id": 39789466,
                "kids": [
                    39789572,
                    39789517,
                    39789946,
                    39789563,
                    39789535,
                    39789679,
                    39789508,
                    39789807,
                    39789492,
                    39789623,
                    39789485,
                    39789893
                ],
                "parent": 39788590,
                "text": "For all the posturing and crypto hate on HN, we&#x27;re entering a world where it&#x27;s socially acceptable to use 1000W of computing power and 5 seconds of inference time to parse a tiny HTML fragment which would take microseconds with traditional methods - and people are cheering about it. Time for some self-reflection? That&#x27;s not very green.",
                "time": 1711105940,
                "type": "comment",
                "comments": [
                    {
                        "by": "delegate",
                        "id": 39789572,
                        "kids": [
                            39789612,
                            39789808,
                            39791207
                        ],
                        "parent": 39789466,
                        "text": "Crypto energy requirements go up as the currency gets more traction.<p>TFA shows that groq is many times faster than GPT-4.\nUp to 18x groq claims. Faster means less energy.\nSo I think it&#x27;s just a matter of time until these things become ridiculously power efficient (eg run on phones in sub second times)",
                        "time": 1711106855,
                        "type": "comment",
                        "comments": [
                            {
                                "by": "jodleif",
                                "id": 39789612,
                                "kids": [
                                    39789654,
                                    39789663
                                ],
                                "parent": 39789572,
                                "text": "How does faster mean less energy? Thats only true if you\u2019re running faster on the same hardware\u2026",
                                "time": 1711107126,
                                "type": "comment",
                                "comments": [
                                    {
                                        "by": "delegate",
                                        "id": 39789654,
                                        "parent": 39789612,
                                        "text": "Presumably. Less time the giant chip has to draw power for computation. \nThe point is that everyone&#x27;s interested in making AI power efficient, while crypto&#x27;s proof of work is a competition for more power burned hashing and throwing away the result.",
                                        "time": 1711107529,
                                        "type": "comment"
                                    },
                                    {
                                        "by": "wenebego",
                                        "id": 39789663,
                                        "kids": [
                                            39806952
                                        ],
                                        "parent": 39789612,
                                        "text": "I think they are talking about the case where, hypothetically, there is a 10x increase in speed but only 2x increase in power consumption",
                                        "time": 1711107660,
                                        "type": "comment",
                                        "comments": [
                                            {
                                                "by": "jodleif",
                                                "id": 39806952,
                                                "parent": 39789663,
                                                "text": "I\u2019m just pointing out that this is not a given\u2026",
                                                "time": 1711285084,
                                                "type": "comment"
                                            }
                                        ]
                                    }
                                ]
                            },
                            {
                                "by": "drexlspivey",
                                "id": 39789808,
                                "parent": 39789572,
                                "text": "Bitcoin energy requirements will be cut in half in a few days..",
                                "time": 1711108983,
                                "type": "comment"
                            },
                            {
                                "by": "samus",
                                "id": 39791207,
                                "parent": 39789572,
                                "text": "It&#x27;s still a monstrosity compared to a traditional parser. You can even be fancy and use complex parsers that backtrack and can deal with mildly context-sensitive languages (as required for HTML, XML, and many programmin languages), and you&#x27;d still be more efficient.",
                                "time": 1711118429,
                                "type": "comment"
                            }
                        ]
                    },
                    {
                        "by": "shanehoban",
                        "id": 39789517,
                        "kids": [
                            39789546
                        ],
                        "parent": 39789466,
                        "text": "This is a valid point, but we are still in the early stages of AI&#x2F;LLMs, so one would expect the speed and efficiency to improve drastically (perhaps accuracy too) over the coming years.<p>At least AI &amp; LLMs have large scale practical applications as opposed to crypto (IMO).",
                        "time": 1711106315,
                        "type": "comment",
                        "comments": [
                            {
                                "by": "AlchemistCamp",
                                "id": 39789546,
                                "kids": [
                                    39789687,
                                    39789728,
                                    39789637
                                ],
                                "parent": 39789517,
                                "text": "AI is a lot older than blockchain. There were full-fledged neural networks in the 40s and the perceptron was implemented in hardware in the 50s.",
                                "time": 1711106576,
                                "type": "comment",
                                "comments": [
                                    {
                                        "by": "IshanMi",
                                        "id": 39789687,
                                        "kids": [
                                            39789794
                                        ],
                                        "parent": 39789546,
                                        "text": "It&#x27;s also interesting to think that IBM released an 8-trillion parameter model back in the 1980s [0]. Granted it was an n-gram model so it&#x27;s not exactly an apples-to-apples comparison with today&#x27;s models, but still, quite crazy to think about.<p>[0]: <a href=\"https:&#x2F;&#x2F;aclanthology.org&#x2F;J92-4003.pdf\" rel=\"nofollow\">https:&#x2F;&#x2F;aclanthology.org&#x2F;J92-4003.pdf</a>",
                                        "time": 1711107930,
                                        "type": "comment",
                                        "comments": [
                                            {
                                                "by": "lukeschantz",
                                                "id": 39789794,
                                                "parent": 39789687,
                                                "text": "Interesting to see Robert Mercer the former CEO of Renaissance Technology is one of the authors on that paper. He is a former IBMer. If his name is unfamiliar he is a reclusive character who was a major funder of Breitbart, Cambridge Analytica and the Republican candidate in the 2016 presidential election.",
                                                "time": 1711108866,
                                                "type": "comment"
                                            }
                                        ]
                                    },
                                    {
                                        "by": "varjag",
                                        "id": 39789728,
                                        "kids": [
                                            39791233
                                        ],
                                        "parent": 39789546,
                                        "text": "I wouldn&#x27;t call the early McCulloch &amp; Pitts work quite &quot;full-fledged&quot;. Also backpropagation, essential for multi level perceptrons was not a thing until 1980s.",
                                        "time": 1711108340,
                                        "type": "comment",
                                        "comments": [
                                            {
                                                "by": "samus",
                                                "id": 39791233,
                                                "kids": [
                                                    39800693
                                                ],
                                                "parent": 39789728,
                                                "text": "Backprop is just applied calculus. People simply didn&#x27;t think about using it for neuronal networks yet.",
                                                "time": 1711118638,
                                                "type": "comment",
                                                "comments": [
                                                    {
                                                        "by": "varjag",
                                                        "id": 39800693,
                                                        "parent": 39791233,
                                                        "text": "It was thought of as early as in 1960s by Rosenblatt but he did not come up with a practical implementation at the time. Lotsa things look obvious in hindsight.",
                                                        "time": 1711208236,
                                                        "type": "comment"
                                                    }
                                                ]
                                            }
                                        ]
                                    },
                                    {
                                        "deleted": true,
                                        "id": 39789637,
                                        "parent": 39789546,
                                        "time": 1711107383,
                                        "type": "comment"
                                    }
                                ]
                            }
                        ]
                    },
                    {
                        "by": "ogogmad",
                        "id": 39789946,
                        "kids": [
                            39790548
                        ],
                        "parent": 39789466,
                        "text": "You&#x27;re partially right. It&#x27;s obvious that the solution is to combine traditional programming with AI, using traditional programming wherever possible because it&#x27;s greener. Assuming you want things to turn out well in every possible future scenario, your decisions only matter if AGI isn&#x27;t right around the corner. So assume it isn&#x27;t right around the corner. Then there&#x27;s going to be some interesting combining-together of manual human intervention, traditional software, and AI. We&#x27;ll need to charge more for some uses of electricity, to incentivise turning AI into traditional software wherever possible.<p>Crypto is nearly pure waste.",
                        "time": 1711110087,
                        "type": "comment",
                        "comments": [
                            {
                                "by": "CaptainFever",
                                "id": 39790548,
                                "parent": 39789946,
                                "text": "&gt; We&#x27;ll need to charge more for some uses of electricity, to incentivise turning AI into traditional software wherever possible.<p>I don&#x27;t understand this. This adds bureaucracy and I don&#x27;t see why different uses need to be charged differently if they all use energy the same.<p>In other words, if energy costs X per unit, and an inefficient (AI) software takes 30 units and an efficient (traditional) software takes 10 units, then it is already cheaper to run the efficient software, and thus people are already incentivised to do so. There&#x27;s no need to charge differently. If one day AI turns out to only need 5 units, turning more efficient, then just charge them for 5X. People will gravitate towards the new, efficient AI software naturally then.",
                                "time": 1711114288,
                                "type": "comment"
                            }
                        ]
                    },
                    {
                        "by": "Jensson",
                        "id": 39789563,
                        "parent": 39789466,
                        "text": "Websites will never be fast, will they? Even with 1000x more compute than now they will just perform everything in LLM calls and stuff are just as slow as now.",
                        "time": 1711106719,
                        "type": "comment"
                    },
                    {
                        "by": "qup",
                        "id": 39789535,
                        "kids": [
                            39789901
                        ],
                        "parent": 39789466,
                        "text": "It would take microseconds after a complete program was written by a human?<p>It no longer requires an expert human",
                        "time": 1711106442,
                        "type": "comment",
                        "comments": [
                            {
                                "by": "josho",
                                "id": 39789901,
                                "parent": 39789535,
                                "text": "And if this use case hit any kind of scale. We\u2019d just have an llm generate a parser and be back to microseconds.<p>This was just a blog to generate traffic on the site. Not to showcase some new use case for an llm.",
                                "time": 1711109780,
                                "type": "comment"
                            }
                        ]
                    },
                    {
                        "by": "samlinnfer",
                        "id": 39789679,
                        "kids": [
                            39790423,
                            39791242
                        ],
                        "parent": 39789466,
                        "text": "Any amount of energy spent useful work is vastly superior than whatever \u201cPOW\u201d crypto burn does.<p>&gt;For all the posturing and forest fire hate on HN, it\u2019s now socially acceptable to run a toy steam engine to power a model car? Not very green of you.",
                        "time": 1711107866,
                        "type": "comment",
                        "comments": [
                            {
                                "by": "CaptainFever",
                                "id": 39790423,
                                "parent": 39789679,
                                "text": "It&#x27;s almost a fallacy at this point to declare something bad simply because of the existence of carbon emissions, without first comparing the benefits of what is being produced, and the alternative tradeoffs.<p>To be fair to GP, they did compare it to alternatives (dumb HTML parsing), but failed to consider versatile HTML parsing or other uses for Groq LLM.",
                                "time": 1711113521,
                                "type": "comment"
                            },
                            {
                                "by": "samus",
                                "id": 39791242,
                                "parent": 39789679,
                                "text": "While you are not wrong, crypto is not what this is being compared with.",
                                "time": 1711118713,
                                "type": "comment"
                            }
                        ]
                    },
                    {
                        "by": "londons_explore",
                        "id": 39789508,
                        "kids": [
                            39789913
                        ],
                        "parent": 39789466,
                        "text": "While energy remains cheap and human minds remain expensive, it always makes sense to use AI to reduce human effort.<p>If one cares about the environment, a carbon cap&#x2F;tax is what you should campaign for.   Then carbon-based energy sources will be curtailled, energy costs will go up, and AI like this will be encouraged to become more energy efficient or other methods used instead.",
                        "time": 1711106251,
                        "type": "comment",
                        "comments": [
                            {
                                "by": "osigurdson",
                                "id": 39789913,
                                "kids": [
                                    39790752
                                ],
                                "parent": 39789508,
                                "text": "It is a nice idea in principle but ends up being a political tool and a tariff on goods and services of your own country. A global and corruption free carbon tax might work but that is impossible to achieve.",
                                "time": 1711109859,
                                "type": "comment",
                                "comments": [
                                    {
                                        "by": "londons_explore",
                                        "id": 39790752,
                                        "kids": [
                                            39799910
                                        ],
                                        "parent": 39789913,
                                        "text": "The only way it&#x27;s gonna work is if a bunch of countries get together, agree a carbon cap&#x2F;tax, and then tell other countries that they need to join the scheme if they want to trade goods with the group.<p>One way to combat corruption is to ask an international panel of experts to assess how many extra emissions came from non-official sources in each country and reduce next years cap by that amount.   Then countries have an incentive to stamp out corruption.",
                                        "time": 1711115374,
                                        "type": "comment",
                                        "comments": [
                                            {
                                                "by": "osigurdson",
                                                "id": 39799910,
                                                "kids": [
                                                    39802018
                                                ],
                                                "parent": 39790752,
                                                "text": "I don&#x27;t know. Corruption gets easier with increased centralization. I think a far better approach is to innovate our way out of it. If carbon free energy sources are less expensive then the problem will solve itself essentially. A global carbon tax will enviably extract some portion of global GDP from corruption. That money would likely be better spent in other ways.<p>Basically, carbon tax is the accountant&#x27;s solution, innovation is the engineer&#x27;s.",
                                                "time": 1711201619,
                                                "type": "comment",
                                                "comments": [
                                                    {
                                                        "by": "londons_explore",
                                                        "id": 39802018,
                                                        "parent": 39799910,
                                                        "text": "carbon-free will take a really long time to be cheaper.<p>As soon as demand for oil starts to drop, so will oil prices, and I suspect they could go down by a factor of 10 or more and oil-rich nations would still think it worthwhile to exploit at least some reserves.",
                                                        "time": 1711218218,
                                                        "type": "comment"
                                                    }
                                                ]
                                            }
                                        ]
                                    }
                                ]
                            }
                        ]
                    },
                    {
                        "by": "infecto",
                        "id": 39789807,
                        "parent": 39789466,
                        "text": "Because crypto has very little real world use.<p>There is a lot of business value happening in the AI space and its only going to get better.",
                        "time": 1711108982,
                        "type": "comment"
                    },
                    {
                        "by": "skc",
                        "id": 39789492,
                        "parent": 39789466,
                        "text": "One is actually useful day to day though.",
                        "time": 1711106156,
                        "type": "comment"
                    },
                    {
                        "by": "rafaelero",
                        "id": 39789623,
                        "kids": [
                            39789706
                        ],
                        "parent": 39789466,
                        "text": "What a ridiculous complaint. Energy efficiency won&#x27;t remain static, and even if it were, it&#x27;s not up to you to decide how to best leverage the available electricity.",
                        "time": 1711107214,
                        "type": "comment",
                        "comments": [
                            {
                                "by": "lm28469",
                                "id": 39789706,
                                "kids": [
                                    39789826,
                                    39789866
                                ],
                                "parent": 39789623,
                                "text": "&gt; it&#x27;s not up to you to decide<p>Unless you live in a dictatorship it&#x27;s definitely up to us to decide... Otherwise you leave your voice to the top 0.0001% business owners and expect them to work for your good and not for their own interests<p>Also read about the rebound effect. Planes are twice as efficient as they were 100 years ago yet they pollute infinitely more as a whole.<p>There is nothing ridiculous about the comment you&#x27;re replying to",
                                "time": 1711108029,
                                "type": "comment",
                                "comments": [
                                    {
                                        "by": "infecto",
                                        "id": 39789826,
                                        "parent": 39789706,
                                        "text": "Yes you are right and the future is dependent on innovation and using more electricity with a large percentage of it coming form renewable sources. I don&#x27;t want to go live on the farm myself.",
                                        "time": 1711109132,
                                        "type": "comment"
                                    },
                                    {
                                        "by": "rafaelero",
                                        "id": 39789866,
                                        "parent": 39789706,
                                        "text": "Ok, then let&#x27;s start by getting away with all the wasteful animal farming.",
                                        "time": 1711109513,
                                        "type": "comment"
                                    }
                                ]
                            }
                        ]
                    },
                    {
                        "by": "satisfice",
                        "id": 39789485,
                        "parent": 39789466,
                        "text": "AND it&#x27;s not even reliable.",
                        "time": 1711106097,
                        "type": "comment"
                    },
                    {
                        "deleted": true,
                        "id": 39789893,
                        "parent": 39789466,
                        "time": 1711109732,
                        "type": "comment"
                    }
                ]
            },
            {
                "deleted": true,
                "id": 39789902,
                "parent": 39788590,
                "time": 1711109786,
                "type": "comment"
            }
        ]
    },
    {
        "by": "baalimago",
        "descendants": 3,
        "id": 39805484,
        "kids": [
            39819663,
            39805960
        ],
        "score": 6,
        "text": "Supports text and image generation. For text generation you can query, chat or enter a glob + a query. For any of the commands xargs-like argument replacement can be used.<p>It&#x27;s written using only go&#x27;s standard library (plus go experimental, within my boilerplate package)",
        "time": 1711262367,
        "title": "Show HN: Clai \u2013 OpenAI models brought to the terminal",
        "type": "story",
        "url": "https://github.com/baalimago/clai",
        "comments": [
            {
                "by": "jshreder",
                "id": 39819663,
                "parent": 39805484,
                "text": "This looks great -- I&#x27;ve been using <a href=\"https:&#x2F;&#x2F;github.com&#x2F;ibigio&#x2F;shell-ai\">https:&#x2F;&#x2F;github.com&#x2F;ibigio&#x2F;shell-ai</a> (aliased to `q` ) but this looks even more apt for my use case. I use TypingMind for any real conversation with LLMs, but for quick answers in terminal, these kinds of tools are super useful.<p>I love the `ask` and `rask` shortcuts!<p>Would love support for Claude APIs :)",
                "time": 1711391223,
                "type": "comment"
            },
            {
                "by": "mehmet_mhy",
                "id": 39805960,
                "kids": [
                    39806137
                ],
                "parent": 39805484,
                "text": "This looks awesome. I like how clean it looks. I made something similar called Cha (<a href=\"https:&#x2F;&#x2F;github.com&#x2F;MehmetMHY&#x2F;cha\">https:&#x2F;&#x2F;github.com&#x2F;MehmetMHY&#x2F;cha</a>) that supports image generation, answer search, and web scrapping.",
                "time": 1711271645,
                "type": "comment",
                "comments": [
                    {
                        "by": "baalimago",
                        "id": 39806137,
                        "parent": 39805960,
                        "text": "Very cool! The way to swap between models and &#x27;live configure&#x27; is neat, also the ascii picture previews.<p>I think the idea of a cli text&#x2F;photo generator is so simple I think that anyone who is technically adept enough to appreciate it are also able to write a version of their own within a short amount of time.",
                        "time": 1711274683,
                        "type": "comment"
                    }
                ]
            }
        ]
    }
]